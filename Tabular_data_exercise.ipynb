{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf33f87c",
   "metadata": {},
   "source": [
    "# Tabular Dataset Exercise\n",
    "### The dataset is comming from this [Kaggle competition](https://www.kaggle.com/datasets/harlfoxem/housesalesprediction)\n",
    "### Where the goal is to predict the price of houses in King Country, USA.\n",
    "#### You can check the documentation of [Autogluon](https://auto.gluon.ai/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2200aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on your own computer please refer to AutoGluon installation instructions:\n",
    "# https://auto.gluon.ai/stable/install.html\n",
    "# This notebook assumes running in SageMaker Studio with \"PyTorch 1.12 Python 3.8 CPU Optimized\" kernel.\n",
    "!pip3 install autogluon\n",
    "!pip3 install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96871d97",
   "metadata": {},
   "source": [
    "#### 1) Run Autogluon default settings on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd836f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import autogluon tabular predictor and datasets\n",
    "# import ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dfb3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = TabularDataset('Datasets/kc_house_data.csv')\n",
    "    train_data, test_data = train_test_split(dataset, test_size=0.3, random_state=402)\n",
    "except:\n",
    "    # unzip the achive in the datasets folder\n",
    "    !unzip Datasets/archive.zip -d Datasets\n",
    "    dataset = TabularDataset('Datasets/kc_house_data.csv')\n",
    "    train_data, test_data = train_test_split(dataset, test_size=0.3, random_state=402)\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42348c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'price'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3487f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### call tabular predictor with default settings\n",
    "# predictor = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545faa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the predictor with the train data and set a time limit of 5 min.\n",
    "# predictor. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc37777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test dataset without the labels.\n",
    "\n",
    "# y_test = ...\n",
    "# test_data_nolab = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels of the test dataset you created \n",
    "# y_pred = ...\n",
    "# Evaluate your predictions\n",
    "# perf = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c092a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look to the leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4248f097",
   "metadata": {},
   "source": [
    "#### 2) Run Autogluon with your hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea74d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the core lib of autogluon\n",
    "# import ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9912362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the eval metric to mae (mean average error)\n",
    "# eval_metric = ...\n",
    "\n",
    "# Set hyperparameter of a NN model \n",
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    #'num_epochs': ... ,  # number of training epochs (controls training time of NN models)\n",
    "    #'learning_rate': ...,  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    #'activation': ...,  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    #'dropout_prob': ...,  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    #'num_boost_round': ...,  # number of boosting rounds (controls training time of GBM models)\n",
    "    #'num_leaves': ...,  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "# you can let a given model without setting hyperparameter\n",
    "cat_options = {\n",
    "}\n",
    "\n",
    "# set the hyperparameters of each model type\n",
    "hyperparameters = {  \n",
    "                   #'GBM': ...,\n",
    "                   #'NN_TORCH': ...,  \n",
    "                   #'CAT': ...\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "# train various models for ~5 min\n",
    "# time_limit = ...  \n",
    "# try at most 5 different hyperparameter configurations for each type of model\n",
    "# num_trials = ...   \n",
    "# to tune hyperparameters using random search routine with a local scheduler\n",
    "# search_strategy = ... \n",
    "\n",
    "# HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "hyperparameter_tune_kwargs = {  \n",
    "    # 'num_trials': ...,\n",
    "    'scheduler' : 'local',\n",
    "    # 'searcher': ...,\n",
    "}\n",
    "\n",
    "# Set up the predictor with the label, evaluation metric and problem type\n",
    "# predictor = ...\n",
    "\n",
    "# Fit the predictor with the train data, time limit, hyperparameters and the hyperparameter tune kwargs\n",
    "# predictor.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ffa5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictor\n",
    "# perf = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe46321",
   "metadata": {},
   "source": [
    "#### 3) Run Ensembling with you hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1803ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameter like above\n",
    "\n",
    "# Set the predictor \n",
    "# predictor = TabularPredictor()\n",
    "\n",
    "# fit the predictor with ensembling using num_bag_folds=..., num_bag_sets=..., num_stack_levels=... . You can aslo use auto_stack and presets\n",
    "# predictor.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800150c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the leaderboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2290c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
