{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ed16c6",
   "metadata": {},
   "source": [
    "# Tabular Dataset Exercise\n",
    "### The dataset is comming from this [Kaggle competition](https://www.kaggle.com/datasets/harlfoxem/housesalesprediction)\n",
    "### Where the goal is to predict the price of houses in King Country, USA.\n",
    "#### You can check the documentation of [Autogluon](https://auto.gluon.ai/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5d6399",
   "metadata": {},
   "source": [
    "### Context\n",
    "In this notebook you will have multiple cells to fill. You can use the demonstration notebook as a guide to use the different methods of Autogluon as both notebooks share the same structure. If you are blocked, please ask the team or you can use the solution notebook of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa6a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on your own computer please refer to AutoGluon installation instructions:\n",
    "# https://auto.gluon.ai/stable/install.html\n",
    "# This notebook assumes running in SageMaker Studio with \"PyTorch 1.12 Python 3.8 CPU Optimized\" kernel.\n",
    "!pip3 install autogluon\n",
    "!pip3 install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a948125",
   "metadata": {},
   "source": [
    "#### 1) Run Autogluon default settings on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8910cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import autogluon tabular predictor and datasets\n",
    "# import ...\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44135d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = TabularDataset('Datasets/kc_house_data.csv')\n",
    "    train_data, test_data = train_test_split(dataset, test_size=0.3, random_state=402)\n",
    "except:\n",
    "    # unzip the achive in the datasets folder\n",
    "    !unzip Datasets/archive.zip -d Datasets\n",
    "    dataset = TabularDataset('Datasets/kc_house_data.csv')\n",
    "    train_data, test_data = train_test_split(dataset, test_size=0.3, random_state=402)\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a2ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'price'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02210c54",
   "metadata": {},
   "source": [
    "### Call tabular predictor with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adedfb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call tabular predictor with default settings\n",
    "# predictor = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the predictor with the train data and set a time limit of 5 min.\n",
    "# predictor. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83adbc59",
   "metadata": {},
   "source": [
    "### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test dataset without the labels.\n",
    "\n",
    "# y_test = ...\n",
    "# test_data_nolab = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d31783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels of the test dataset you created \n",
    "# y_pred = ...\n",
    "# Evaluate your predictions\n",
    "# perf = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f13fdbc",
   "metadata": {},
   "source": [
    "### Models Leaderboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look to the leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67688bab",
   "metadata": {},
   "source": [
    "## 2) Run Autogluon with your hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaaea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the core lib of autogluon\n",
    "# import ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the eval metric to mae (mean average error)\n",
    "# eval_metric = ...\n",
    "\n",
    "# Set hyperparameter of a NN model \n",
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    #'num_epochs': ... ,  # number of training epochs (controls training time of NN models)\n",
    "    #'learning_rate': ...,  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    #'activation': ...,  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    #'dropout_prob': ...,  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    #'num_boost_round': ...,  # number of boosting rounds (controls training time of GBM models)\n",
    "    #'num_leaves': ...,  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "# you can let a given model without setting hyperparameter\n",
    "cat_options = {\n",
    "}\n",
    "\n",
    "# set the hyperparameters of each model type\n",
    "hyperparameters = {  \n",
    "                   #'GBM': ...,\n",
    "                   #'NN_TORCH': ...,  \n",
    "                   #'CAT': ...\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "# train various models for ~5 min\n",
    "# time_limit = ...  \n",
    "# try at most 5 different hyperparameter configurations for each type of model\n",
    "# num_trials = ...   \n",
    "# to tune hyperparameters using random search routine with a local scheduler\n",
    "# search_strategy = ... \n",
    "\n",
    "# HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "hyperparameter_tune_kwargs = {  \n",
    "    # 'num_trials': ...,\n",
    "    'scheduler' : 'local',\n",
    "    # 'searcher': ...,\n",
    "}\n",
    "\n",
    "# Set up the predictor with the label, evaluation metric and problem type\n",
    "# predictor = ...\n",
    "\n",
    "# Fit the predictor with the train data, time limit, hyperparameters and the hyperparameter tune kwargs\n",
    "# predictor.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02539e5",
   "metadata": {},
   "source": [
    "### Performance evaluation vs default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictor\n",
    "# perf = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95448054",
   "metadata": {},
   "source": [
    "## 3) Run Ensembling with you hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ebfb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameter like above\n",
    "\n",
    "# Set the predictor \n",
    "# predictor = TabularPredictor()\n",
    "\n",
    "# fit the predictor with ensembling using num_bag_folds=..., num_bag_sets=..., num_stack_levels=... . You can aslo use auto_stack and presets\n",
    "# predictor.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149ca24",
   "metadata": {},
   "source": [
    "### Ensembling Models Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the leaderboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6557e34a",
   "metadata": {},
   "source": [
    "### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf855257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
