{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54381805",
   "metadata": {},
   "source": [
    "# AWS Re:Invent  Autogluon Workshop\n",
    "### This workshop will demonstrate a machine learning problem solved by autogluon.\n",
    "* Use the documentation of autogluon and the different tutorials [here](https://auto.gluon.ai/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5f858c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a49b688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt      education  education-num  \\\n",
       "6118    51   Private   39264   Some-college             10   \n",
       "23204   58   Private   51662           10th              6   \n",
       "29590   40   Private  326310   Some-college             10   \n",
       "18116   37   Private  222450        HS-grad              9   \n",
       "33964   62   Private  109190      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bee717e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count        500\n",
      "unique         2\n",
      "top        <=50K\n",
      "freq         365\n",
      "Name: class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "label = 'class'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58f98c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221019_114034/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221019_114034/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4152.73 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.73\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.65\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.81\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t2.75s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 8.32s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221019_114034/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b87fabae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>169085</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>226203</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>54260</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>176262</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>241185</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt      education  education-num  \\\n",
       "0   31            Private  169085           11th              7   \n",
       "1   17   Self-emp-not-inc  226203           12th              8   \n",
       "2   47            Private   54260      Assoc-voc             11   \n",
       "3   21            Private  176262   Some-college             10   \n",
       "4   17            Private  241185           12th              8   \n",
       "\n",
       "        marital-status        occupation relationship    race      sex  \\\n",
       "0   Married-civ-spouse             Sales         Wife   White   Female   \n",
       "1        Never-married             Sales    Own-child   White     Male   \n",
       "2   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n",
       "3        Never-married   Exec-managerial    Own-child   White   Female   \n",
       "4        Never-married    Prof-specialty    Own-child   White     Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0             0             0              20   United-States  \n",
       "1             0             0              45   United-States  \n",
       "2             0          1887              60   United-States  \n",
       "3             0             0              30   United-States  \n",
       "4             0             0              20   United-States  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "y_test = test_data[label]  # values to predict\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3aa1c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8374449790152523\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8374449790152523\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc19eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8374449790152523\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8374449790152523\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8374449790152523}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b133f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.842973</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.157960</td>\n",
       "      <td>0.062463</td>\n",
       "      <td>0.570961</td>\n",
       "      <td>0.157960</td>\n",
       "      <td>0.062463</td>\n",
       "      <td>0.570961</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.037239</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>0.915137</td>\n",
       "      <td>0.037239</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>0.915137</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.841130</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.159155</td>\n",
       "      <td>0.061881</td>\n",
       "      <td>0.477284</td>\n",
       "      <td>0.159155</td>\n",
       "      <td>0.061881</td>\n",
       "      <td>0.477284</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.035789</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.327178</td>\n",
       "      <td>0.035789</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.327178</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.837445</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.040946</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>0.218343</td>\n",
       "      <td>0.040946</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>0.218343</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.837445</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.044501</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.596575</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.378232</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.836421</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.017048</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.213307</td>\n",
       "      <td>0.017048</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.213307</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.833453</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.174446</td>\n",
       "      <td>0.060263</td>\n",
       "      <td>0.470668</td>\n",
       "      <td>0.174446</td>\n",
       "      <td>0.060263</td>\n",
       "      <td>0.470668</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.832839</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.465740</td>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.465740</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.828949</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.035526</td>\n",
       "      <td>0.011122</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>0.035526</td>\n",
       "      <td>0.011122</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.818610</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.197174</td>\n",
       "      <td>0.016836</td>\n",
       "      <td>0.548692</td>\n",
       "      <td>0.197174</td>\n",
       "      <td>0.016836</td>\n",
       "      <td>0.548692</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.810523</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.162917</td>\n",
       "      <td>0.011873</td>\n",
       "      <td>2.751457</td>\n",
       "      <td>0.162917</td>\n",
       "      <td>0.011873</td>\n",
       "      <td>2.751457</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.725970</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.006426</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.006426</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.695158</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0      RandomForestGini    0.842973       0.84        0.157960       0.062463   \n",
       "1              CatBoost    0.842461       0.85        0.037239       0.007632   \n",
       "2      RandomForestEntr    0.841130       0.83        0.159155       0.061881   \n",
       "3              LightGBM    0.839799       0.85        0.035789       0.005974   \n",
       "4               XGBoost    0.837445       0.87        0.040946       0.007789   \n",
       "5   WeightedEnsemble_L2    0.837445       0.87        0.044501       0.008325   \n",
       "6            LightGBMXT    0.836421       0.83        0.017048       0.005589   \n",
       "7        ExtraTreesGini    0.833453       0.82        0.174446       0.060263   \n",
       "8        ExtraTreesEntr    0.832839       0.81        0.206226       0.060837   \n",
       "9         LightGBMLarge    0.828949       0.83        0.035526       0.011122   \n",
       "10      NeuralNetFastAI    0.818610       0.82        0.197174       0.016836   \n",
       "11       NeuralNetTorch    0.810523       0.85        0.162917       0.011873   \n",
       "12       KNeighborsUnif    0.725970       0.73        0.015232       0.004500   \n",
       "13       KNeighborsDist    0.695158       0.65        0.024206       0.004900   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.570961                 0.157960                0.062463   \n",
       "1   0.915137                 0.037239                0.007632   \n",
       "2   0.477284                 0.159155                0.061881   \n",
       "3   0.327178                 0.035789                0.005974   \n",
       "4   0.218343                 0.040946                0.007789   \n",
       "5   0.596575                 0.003556                0.000536   \n",
       "6   0.213307                 0.017048                0.005589   \n",
       "7   0.470668                 0.174446                0.060263   \n",
       "8   0.465740                 0.206226                0.060837   \n",
       "9   0.395346                 0.035526                0.011122   \n",
       "10  0.548692                 0.197174                0.016836   \n",
       "11  2.751457                 0.162917                0.011873   \n",
       "12  0.006426                 0.015232                0.004500   \n",
       "13  0.004529                 0.024206                0.004900   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.570961            1       True          5  \n",
       "1            0.915137            1       True          7  \n",
       "2            0.477284            1       True          6  \n",
       "3            0.327178            1       True          4  \n",
       "4            0.218343            1       True         11  \n",
       "5            0.378232            2       True         14  \n",
       "6            0.213307            1       True          3  \n",
       "7            0.470668            1       True          8  \n",
       "8            0.465740            1       True          9  \n",
       "9            0.395346            1       True         13  \n",
       "10           0.548692            1       True         10  \n",
       "11           2.751457            1       True         12  \n",
       "12           0.006426            1       True          1  \n",
       "13           0.004529            1       True          2  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aaff5b",
   "metadata": {},
   "source": [
    "### Using hyperparameter settings\n",
    "#### You can find [here](https://auto.gluon.ai/dev/api/autogluon.tabular.models.html) some models and which hyperparameters you can set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03252f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n"
     ]
    }
   ],
   "source": [
    "import autogluon.core as ag\n",
    "\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54834820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221019_115121/\"\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221019_115121/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    39073\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' <=50K', ' >50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3474.02 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.92 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.19 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 4 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 11.99s of the 599.73s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53954554e17049dc8ac6086786393248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM_BAG_L1/T1 ...\n",
      "\t0.8713\t = Validation score   (accuracy)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T2 ...\n",
      "\t0.8715\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T3 ...\n",
      "\t0.8694\t = Validation score   (accuracy)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T4 ...\n",
      "\t0.8193\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T5 ...\n",
      "\t0.8681\t = Validation score   (accuracy)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest_BAG_L1 ... Tuning model for up to 11.99s of the 595.95s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e269ac6c3f44f0794a74099d921c8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Reducing model 'n_estimators' from 400 -> 363 due to low time. Expected time usage reduced from 10.5s -> 9.6s...\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: RandomForest_BAG_L1/T1 ...\n",
      "\t0.8639\t = Validation score   (accuracy)\n",
      "\t4.15s\t = Training   runtime\n",
      "\t1.51s\t = Validation runtime\n",
      "Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 11.99s of the 588.15s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9079c5d82b44bb86fd3165f4815d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 274.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L1/T1 ...\n",
      "\t0.8704\t = Validation score   (accuracy)\n",
      "\t9.54s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 11.99s of the 578.5s of remaining time.\n",
      "2022-10-19 11:51:50,775\tWARNING tune.py:682 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32193/859933617.py\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m }\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m predictor = TabularPredictor(label=label, eval_metric='acc').fit(\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mnum_bag_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bag_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_stack_levels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/utils/decorators.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_inner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    829\u001b[0m         }\n\u001b[1;32m    830\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save predictor to disk to enable prediction and training after interrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         self._learner.fit(X=train_data, X_val=tuning_data, X_unlabeled=unlabeled_data,\n\u001b[0m\u001b[1;32m    832\u001b[0m                           \u001b[0mholdout_frac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholdout_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bag_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bag_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bag_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bag_sets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                           \u001b[0mnum_stack_levels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_stack_levels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Learner is already fit.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     def _fit(self, X: DataFrame, X_val: DataFrame = None, scheduler_options=None, hyperparameter_tune=False,\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/tabular/learner/default_learner.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         trainer.fit(\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/tabular/trainer/auto_trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m                                      'Bagging/Stacking with a held-out validation set (blend stacking) is not yet supported.')\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         self._train_multi_and_ensemble(X=X,\n\u001b[0m\u001b[1;32m     86\u001b[0m                                        \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                                        \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_and_ensemble\u001b[0;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_rows_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_cols_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1665\u001b[0;31m         model_names_fit = self.train_multi_levels(X, y, hyperparameters=hyperparameters, X_val=X_val, y_val=y_val,\n\u001b[0m\u001b[1;32m   1666\u001b[0m                                                   X_unlabeled=X_unlabeled, level_start=1, level_end=num_stack_levels+1, time_limit=time_limit, **kwargs)\n\u001b[1;32m   1667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mtrain_multi_levels\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_core\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_aux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             base_model_names, aux_models = self.stack_new_level(\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_unlabeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_unlabeled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0maux_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         core_models = self.stack_new_level_core(X=X, y=y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled, models=models,\n\u001b[0m\u001b[1;32m    406\u001b[0m                                                 level=level, infer_limit=infer_limit, infer_limit_batch_size=infer_limit_batch_size, base_model_names=base_model_names, **core_kwargs)\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level_core\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         return self._train_multi(X=X_init, y=y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled,\n\u001b[0m\u001b[1;32m    497\u001b[0m                                  models=models, level=level, stack_name=stack_name, compute_score=compute_score, fit_kwargs=fit_kwargs, **kwargs)\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi\u001b[0;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_repeat_start\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m             model_names_trained = self._train_multi_initial(X=X, y=y, models=models, k_fold=k_fold, n_repeats=n_repeats_initial, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n\u001b[0m\u001b[1;32m   1636\u001b[0m                                                             feature_prune_kwargs=feature_prune_kwargs, time_limit=time_limit, **kwargs)\n\u001b[1;32m   1637\u001b[0m             \u001b[0mn_repeat_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_repeats_initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_initial\u001b[0;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhpo_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 \u001b[0mtime_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhpo_time_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m                 models = self._train_multi_fold(models=models, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n\u001b[0m\u001b[1;32m   1528\u001b[0m                                                 \u001b[0mk_fold_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeat_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m                                                 time_split=time_split, time_ratio=time_ratio, **fit_args)\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_fold\u001b[0;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1604\u001b[0m                     \u001b[0mtime_start_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m                     \u001b[0mtime_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_start_model\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1606\u001b[0;31m             \u001b[0mmodel_name_trained_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameter_tune_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameter_tune_kwargs_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single_full\u001b[0;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, **kwargs)\u001b[0m\n\u001b[1;32m   1378\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaggedEnsembleModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m                     hpo_models, hpo_results = model.hyperparameter_tune(\n\u001b[0m\u001b[1;32m   1381\u001b[0m                         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36mhyperparameter_tune\u001b[0;34m(self, hyperparameter_tune_kwargs, hpo_executor, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0mhpo_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyperparameter_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhpo_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhpo_executor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_hyperparameter_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpo_executor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\u001b[0m in \u001b[0;36m_hyperparameter_tune\u001b[0;34m(self, X, y, k_fold, hpo_executor, compute_base_preds, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mpreprocess_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'compute_base_preds'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompute_base_preds\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyperparameter_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpo_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhpo_executor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\u001b[0m in \u001b[0;36m_hyperparameter_tune\u001b[0;34m(self, X, y, k_fold, hpo_executor, preprocess_kwargs, groups, **kwargs)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morig_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0mhpo_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_time\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.8\u001b[0m  \u001b[0;31m# TODO: Scheduler doesn't early stop on final model, this is a safety net. Scheduler should be updated to early stop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         hpo_models, hpo_results = model_base.hyperparameter_tune(\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36mhyperparameter_tune\u001b[0;34m(self, hyperparameter_tune_kwargs, hpo_executor, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0mhpo_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyperparameter_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhpo_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhpo_executor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_hyperparameter_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpo_executor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36m_hyperparameter_tune\u001b[0;34m(self, X, y, X_val, y_val, hpo_executor, **kwargs)\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0mmodel_estimate_memory_usage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0mminimum_resources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minimum_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         hpo_executor.execute(\n\u001b[0m\u001b[1;32m   1054\u001b[0m             \u001b[0mmodel_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0mtrain_fn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_fn_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, model_trial, train_fn_kwargs, directory, minimum_cpu_per_trial, minimum_gpu_per_trial, model_estimate_memory_usage, adapter_type)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mRayTuneAdapterFactory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         )\n\u001b[0;32m--> 242\u001b[0;31m         analysis = run(\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mtrainable_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_fn_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/hpo/ray_hpo.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(trainable, trainable_args, search_space, hyperparameter_tune_kwargs, metric, mode, save_dir, ray_tune_adapter, total_resources, minimum_cpu_per_trial, minimum_gpu_per_trial, model_estimate_memory_usage, time_budget_s, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0moriginal_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     analysis = tune.run(\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrainable_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, loggers, _remote)\u001b[0m\n\u001b[1;32m    716\u001b[0m     )\n\u001b[1;32m    717\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"signal\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVerbosity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV1_EXPERIMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got new trial to run: {next_trial}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_and_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop_experiment_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_wait_and_handle_event\u001b[0;34m(self, next_trial)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;31m# Single wait of entire tune loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m             event = self.trial_executor.get_next_executor_event(\n\u001b[0m\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_live_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_trial\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_executor_event\u001b[0;34m(self, live_trials, next_trial_exists)\u001b[0m\n\u001b[1;32m    888\u001b[0m             )\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m             ready_futures, _ = ray.wait(\n\u001b[0m\u001b[1;32m    891\u001b[0m                 \u001b[0mfutures_to_wait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_returns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_event_wait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2013\u001b[0m         \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mtimeout_milliseconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m         ready_ids, remaining_ids = worker.core_worker.wait(\n\u001b[0m\u001b[1;32m   2016\u001b[0m             \u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2017\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "rf_options = {\n",
    "    'n_estimators': 400,\n",
    "    'max_leaf_nodes' : ag.space.Int(lower=500, upper=15000, default=2000),\n",
    "}\n",
    "\n",
    "cat_options = {\n",
    "    'learning_rate' : ag.space.Real(0.0,0.2,default=0.05),\n",
    "}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                   'RF': rf_options,\n",
    "                   'CAT': cat_options,\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 10*60  # train various models for ~2 min\n",
    "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric='acc').fit(\n",
    "    train_data, time_limit=time_limit,\n",
    "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6f2f0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8748080663322756\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8748080663322756\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b63e72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost/T5</td>\n",
       "      <td>0.875934</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.021565</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>14.451684</td>\n",
       "      <td>0.021565</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>14.451684</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM/T2</td>\n",
       "      <td>0.875934</td>\n",
       "      <td>0.876400</td>\n",
       "      <td>0.033536</td>\n",
       "      <td>0.045624</td>\n",
       "      <td>1.525269</td>\n",
       "      <td>0.033536</td>\n",
       "      <td>0.045624</td>\n",
       "      <td>1.525269</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost/T3</td>\n",
       "      <td>0.875115</td>\n",
       "      <td>0.877600</td>\n",
       "      <td>0.020148</td>\n",
       "      <td>0.013745</td>\n",
       "      <td>11.598638</td>\n",
       "      <td>0.020148</td>\n",
       "      <td>0.013745</td>\n",
       "      <td>11.598638</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost/T4</td>\n",
       "      <td>0.875115</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>0.013583</td>\n",
       "      <td>10.887210</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>0.013583</td>\n",
       "      <td>10.887210</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.874808</td>\n",
       "      <td>0.878800</td>\n",
       "      <td>1.067491</td>\n",
       "      <td>2.735195</td>\n",
       "      <td>81.948931</td>\n",
       "      <td>0.013306</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>3.274111</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost/T1</td>\n",
       "      <td>0.874706</td>\n",
       "      <td>0.876600</td>\n",
       "      <td>0.021638</td>\n",
       "      <td>0.013772</td>\n",
       "      <td>12.517243</td>\n",
       "      <td>0.021638</td>\n",
       "      <td>0.013772</td>\n",
       "      <td>12.517243</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM/T1</td>\n",
       "      <td>0.874296</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.039398</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>1.945582</td>\n",
       "      <td>0.039398</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>1.945582</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost/T2</td>\n",
       "      <td>0.873989</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.017486</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>6.171221</td>\n",
       "      <td>0.017486</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>6.171221</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM/T3</td>\n",
       "      <td>0.873887</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.050109</td>\n",
       "      <td>0.058517</td>\n",
       "      <td>1.698694</td>\n",
       "      <td>0.050109</td>\n",
       "      <td>0.058517</td>\n",
       "      <td>1.698694</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM/T5</td>\n",
       "      <td>0.872249</td>\n",
       "      <td>0.874200</td>\n",
       "      <td>0.046430</td>\n",
       "      <td>0.036162</td>\n",
       "      <td>1.085283</td>\n",
       "      <td>0.046430</td>\n",
       "      <td>0.036162</td>\n",
       "      <td>1.085283</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest/T1</td>\n",
       "      <td>0.864879</td>\n",
       "      <td>0.863499</td>\n",
       "      <td>0.317698</td>\n",
       "      <td>1.144103</td>\n",
       "      <td>3.926396</td>\n",
       "      <td>0.317698</td>\n",
       "      <td>1.144103</td>\n",
       "      <td>3.926396</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest/T2</td>\n",
       "      <td>0.860477</td>\n",
       "      <td>0.860564</td>\n",
       "      <td>0.390059</td>\n",
       "      <td>1.233687</td>\n",
       "      <td>3.313111</td>\n",
       "      <td>0.390059</td>\n",
       "      <td>1.233687</td>\n",
       "      <td>3.313111</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForest/T5</td>\n",
       "      <td>0.858225</td>\n",
       "      <td>0.859625</td>\n",
       "      <td>0.325078</td>\n",
       "      <td>1.282908</td>\n",
       "      <td>3.450986</td>\n",
       "      <td>0.325078</td>\n",
       "      <td>1.282908</td>\n",
       "      <td>3.450986</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForest/T4</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.856426</td>\n",
       "      <td>0.381077</td>\n",
       "      <td>1.376040</td>\n",
       "      <td>3.804994</td>\n",
       "      <td>0.381077</td>\n",
       "      <td>1.376040</td>\n",
       "      <td>3.804994</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForest/T3</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.856426</td>\n",
       "      <td>0.486649</td>\n",
       "      <td>1.386862</td>\n",
       "      <td>3.802230</td>\n",
       "      <td>0.486649</td>\n",
       "      <td>1.386862</td>\n",
       "      <td>3.802230</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NeuralNetTorch/93d6b_00001</td>\n",
       "      <td>0.853311</td>\n",
       "      <td>0.856800</td>\n",
       "      <td>0.161324</td>\n",
       "      <td>0.145969</td>\n",
       "      <td>22.624712</td>\n",
       "      <td>0.161324</td>\n",
       "      <td>0.145969</td>\n",
       "      <td>22.624712</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NeuralNetTorch/93d6b_00000</td>\n",
       "      <td>0.850548</td>\n",
       "      <td>0.853000</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.210032</td>\n",
       "      <td>28.253626</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.210032</td>\n",
       "      <td>28.253626</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NeuralNetTorch/93d6b_00003</td>\n",
       "      <td>0.849217</td>\n",
       "      <td>0.848600</td>\n",
       "      <td>0.155053</td>\n",
       "      <td>0.124429</td>\n",
       "      <td>23.429226</td>\n",
       "      <td>0.155053</td>\n",
       "      <td>0.124429</td>\n",
       "      <td>23.429226</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NeuralNetTorch/93d6b_00004</td>\n",
       "      <td>0.847784</td>\n",
       "      <td>0.845600</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.096776</td>\n",
       "      <td>19.755929</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.096776</td>\n",
       "      <td>19.755929</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NeuralNetTorch/93d6b_00002</td>\n",
       "      <td>0.845737</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>0.176284</td>\n",
       "      <td>0.122191</td>\n",
       "      <td>25.757243</td>\n",
       "      <td>0.176284</td>\n",
       "      <td>0.122191</td>\n",
       "      <td>25.757243</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LightGBM/T4</td>\n",
       "      <td>0.820248</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.031249</td>\n",
       "      <td>0.057091</td>\n",
       "      <td>1.312392</td>\n",
       "      <td>0.031249</td>\n",
       "      <td>0.057091</td>\n",
       "      <td>1.312392</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  score_test  score_val  pred_time_test  \\\n",
       "0                  CatBoost/T5    0.875934   0.877000        0.021565   \n",
       "1                  LightGBM/T2    0.875934   0.876400        0.033536   \n",
       "2                  CatBoost/T3    0.875115   0.877600        0.020148   \n",
       "3                  CatBoost/T4    0.875115   0.877800        0.020232   \n",
       "4          WeightedEnsemble_L2    0.874808   0.878800        1.067491   \n",
       "5                  CatBoost/T1    0.874706   0.876600        0.021638   \n",
       "6                  LightGBM/T1    0.874296   0.875600        0.039398   \n",
       "7                  CatBoost/T2    0.873989   0.877000        0.017486   \n",
       "8                  LightGBM/T3    0.873887   0.875600        0.050109   \n",
       "9                  LightGBM/T5    0.872249   0.874200        0.046430   \n",
       "10             RandomForest/T1    0.864879   0.863499        0.317698   \n",
       "11             RandomForest/T2    0.860477   0.860564        0.390059   \n",
       "12             RandomForest/T5    0.858225   0.859625        0.325078   \n",
       "13             RandomForest/T4    0.857201   0.856426        0.381077   \n",
       "14             RandomForest/T3    0.857201   0.856426        0.486649   \n",
       "15  NeuralNetTorch/93d6b_00001    0.853311   0.856800        0.161324   \n",
       "16  NeuralNetTorch/93d6b_00000    0.850548   0.853000        0.508693   \n",
       "17  NeuralNetTorch/93d6b_00003    0.849217   0.848600        0.155053   \n",
       "18  NeuralNetTorch/93d6b_00004    0.847784   0.845600        0.191878   \n",
       "19  NeuralNetTorch/93d6b_00002    0.845737   0.846000        0.176284   \n",
       "20                 LightGBM/T4    0.820248   0.818600        0.031249   \n",
       "\n",
       "    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.014523  14.451684                 0.021565                0.014523   \n",
       "1        0.045624   1.525269                 0.033536                0.045624   \n",
       "2        0.013745  11.598638                 0.020148                0.013745   \n",
       "3        0.013583  10.887210                 0.020232                0.013583   \n",
       "4        2.735195  81.948931                 0.013306                0.007610   \n",
       "5        0.013772  12.517243                 0.021638                0.013772   \n",
       "6        0.046588   1.945582                 0.039398                0.046588   \n",
       "7        0.012644   6.171221                 0.017486                0.012644   \n",
       "8        0.058517   1.698694                 0.050109                0.058517   \n",
       "9        0.036162   1.085283                 0.046430                0.036162   \n",
       "10       1.144103   3.926396                 0.317698                1.144103   \n",
       "11       1.233687   3.313111                 0.390059                1.233687   \n",
       "12       1.282908   3.450986                 0.325078                1.282908   \n",
       "13       1.376040   3.804994                 0.381077                1.376040   \n",
       "14       1.386862   3.802230                 0.486649                1.386862   \n",
       "15       0.145969  22.624712                 0.161324                0.145969   \n",
       "16       0.210032  28.253626                 0.508693                0.210032   \n",
       "17       0.124429  23.429226                 0.155053                0.124429   \n",
       "18       0.096776  19.755929                 0.191878                0.096776   \n",
       "19       0.122191  25.757243                 0.176284                0.122191   \n",
       "20       0.057091   1.312392                 0.031249                0.057091   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           14.451684            1       True         15  \n",
       "1            1.525269            1       True          2  \n",
       "2           11.598638            1       True         13  \n",
       "3           10.887210            1       True         14  \n",
       "4            3.274111            2       True         21  \n",
       "5           12.517243            1       True         11  \n",
       "6            1.945582            1       True          1  \n",
       "7            6.171221            1       True         12  \n",
       "8            1.698694            1       True          3  \n",
       "9            1.085283            1       True          5  \n",
       "10           3.926396            1       True          6  \n",
       "11           3.313111            1       True          7  \n",
       "12           3.450986            1       True         10  \n",
       "13           3.804994            1       True          9  \n",
       "14           3.802230            1       True          8  \n",
       "15          22.624712            1       True         17  \n",
       "16          28.253626            1       True         16  \n",
       "17          23.429226            1       True         19  \n",
       "18          19.755929            1       True         20  \n",
       "19          25.757243            1       True         18  \n",
       "20           1.312392            1       True          4  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f73b5",
   "metadata": {},
   "source": [
    "### Using ensembling techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4d82463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221019_115218/\"\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221019_115218/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    39073\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' <=50K', ' >50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2676.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.92 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.19 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 4 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 11.99s of the 599.73s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339d3227c18a40e6aeab6079820a0e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM_BAG_L1/T1 ...\n",
      "\t0.8713\t = Validation score   (accuracy)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T2 ...\n",
      "\t0.8715\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T3 ...\n",
      "\t0.8694\t = Validation score   (accuracy)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T4 ...\n",
      "\t0.8193\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T5 ...\n",
      "\t0.8681\t = Validation score   (accuracy)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest_BAG_L1 ... Tuning model for up to 11.99s of the 596.0s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb1bb01cda444b6adc21dd124e3d5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Reducing model 'n_estimators' from 400 -> 336 due to low time. Expected time usage reduced from 11.3s -> 9.6s...\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: RandomForest_BAG_L1/T1 ...\n",
      "\t0.8637\t = Validation score   (accuracy)\n",
      "\t3.82s\t = Training   runtime\n",
      "\t1.39s\t = Validation runtime\n",
      "Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 11.99s of the 588.75s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f32e2bcd73c4d9587bd6f776f6d36e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 269.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L1/T1 ...\n",
      "\t0.8701\t = Validation score   (accuracy)\n",
      "\t9.56s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 11.99s of the 579.07s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "2022-10-19 11:52:50,276\tINFO stopper.py:363 -- Reached timeout of 9.593280153565408 seconds. Stopping all trials.\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T1 ...\n",
      "\t0.8374\t = Validation score   (accuracy)\n",
      "\t5.46s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T2 ...\n",
      "\t0.8375\t = Validation score   (accuracy)\n",
      "\t4.86s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T3 ...\n",
      "\t0.8395\t = Validation score   (accuracy)\n",
      "\t5.41s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 234.38s of the 567.63s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8733\t = Validation score   (accuracy)\n",
      "\t3.21s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 229.23s of the 562.48s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8743\t = Validation score   (accuracy)\n",
      "\t2.68s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T3 ... Training model for up to 224.27s of the 557.52s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t3.52s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T4 ... Training model for up to 218.56s of the 551.81s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8214\t = Validation score   (accuracy)\n",
      "\t3.14s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T5 ... Training model for up to 213.23s of the 546.48s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8715\t = Validation score   (accuracy)\n",
      "\t3.53s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L1/T1 ... Training model for up to 207.67s of the 540.92s of remaining time.\n",
      "\t0.8637\t = Validation score   (accuracy)\n",
      "\t3.82s\t = Training   runtime\n",
      "\t1.39s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1/T1 ... Training model for up to 207.6s of the 540.85s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8744\t = Validation score   (accuracy)\n",
      "\t90.19s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T1 ... Training model for up to 124.3s of the 457.55s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8479\t = Validation score   (accuracy)\n",
      "\t32.16s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T2 ... Training model for up to 94.79s of the 428.03s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8439\t = Validation score   (accuracy)\n",
      "\t34.3s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T3 ... Training model for up to 62.77s of the 396.02s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.848\t = Validation score   (accuracy)\n",
      "\t28.11s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Completed 1/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 370.73s of remaining time.\n",
      "\t0.8744\t = Validation score   (accuracy)\n",
      "\t10.84s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting 4 L2 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 10.79s of the 359.81s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cea2a571694ea598dccff0a3b25295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM_BAG_L2/T1 ...\n",
      "\t0.8738\t = Validation score   (accuracy)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L2/T2 ...\n",
      "\t0.8741\t = Validation score   (accuracy)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L2/T3 ...\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L2/T4 ...\n",
      "\t0.8394\t = Validation score   (accuracy)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L2/T5 ...\n",
      "\t0.8728\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest_BAG_L2 ... Tuning model for up to 10.79s of the 355.71s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634c64873fe74424884cd3562535d7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Reducing model 'n_estimators' from 400 -> 267 due to low time. Expected time usage reduced from 12.8s -> 8.6s...\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: RandomForest_BAG_L2/T1 ...\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t6.94s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Hyperparameter tuning model: CatBoost_BAG_L2 ... Tuning model for up to 10.79s of the 346.19s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1edb99d2743a4b759fe74780041aa43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L2/T1 ...\n",
      "\t0.8741\t = Validation score   (accuracy)\n",
      "\t7.98s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L2 ... Tuning model for up to 10.79s of the 338.07s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "2022-10-19 11:56:50,240\tINFO stopper.py:363 -- Reached timeout of 8.633498659306527 seconds. Stopping all trials.\n",
      "Fitted model: NeuralNetTorch_BAG_L2/T1 ...\n",
      "\t0.8713\t = Validation score   (accuracy)\n",
      "\t5.07s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L2/T2 ...\n",
      "\t0.8718\t = Validation score   (accuracy)\n",
      "\t4.47s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T1 ... Training model for up to 207.8s of the 327.79s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8736\t = Validation score   (accuracy)\n",
      "\t3.1s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T2 ... Training model for up to 202.86s of the 322.85s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8746\t = Validation score   (accuracy)\n",
      "\t3.41s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T3 ... Training model for up to 197.13s of the 317.12s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8744\t = Validation score   (accuracy)\n",
      "\t3.85s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T4 ... Training model for up to 191.17s of the 311.16s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8392\t = Validation score   (accuracy)\n",
      "\t3.57s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T5 ... Training model for up to 185.45s of the 305.44s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8735\t = Validation score   (accuracy)\n",
      "\t3.66s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L2/T1 ... Training model for up to 179.72s of the 299.7s of remaining time.\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t6.94s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2/T1 ... Training model for up to 179.65s of the 299.64s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8753\t = Validation score   (accuracy)\n",
      "\t23.44s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2/T1 ... Training model for up to 161.26s of the 281.25s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8733\t = Validation score   (accuracy)\n",
      "\t30.51s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2/T2 ... Training model for up to 133.11s of the 253.09s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8738\t = Validation score   (accuracy)\n",
      "\t28.97s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Completed 1/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 225.88s of remaining time.\n",
      "\t0.8758\t = Validation score   (accuracy)\n",
      "\t9.91s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting 4 L3 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L3 ... Tuning model for up to 9.72s of the 215.88s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e379568b6774a77a0c7a540e129870c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM_BAG_L3/T1 ...\n",
      "\t0.8816\t = Validation score   (accuracy)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L3/T2 ...\n",
      "\t0.8801\t = Validation score   (accuracy)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L3/T3 ...\n",
      "\t0.8811\t = Validation score   (accuracy)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L3/T4 ...\n",
      "\t0.8514\t = Validation score   (accuracy)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L3/T5 ...\n",
      "\t0.8807\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest_BAG_L3 ... Tuning model for up to 9.72s of the 211.67s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac98414b2ba457192966aaca6ca0e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Reducing model 'n_estimators' from 400 -> 305 due to low time. Expected time usage reduced from 10.1s -> 7.7s...\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: RandomForest_BAG_L3/T1 ...\n",
      "\t0.8728\t = Validation score   (accuracy)\n",
      "\t7.24s\t = Training   runtime\n",
      "\t1.21s\t = Validation runtime\n",
      "Hyperparameter tuning model: CatBoost_BAG_L3 ... Tuning model for up to 9.72s of the 201.53s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97599ce1795b44299f45cafa96baceb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L3/T1 ...\n",
      "\t0.8819\t = Validation score   (accuracy)\n",
      "\t7.65s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L3 ... Tuning model for up to 9.72s of the 193.75s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "2022-10-19 11:59:13,840\tINFO stopper.py:363 -- Reached timeout of 7.772111286163332 seconds. Stopping all trials.\n",
      "Fitted model: NeuralNetTorch_BAG_L3/T1 ...\n",
      "\t0.8796\t = Validation score   (accuracy)\n",
      "\t4.0s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L3/T2 ...\n",
      "\t0.8802\t = Validation score   (accuracy)\n",
      "\t3.76s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3/T1 ... Training model for up to 184.23s of the 184.22s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8752\t = Validation score   (accuracy)\n",
      "\t3.46s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3/T2 ... Training model for up to 178.96s of the 178.95s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8751\t = Validation score   (accuracy)\n",
      "\t2.98s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3/T3 ... Training model for up to 173.83s of the 173.82s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t3.82s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3/T4 ... Training model for up to 167.89s of the 167.88s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8458\t = Validation score   (accuracy)\n",
      "\t3.44s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3/T5 ... Training model for up to 162.39s of the 162.38s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8749\t = Validation score   (accuracy)\n",
      "\t3.39s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L3/T1 ... Training model for up to 156.98s of the 156.97s of remaining time.\n",
      "\t0.8728\t = Validation score   (accuracy)\n",
      "\t7.24s\t = Training   runtime\n",
      "\t1.21s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3/T1 ... Training model for up to 156.92s of the 156.91s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8758\t = Validation score   (accuracy)\n",
      "\t25.09s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3/T1 ... Training model for up to 136.69s of the 136.68s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8744\t = Validation score   (accuracy)\n",
      "\t29.37s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3/T2 ... Training model for up to 108.57s of the 108.56s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8746\t = Validation score   (accuracy)\n",
      "\t27.71s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Completed 1/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.0s of the 81.97s of remaining time.\n",
      "\t0.876\t = Validation score   (accuracy)\n",
      "\t10.04s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 528.14s ... Best model: \"WeightedEnsemble_L4\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221019_115218/\")\n"
     ]
    }
   ],
   "source": [
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "rf_options = {\n",
    "    'n_estimators': 400,\n",
    "    'max_leaf_nodes' : ag.space.Int(lower=500, upper=15000, default=2000),\n",
    "}\n",
    "\n",
    "cat_options = {\n",
    "    'learning_rate' : ag.space.Real(0.0,0.2,default=0.05),\n",
    "}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                   'RF': rf_options,\n",
    "                   'CAT': cat_options,\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 10*60  # train various models for ~2 min\n",
    "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric='acc').fit(\n",
    "    train_data, time_limit=time_limit, #auto_stack=True,\n",
    "    num_bag_folds=5, num_bag_sets=2, num_stack_levels=2,\n",
    "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0be9f202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8745009724639164\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8745009724639164\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf61108c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L2/T1</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>0.873647</td>\n",
       "      <td>4.607929</td>\n",
       "      <td>6.392114</td>\n",
       "      <td>207.766691</td>\n",
       "      <td>0.130898</td>\n",
       "      <td>0.145210</td>\n",
       "      <td>3.098280</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L2/T5</td>\n",
       "      <td>0.876241</td>\n",
       "      <td>0.873519</td>\n",
       "      <td>4.621554</td>\n",
       "      <td>6.435337</td>\n",
       "      <td>208.331747</td>\n",
       "      <td>0.144523</td>\n",
       "      <td>0.188432</td>\n",
       "      <td>3.663336</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_BAG_L2/T1</td>\n",
       "      <td>0.876036</td>\n",
       "      <td>0.875259</td>\n",
       "      <td>4.536136</td>\n",
       "      <td>6.349077</td>\n",
       "      <td>228.112616</td>\n",
       "      <td>0.059106</td>\n",
       "      <td>0.102173</td>\n",
       "      <td>23.444205</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetTorch_BAG_L2/T2</td>\n",
       "      <td>0.876036</td>\n",
       "      <td>0.873800</td>\n",
       "      <td>5.286805</td>\n",
       "      <td>7.319544</td>\n",
       "      <td>233.640086</td>\n",
       "      <td>0.809774</td>\n",
       "      <td>1.072639</td>\n",
       "      <td>28.971675</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L2/T2</td>\n",
       "      <td>0.875934</td>\n",
       "      <td>0.874594</td>\n",
       "      <td>4.596604</td>\n",
       "      <td>6.382348</td>\n",
       "      <td>208.082765</td>\n",
       "      <td>0.119574</td>\n",
       "      <td>0.135443</td>\n",
       "      <td>3.414354</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetTorch_BAG_L3/T1</td>\n",
       "      <td>0.875729</td>\n",
       "      <td>0.874389</td>\n",
       "      <td>8.779307</td>\n",
       "      <td>11.338098</td>\n",
       "      <td>341.504479</td>\n",
       "      <td>1.406430</td>\n",
       "      <td>1.038578</td>\n",
       "      <td>29.374693</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_BAG_L3/T1</td>\n",
       "      <td>0.875627</td>\n",
       "      <td>0.875234</td>\n",
       "      <td>7.513283</td>\n",
       "      <td>10.468890</td>\n",
       "      <td>315.592884</td>\n",
       "      <td>0.140405</td>\n",
       "      <td>0.169370</td>\n",
       "      <td>3.463098</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost_BAG_L1/T1</td>\n",
       "      <td>0.875525</td>\n",
       "      <td>0.874415</td>\n",
       "      <td>0.099878</td>\n",
       "      <td>0.165818</td>\n",
       "      <td>90.194755</td>\n",
       "      <td>0.099878</td>\n",
       "      <td>0.165818</td>\n",
       "      <td>90.194755</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.875525</td>\n",
       "      <td>0.874415</td>\n",
       "      <td>0.101681</td>\n",
       "      <td>0.224807</td>\n",
       "      <td>101.035081</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.058988</td>\n",
       "      <td>10.840326</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.875525</td>\n",
       "      <td>0.875797</td>\n",
       "      <td>6.286457</td>\n",
       "      <td>8.940844</td>\n",
       "      <td>286.408552</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.056937</td>\n",
       "      <td>9.914819</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetTorch_BAG_L3/T2</td>\n",
       "      <td>0.875320</td>\n",
       "      <td>0.874645</td>\n",
       "      <td>8.112207</td>\n",
       "      <td>11.118531</td>\n",
       "      <td>339.839060</td>\n",
       "      <td>0.739329</td>\n",
       "      <td>0.819011</td>\n",
       "      <td>27.709274</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetTorch_BAG_L2/T1</td>\n",
       "      <td>0.875013</td>\n",
       "      <td>0.873263</td>\n",
       "      <td>5.582727</td>\n",
       "      <td>7.183865</td>\n",
       "      <td>235.181222</td>\n",
       "      <td>1.105696</td>\n",
       "      <td>0.936960</td>\n",
       "      <td>30.512811</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM_BAG_L1/T1</td>\n",
       "      <td>0.874910</td>\n",
       "      <td>0.873288</td>\n",
       "      <td>0.207766</td>\n",
       "      <td>0.380227</td>\n",
       "      <td>3.210361</td>\n",
       "      <td>0.207766</td>\n",
       "      <td>0.380227</td>\n",
       "      <td>3.210361</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM_BAG_L2/T3</td>\n",
       "      <td>0.874910</td>\n",
       "      <td>0.874415</td>\n",
       "      <td>4.622298</td>\n",
       "      <td>6.456453</td>\n",
       "      <td>208.514598</td>\n",
       "      <td>0.145268</td>\n",
       "      <td>0.209549</td>\n",
       "      <td>3.846187</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CatBoost_BAG_L3/T1</td>\n",
       "      <td>0.874808</td>\n",
       "      <td>0.875771</td>\n",
       "      <td>7.429229</td>\n",
       "      <td>10.415279</td>\n",
       "      <td>337.218210</td>\n",
       "      <td>0.056351</td>\n",
       "      <td>0.115759</td>\n",
       "      <td>25.088424</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBM_BAG_L1/T2</td>\n",
       "      <td>0.874706</td>\n",
       "      <td>0.874338</td>\n",
       "      <td>0.208750</td>\n",
       "      <td>0.333238</td>\n",
       "      <td>2.681744</td>\n",
       "      <td>0.208750</td>\n",
       "      <td>0.333238</td>\n",
       "      <td>2.681744</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WeightedEnsemble_L4</td>\n",
       "      <td>0.874501</td>\n",
       "      <td>0.876001</td>\n",
       "      <td>9.943621</td>\n",
       "      <td>13.653987</td>\n",
       "      <td>414.556287</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.058871</td>\n",
       "      <td>10.036003</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBM_BAG_L3/T2</td>\n",
       "      <td>0.874399</td>\n",
       "      <td>0.875131</td>\n",
       "      <td>7.479229</td>\n",
       "      <td>10.408600</td>\n",
       "      <td>315.110751</td>\n",
       "      <td>0.106352</td>\n",
       "      <td>0.109080</td>\n",
       "      <td>2.980965</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBM_BAG_L1/T3</td>\n",
       "      <td>0.874296</td>\n",
       "      <td>0.872495</td>\n",
       "      <td>0.243452</td>\n",
       "      <td>0.424122</td>\n",
       "      <td>3.523225</td>\n",
       "      <td>0.243452</td>\n",
       "      <td>0.424122</td>\n",
       "      <td>3.523225</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LightGBM_BAG_L3/T5</td>\n",
       "      <td>0.874194</td>\n",
       "      <td>0.874926</td>\n",
       "      <td>7.502532</td>\n",
       "      <td>10.460410</td>\n",
       "      <td>315.522188</td>\n",
       "      <td>0.129654</td>\n",
       "      <td>0.160890</td>\n",
       "      <td>3.392403</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LightGBM_BAG_L3/T3</td>\n",
       "      <td>0.873887</td>\n",
       "      <td>0.874978</td>\n",
       "      <td>7.503123</td>\n",
       "      <td>10.439641</td>\n",
       "      <td>315.948419</td>\n",
       "      <td>0.130246</td>\n",
       "      <td>0.140121</td>\n",
       "      <td>3.818633</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LightGBM_BAG_L1/T5</td>\n",
       "      <td>0.873682</td>\n",
       "      <td>0.871523</td>\n",
       "      <td>0.208398</td>\n",
       "      <td>0.356232</td>\n",
       "      <td>3.529536</td>\n",
       "      <td>0.208398</td>\n",
       "      <td>0.356232</td>\n",
       "      <td>3.529536</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForest_BAG_L2/T1</td>\n",
       "      <td>0.872454</td>\n",
       "      <td>0.874466</td>\n",
       "      <td>4.708894</td>\n",
       "      <td>7.311350</td>\n",
       "      <td>211.612840</td>\n",
       "      <td>0.231863</td>\n",
       "      <td>1.064445</td>\n",
       "      <td>6.944429</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForest_BAG_L3/T1</td>\n",
       "      <td>0.871839</td>\n",
       "      <td>0.872777</td>\n",
       "      <td>7.632092</td>\n",
       "      <td>11.512689</td>\n",
       "      <td>319.366928</td>\n",
       "      <td>0.259214</td>\n",
       "      <td>1.213169</td>\n",
       "      <td>7.237143</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForest_BAG_L1/T1</td>\n",
       "      <td>0.866824</td>\n",
       "      <td>0.863742</td>\n",
       "      <td>0.293873</td>\n",
       "      <td>1.394450</td>\n",
       "      <td>3.821753</td>\n",
       "      <td>0.293873</td>\n",
       "      <td>1.394450</td>\n",
       "      <td>3.821753</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T1</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.847926</td>\n",
       "      <td>1.483267</td>\n",
       "      <td>1.408864</td>\n",
       "      <td>32.156450</td>\n",
       "      <td>1.483267</td>\n",
       "      <td>1.408864</td>\n",
       "      <td>32.156450</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T3</td>\n",
       "      <td>0.850957</td>\n",
       "      <td>0.848028</td>\n",
       "      <td>0.842502</td>\n",
       "      <td>0.617082</td>\n",
       "      <td>28.106969</td>\n",
       "      <td>0.842502</td>\n",
       "      <td>0.617082</td>\n",
       "      <td>28.106969</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T2</td>\n",
       "      <td>0.846555</td>\n",
       "      <td>0.843856</td>\n",
       "      <td>0.725487</td>\n",
       "      <td>0.910513</td>\n",
       "      <td>34.302268</td>\n",
       "      <td>0.725487</td>\n",
       "      <td>0.910513</td>\n",
       "      <td>34.302268</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LightGBM_BAG_L3/T4</td>\n",
       "      <td>0.845941</td>\n",
       "      <td>0.845750</td>\n",
       "      <td>7.512534</td>\n",
       "      <td>10.488720</td>\n",
       "      <td>315.571300</td>\n",
       "      <td>0.139657</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>3.441514</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LightGBM_BAG_L2/T4</td>\n",
       "      <td>0.837547</td>\n",
       "      <td>0.839224</td>\n",
       "      <td>4.626174</td>\n",
       "      <td>6.444669</td>\n",
       "      <td>208.234509</td>\n",
       "      <td>0.149144</td>\n",
       "      <td>0.197764</td>\n",
       "      <td>3.566098</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LightGBM_BAG_L1/T4</td>\n",
       "      <td>0.820760</td>\n",
       "      <td>0.821411</td>\n",
       "      <td>0.163656</td>\n",
       "      <td>0.256358</td>\n",
       "      <td>3.141349</td>\n",
       "      <td>0.163656</td>\n",
       "      <td>0.256358</td>\n",
       "      <td>3.141349</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  score_test  score_val  pred_time_test  \\\n",
       "0         LightGBM_BAG_L2/T1    0.876344   0.873647        4.607929   \n",
       "1         LightGBM_BAG_L2/T5    0.876241   0.873519        4.621554   \n",
       "2         CatBoost_BAG_L2/T1    0.876036   0.875259        4.536136   \n",
       "3   NeuralNetTorch_BAG_L2/T2    0.876036   0.873800        5.286805   \n",
       "4         LightGBM_BAG_L2/T2    0.875934   0.874594        4.596604   \n",
       "5   NeuralNetTorch_BAG_L3/T1    0.875729   0.874389        8.779307   \n",
       "6         LightGBM_BAG_L3/T1    0.875627   0.875234        7.513283   \n",
       "7         CatBoost_BAG_L1/T1    0.875525   0.874415        0.099878   \n",
       "8        WeightedEnsemble_L2    0.875525   0.874415        0.101681   \n",
       "9        WeightedEnsemble_L3    0.875525   0.875797        6.286457   \n",
       "10  NeuralNetTorch_BAG_L3/T2    0.875320   0.874645        8.112207   \n",
       "11  NeuralNetTorch_BAG_L2/T1    0.875013   0.873263        5.582727   \n",
       "12        LightGBM_BAG_L1/T1    0.874910   0.873288        0.207766   \n",
       "13        LightGBM_BAG_L2/T3    0.874910   0.874415        4.622298   \n",
       "14        CatBoost_BAG_L3/T1    0.874808   0.875771        7.429229   \n",
       "15        LightGBM_BAG_L1/T2    0.874706   0.874338        0.208750   \n",
       "16       WeightedEnsemble_L4    0.874501   0.876001        9.943621   \n",
       "17        LightGBM_BAG_L3/T2    0.874399   0.875131        7.479229   \n",
       "18        LightGBM_BAG_L1/T3    0.874296   0.872495        0.243452   \n",
       "19        LightGBM_BAG_L3/T5    0.874194   0.874926        7.502532   \n",
       "20        LightGBM_BAG_L3/T3    0.873887   0.874978        7.503123   \n",
       "21        LightGBM_BAG_L1/T5    0.873682   0.871523        0.208398   \n",
       "22    RandomForest_BAG_L2/T1    0.872454   0.874466        4.708894   \n",
       "23    RandomForest_BAG_L3/T1    0.871839   0.872777        7.632092   \n",
       "24    RandomForest_BAG_L1/T1    0.866824   0.863742        0.293873   \n",
       "25  NeuralNetTorch_BAG_L1/T1    0.853414   0.847926        1.483267   \n",
       "26  NeuralNetTorch_BAG_L1/T3    0.850957   0.848028        0.842502   \n",
       "27  NeuralNetTorch_BAG_L1/T2    0.846555   0.843856        0.725487   \n",
       "28        LightGBM_BAG_L3/T4    0.845941   0.845750        7.512534   \n",
       "29        LightGBM_BAG_L2/T4    0.837547   0.839224        4.626174   \n",
       "30        LightGBM_BAG_L1/T4    0.820760   0.821411        0.163656   \n",
       "\n",
       "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        6.392114  207.766691                 0.130898   \n",
       "1        6.435337  208.331747                 0.144523   \n",
       "2        6.349077  228.112616                 0.059106   \n",
       "3        7.319544  233.640086                 0.809774   \n",
       "4        6.382348  208.082765                 0.119574   \n",
       "5       11.338098  341.504479                 1.406430   \n",
       "6       10.468890  315.592884                 0.140405   \n",
       "7        0.165818   90.194755                 0.099878   \n",
       "8        0.224807  101.035081                 0.001802   \n",
       "9        8.940844  286.408552                 0.003397   \n",
       "10      11.118531  339.839060                 0.739329   \n",
       "11       7.183865  235.181222                 1.105696   \n",
       "12       0.380227    3.210361                 0.207766   \n",
       "13       6.456453  208.514598                 0.145268   \n",
       "14      10.415279  337.218210                 0.056351   \n",
       "15       0.333238    2.681744                 0.208750   \n",
       "16      13.653987  414.556287                 0.003067   \n",
       "17      10.408600  315.110751                 0.106352   \n",
       "18       0.424122    3.523225                 0.243452   \n",
       "19      10.460410  315.522188                 0.129654   \n",
       "20      10.439641  315.948419                 0.130246   \n",
       "21       0.356232    3.529536                 0.208398   \n",
       "22       7.311350  211.612840                 0.231863   \n",
       "23      11.512689  319.366928                 0.259214   \n",
       "24       1.394450    3.821753                 0.293873   \n",
       "25       1.408864   32.156450                 1.483267   \n",
       "26       0.617082   28.106969                 0.842502   \n",
       "27       0.910513   34.302268                 0.725487   \n",
       "28      10.488720  315.571300                 0.139657   \n",
       "29       6.444669  208.234509                 0.149144   \n",
       "30       0.256358    3.141349                 0.163656   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.145210           3.098280            2       True   \n",
       "1                 0.188432           3.663336            2       True   \n",
       "2                 0.102173          23.444205            2       True   \n",
       "3                 1.072639          28.971675            2       True   \n",
       "4                 0.135443           3.414354            2       True   \n",
       "5                 1.038578          29.374693            3       True   \n",
       "6                 0.169370           3.463098            3       True   \n",
       "7                 0.165818          90.194755            1       True   \n",
       "8                 0.058988          10.840326            2       True   \n",
       "9                 0.056937           9.914819            3       True   \n",
       "10                0.819011          27.709274            3       True   \n",
       "11                0.936960          30.512811            2       True   \n",
       "12                0.380227           3.210361            1       True   \n",
       "13                0.209549           3.846187            2       True   \n",
       "14                0.115759          25.088424            3       True   \n",
       "15                0.333238           2.681744            1       True   \n",
       "16                0.058871          10.036003            4       True   \n",
       "17                0.109080           2.980965            3       True   \n",
       "18                0.424122           3.523225            1       True   \n",
       "19                0.160890           3.392403            3       True   \n",
       "20                0.140121           3.818633            3       True   \n",
       "21                0.356232           3.529536            1       True   \n",
       "22                1.064445           6.944429            2       True   \n",
       "23                1.213169           7.237143            3       True   \n",
       "24                1.394450           3.821753            1       True   \n",
       "25                1.408864          32.156450            1       True   \n",
       "26                0.617082          28.106969            1       True   \n",
       "27                0.910513          34.302268            1       True   \n",
       "28                0.189200           3.441514            3       True   \n",
       "29                0.197764           3.566098            2       True   \n",
       "30                0.256358           3.141349            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          12  \n",
       "1          16  \n",
       "2          18  \n",
       "3          20  \n",
       "4          13  \n",
       "5          29  \n",
       "6          22  \n",
       "7           7  \n",
       "8          11  \n",
       "9          21  \n",
       "10         30  \n",
       "11         19  \n",
       "12          1  \n",
       "13         14  \n",
       "14         28  \n",
       "15          2  \n",
       "16         31  \n",
       "17         23  \n",
       "18          3  \n",
       "19         26  \n",
       "20         24  \n",
       "21          5  \n",
       "22         17  \n",
       "23         27  \n",
       "24          6  \n",
       "25          8  \n",
       "26         10  \n",
       "27          9  \n",
       "28         25  \n",
       "29         15  \n",
       "30          4  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf9ac2",
   "metadata": {},
   "source": [
    "#### Extra automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cf9d51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221019_120848/\"\n",
      "Presets specified: ['best_quality']\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221019_120848/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    39073\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' <=50K', ' >50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3810.2 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.92 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.19 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 4 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 16.87s of the 599.74s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c26bcde77c49d5ae8a0c767d8117c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.125281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM_BAG_L1/T1 ...\n",
      "\t0.8747\t = Validation score   (accuracy)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T2 ...\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T3 ...\n",
      "\t0.8755\t = Validation score   (accuracy)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T4 ...\n",
      "\t0.8747\t = Validation score   (accuracy)\n",
      "\t4.68s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T5 ...\n",
      "\t0.8759\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest_BAG_L1 ... Tuning model for up to 16.87s of the 589.61s of remaining time.\n",
      "\tNo hyperparameter search space specified for RandomForest. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "Warning: Exception caused RandomForest_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1380, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1001, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 182, in _hyperparameter_tune\n",
      "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1080, in _hyperparameter_tune\n",
      "    model_path = model_info['path']\n",
      "TypeError: string indices must be integers\n",
      "string indices must be integers\n",
      "Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 16.87s of the 583.28s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fb10244a3e404c8ae9e1287ceb0afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 381.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L1/T1 ...\n",
      "\t0.8743\t = Validation score   (accuracy)\n",
      "\t13.43s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 16.87s of the 569.74s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "2022-10-19 12:09:33,280\tINFO stopper.py:363 -- Reached timeout of 13.494065542817118 seconds. Stopping all trials.\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T1 ...\n",
      "\t0.8485\t = Validation score   (accuracy)\n",
      "\t9.56s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T2 ...\n",
      "\t0.8506\t = Validation score   (accuracy)\n",
      "\t10.0s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T3 ...\n",
      "\t0.8356\t = Validation score   (accuracy)\n",
      "\t8.2s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T4 ...\n",
      "\t0.8346\t = Validation score   (accuracy)\n",
      "\t6.04s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 554.42s of the 554.42s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t8.5s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 544.33s of the 544.33s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t8.76s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T3 ... Training model for up to 533.92s of the 533.92s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.874\t = Validation score   (accuracy)\n",
      "\t9.1s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T4 ... Training model for up to 523.05s of the 523.05s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8738\t = Validation score   (accuracy)\n",
      "\t25.71s\t = Training   runtime\n",
      "\t4.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T5 ... Training model for up to 498.84s of the 498.84s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8746\t = Validation score   (accuracy)\n",
      "\t8.64s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1/T1 ... Training model for up to 488.35s of the 488.35s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8736\t = Validation score   (accuracy)\n",
      "\t128.01s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T1 ... Training model for up to 371.24s of the 371.24s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8581\t = Validation score   (accuracy)\n",
      "\t163.84s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T2 ... Training model for up to 214.43s of the 214.43s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8551\t = Validation score   (accuracy)\n",
      "\t144.76s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T3 ... Training model for up to 77.15s of the 77.15s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8479\t = Validation score   (accuracy)\n",
      "\t74.56s\t = Training   runtime\n",
      "\t2.94s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T4 ... Training model for up to 8.05s of the 8.05s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1/T4.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 0.41s of remaining time.\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t9.8s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 609.47s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221019_120848/\")\n"
     ]
    }
   ],
   "source": [
    "nn_options = {}\n",
    "gbm_options = {}\n",
    "rf_options = {}\n",
    "cat_options = {}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                   'RF': rf_options,\n",
    "                   'CAT': cat_options,\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 10*60  # train various models for ~2 min\n",
    "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric='acc').fit(\n",
    "    train_data, time_limit=time_limit, auto_stack=True, presets='best_quality',\n",
    "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ba45c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8749104309550619\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8749104309550619\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "874f428c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L1/T1</td>\n",
       "      <td>0.876446</td>\n",
       "      <td>0.873647</td>\n",
       "      <td>0.145938</td>\n",
       "      <td>0.252939</td>\n",
       "      <td>128.013721</td>\n",
       "      <td>0.145938</td>\n",
       "      <td>0.252939</td>\n",
       "      <td>128.013721</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L1/T1</td>\n",
       "      <td>0.876036</td>\n",
       "      <td>0.874543</td>\n",
       "      <td>0.416960</td>\n",
       "      <td>0.577250</td>\n",
       "      <td>8.500129</td>\n",
       "      <td>0.416960</td>\n",
       "      <td>0.577250</td>\n",
       "      <td>8.500129</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L1/T4</td>\n",
       "      <td>0.875525</td>\n",
       "      <td>0.873800</td>\n",
       "      <td>2.969287</td>\n",
       "      <td>4.153718</td>\n",
       "      <td>25.714271</td>\n",
       "      <td>2.969287</td>\n",
       "      <td>4.153718</td>\n",
       "      <td>25.714271</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L1/T3</td>\n",
       "      <td>0.875422</td>\n",
       "      <td>0.873979</td>\n",
       "      <td>0.457224</td>\n",
       "      <td>0.593544</td>\n",
       "      <td>9.099113</td>\n",
       "      <td>0.457224</td>\n",
       "      <td>0.593544</td>\n",
       "      <td>9.099113</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1/T2</td>\n",
       "      <td>0.875320</td>\n",
       "      <td>0.874850</td>\n",
       "      <td>0.410834</td>\n",
       "      <td>0.473358</td>\n",
       "      <td>8.757940</td>\n",
       "      <td>0.410834</td>\n",
       "      <td>0.473358</td>\n",
       "      <td>8.757940</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.874910</td>\n",
       "      <td>0.874978</td>\n",
       "      <td>5.659217</td>\n",
       "      <td>6.664397</td>\n",
       "      <td>225.251606</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.058712</td>\n",
       "      <td>9.797962</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_BAG_L1/T5</td>\n",
       "      <td>0.874194</td>\n",
       "      <td>0.874568</td>\n",
       "      <td>0.390232</td>\n",
       "      <td>0.475660</td>\n",
       "      <td>8.644814</td>\n",
       "      <td>0.390232</td>\n",
       "      <td>0.475660</td>\n",
       "      <td>8.644814</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T1</td>\n",
       "      <td>0.862217</td>\n",
       "      <td>0.858061</td>\n",
       "      <td>1.468261</td>\n",
       "      <td>0.925699</td>\n",
       "      <td>163.836490</td>\n",
       "      <td>1.468261</td>\n",
       "      <td>0.925699</td>\n",
       "      <td>163.836490</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T2</td>\n",
       "      <td>0.859863</td>\n",
       "      <td>0.855066</td>\n",
       "      <td>1.344663</td>\n",
       "      <td>0.980691</td>\n",
       "      <td>144.756043</td>\n",
       "      <td>1.344663</td>\n",
       "      <td>0.980691</td>\n",
       "      <td>144.756043</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T3</td>\n",
       "      <td>0.854028</td>\n",
       "      <td>0.847874</td>\n",
       "      <td>4.660900</td>\n",
       "      <td>2.944922</td>\n",
       "      <td>74.556832</td>\n",
       "      <td>4.660900</td>\n",
       "      <td>2.944922</td>\n",
       "      <td>74.556832</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T4</td>\n",
       "      <td>0.844303</td>\n",
       "      <td>0.834596</td>\n",
       "      <td>0.255812</td>\n",
       "      <td>0.125445</td>\n",
       "      <td>6.041662</td>\n",
       "      <td>0.255812</td>\n",
       "      <td>0.125445</td>\n",
       "      <td>6.041662</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  score_test  score_val  pred_time_test  \\\n",
       "0         CatBoost_BAG_L1/T1    0.876446   0.873647        0.145938   \n",
       "1         LightGBM_BAG_L1/T1    0.876036   0.874543        0.416960   \n",
       "2         LightGBM_BAG_L1/T4    0.875525   0.873800        2.969287   \n",
       "3         LightGBM_BAG_L1/T3    0.875422   0.873979        0.457224   \n",
       "4         LightGBM_BAG_L1/T2    0.875320   0.874850        0.410834   \n",
       "5        WeightedEnsemble_L2    0.874910   0.874978        5.659217   \n",
       "6         LightGBM_BAG_L1/T5    0.874194   0.874568        0.390232   \n",
       "7   NeuralNetTorch_BAG_L1/T1    0.862217   0.858061        1.468261   \n",
       "8   NeuralNetTorch_BAG_L1/T2    0.859863   0.855066        1.344663   \n",
       "9   NeuralNetTorch_BAG_L1/T3    0.854028   0.847874        4.660900   \n",
       "10  NeuralNetTorch_BAG_L1/T4    0.844303   0.834596        0.255812   \n",
       "\n",
       "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        0.252939  128.013721                 0.145938   \n",
       "1        0.577250    8.500129                 0.416960   \n",
       "2        4.153718   25.714271                 2.969287   \n",
       "3        0.593544    9.099113                 0.457224   \n",
       "4        0.473358    8.757940                 0.410834   \n",
       "5        6.664397  225.251606                 0.003643   \n",
       "6        0.475660    8.644814                 0.390232   \n",
       "7        0.925699  163.836490                 1.468261   \n",
       "8        0.980691  144.756043                 1.344663   \n",
       "9        2.944922   74.556832                 4.660900   \n",
       "10       0.125445    6.041662                 0.255812   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.252939         128.013721            1       True   \n",
       "1                 0.577250           8.500129            1       True   \n",
       "2                 4.153718          25.714271            1       True   \n",
       "3                 0.593544           9.099113            1       True   \n",
       "4                 0.473358           8.757940            1       True   \n",
       "5                 0.058712           9.797962            2       True   \n",
       "6                 0.475660           8.644814            1       True   \n",
       "7                 0.925699         163.836490            1       True   \n",
       "8                 0.980691         144.756043            1       True   \n",
       "9                 2.944922          74.556832            1       True   \n",
       "10                0.125445           6.041662            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           6  \n",
       "1           1  \n",
       "2           4  \n",
       "3           3  \n",
       "4           2  \n",
       "5          11  \n",
       "6           5  \n",
       "7           7  \n",
       "8           8  \n",
       "9           9  \n",
       "10         10  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ceab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
