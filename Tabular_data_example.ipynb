{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a562fd",
   "metadata": {},
   "source": [
    "# AWS Re:Invent  Autogluon Workshop\n",
    "### This workshop will demonstrate a machine learning problem solved by autogluon.\n",
    "* Use the documentation of autogluon and the different tutorials [here](https://auto.gluon.ai/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c015423a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (22.3)\n",
      "Collecting pip\n",
      "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.3\n",
      "    Uninstalling pip-22.3:\n",
      "      Successfully uninstalled pip-22.3\n",
      "Successfully installed pip-22.3.1\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (65.5.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-65.6.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (0.37.1)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.37.1\n",
      "    Uninstalling wheel-0.37.1:\n",
      "      Successfully uninstalled wheel-0.37.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.0\n",
      "    Uninstalling setuptools-65.5.0:\n",
      "      Successfully uninstalled setuptools-65.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-project 0.10.2 requires ruamel-yaml, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed setuptools-65.6.0 wheel-0.38.4\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch==1.12.0+cu113 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (1.12.0+cu113)\n",
      "Requirement already satisfied: torchvision==0.13.0+cu113 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (0.13.0+cu113)\n",
      "Requirement already satisfied: torchtext==0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (0.13.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from torch==1.12.0+cu113) (4.0.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from torchvision==0.13.0+cu113) (1.21.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from torchvision==0.13.0+cu113) (2.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from torchvision==0.13.0+cu113) (9.0.1)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from torchtext==0.13.0) (4.62.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->torchvision==0.13.0+cu113) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->torchvision==0.13.0+cu113) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->torchvision==0.13.0+cu113) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->torchvision==0.13.0+cu113) (2021.10.8)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: mxnet_cu101<2.0.0,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (1.9.1)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from mxnet_cu101<2.0.0,>=1.7.0) (0.8.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from mxnet_cu101<2.0.0,>=1.7.0) (1.21.2)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from mxnet_cu101<2.0.0,>=1.7.0) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet_cu101<2.0.0,>=1.7.0) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet_cu101<2.0.0,>=1.7.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet_cu101<2.0.0,>=1.7.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet_cu101<2.0.0,>=1.7.0) (3.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: autogluon in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (0.5.2)\n",
      "Requirement already satisfied: autogluon.features==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: autogluon.core[all]==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: autogluon.tabular[all]==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: autogluon.vision==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: autogluon.multimodal==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: autogluon.text==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: autogluon.timeseries[all]==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (4.62.3)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (1.24.90)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (3.5.0)\n",
      "Requirement already satisfied: autogluon.common==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (0.5.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (2.26.0)\n",
      "Requirement already satisfied: numpy<1.23,>=1.21 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (1.21.2)\n",
      "Requirement already satisfied: scipy<1.8.0,>=1.5.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (1.7.2)\n",
      "Requirement already satisfied: distributed<=2021.11.2,>=2021.09.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (2021.11.2)\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.5,>=1.2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (1.3.4)\n",
      "Requirement already satisfied: scikit-learn<1.1,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (1.0.1)\n",
      "Requirement already satisfied: dask<=2021.11.2,>=2021.09.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (2021.11.2)\n",
      "Requirement already satisfied: ray<1.14,>=1.13 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (1.13.0)\n",
      "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (0.2.7)\n",
      "Requirement already satisfied: psutil<6,>=5.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.features==0.5.2->autogluon) (5.8.0)\n",
      "Requirement already satisfied: transformers<4.21.0,>=4.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (4.20.1)\n",
      "Requirement already satisfied: omegaconf<2.2.0,>=2.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (2.1.2)\n",
      "Requirement already satisfied: torch<1.13,>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (1.12.0+cu113)\n",
      "Requirement already satisfied: Pillow<9.1.0,>=9.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (9.0.1)\n",
      "Requirement already satisfied: torchmetrics<0.8.0,>=0.7.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.7.3)\n",
      "Requirement already satisfied: nptyping<1.5.0,>=1.4.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (1.4.4)\n",
      "Requirement already satisfied: timm<0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.5.4)\n",
      "Requirement already satisfied: sentencepiece<0.2.0,>=0.1.95 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.1.95)\n",
      "Requirement already satisfied: protobuf<=3.18.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (3.18.1)\n",
      "Requirement already satisfied: nlpaug<=1.1.10,>=1.1.10 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (1.1.10)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (3.6.5)\n",
      "Requirement already satisfied: pytorch-metric-learning<1.4.0,>=1.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (1.3.2)\n",
      "Requirement already satisfied: smart-open<5.3.0,>=5.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (5.2.1)\n",
      "Requirement already satisfied: scikit-image<0.20.0,>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.19.3)\n",
      "Requirement already satisfied: torchtext<0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.13.0)\n",
      "Requirement already satisfied: pytorch-lightning<1.7.0,>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (1.6.5)\n",
      "Requirement already satisfied: fairscale<=0.4.6,>=0.4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.4.6)\n",
      "Requirement already satisfied: torchvision<0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.13.0+cu113)\n",
      "Requirement already satisfied: networkx<3.0,>=2.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.tabular[all]==0.5.2->autogluon) (2.6.3)\n",
      "Requirement already satisfied: fastai<2.8,>=2.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.tabular[all]==0.5.2->autogluon) (2.7.9)\n",
      "Requirement already satisfied: xgboost<1.5,>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.tabular[all]==0.5.2->autogluon) (1.4.2)\n",
      "Requirement already satisfied: catboost<1.1,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.tabular[all]==0.5.2->autogluon) (1.0.6)\n",
      "Requirement already satisfied: lightgbm<3.4,>=3.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.tabular[all]==0.5.2->autogluon) (3.3.3)\n",
      "Requirement already satisfied: autogluon-contrib-nlp==0.0.1b20220208 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.text==0.5.2->autogluon) (0.0.1b20220208)\n",
      "Requirement already satisfied: gluonts<0.10.0,>=0.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.timeseries[all]==0.5.2->autogluon) (0.9.9)\n",
      "Requirement already satisfied: pmdarima~=1.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.timeseries[all]==0.5.2->autogluon) (1.8.5)\n",
      "Requirement already satisfied: tbats~=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.timeseries[all]==0.5.2->autogluon) (1.1.1)\n",
      "Requirement already satisfied: sktime~=0.11.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.timeseries[all]==0.5.2->autogluon) (0.11.4)\n",
      "Requirement already satisfied: gluoncv<0.10.6,>=0.10.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.vision==0.5.2->autogluon) (0.10.5.post0)\n",
      "Requirement already satisfied: sacrebleu in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (2.3.1)\n",
      "Requirement already satisfied: pyarrow in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (7.0.0)\n",
      "Requirement already satisfied: contextvars in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (2.4)\n",
      "Requirement already satisfied: tokenizers>=0.9.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (0.12.1)\n",
      "Requirement already satisfied: sacremoses>=0.0.38 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (0.0.53)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (2021.11.10)\n",
      "Requirement already satisfied: yacs>=0.1.6 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (0.1.8)\n",
      "Requirement already satisfied: flake8 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (3.8.4)\n",
      "Requirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.2->autogluon) (5.6.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.2->autogluon) (1.16.0)\n",
      "Requirement already satisfied: graphviz in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.2->autogluon) (0.8.4)\n",
      "Requirement already satisfied: partd>=0.3.10 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (21.3)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (5.4.1)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (0.11.2)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2021.11.1)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.4.0)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (3.0.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (65.6.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.7.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (6.1)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.0.3)\n",
      "Requirement already satisfied: zict>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.0.0)\n",
      "Requirement already satisfied: click>=6.6 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (8.0.3)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (1.0.2)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.0.7)\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (22.3.1)\n",
      "Requirement already satisfied: spacy<4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (3.2.3)\n",
      "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (1.5.27)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.5.2->autogluon) (2.6.0)\n",
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.5.2->autogluon) (4.5.1.48)\n",
      "Requirement already satisfied: autocfg in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.5.2->autogluon) (0.0.8)\n",
      "Requirement already satisfied: pydantic~=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (4.0.0)\n",
      "Requirement already satisfied: holidays>=0.9 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (0.16)\n",
      "Requirement already satisfied: py4j in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.5.2->autogluon) (0.10.9.5)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.5.2->autogluon) (0.18.2)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.5.2->autogluon) (0.38.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (4.28.2)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.5.2->autogluon) (1.1.0)\n",
      "Requirement already satisfied: typish>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nptyping<1.5.0,>=1.4.4->autogluon.multimodal==0.5.2->autogluon) (1.9.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from omegaconf<2.2.0,>=2.1.1->autogluon.multimodal==0.5.2->autogluon) (4.8)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pandas!=1.4.0,<1.5,>=1.2.5->autogluon.core[all]==0.5.2->autogluon) (2021.3)\n",
      "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.5.2->autogluon) (0.29.24)\n",
      "Requirement already satisfied: statsmodels!=0.12.0,>=0.11 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.5.2->autogluon) (0.13.1)\n",
      "Requirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.5.2->autogluon) (1.26.8)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.3.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (2.10.1)\n",
      "Requirement already satisfied: frozenlist in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (1.2.0)\n",
      "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (1.43.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (3.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (3.8.0)\n",
      "Requirement already satisfied: aiosignal in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (1.2.0)\n",
      "Requirement already satisfied: virtualenv in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (20.16.5)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (21.2.0)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (0.8.9)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (2.5.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->autogluon.core[all]==0.5.2->autogluon) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->autogluon.core[all]==0.5.2->autogluon) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->autogluon.core[all]==0.5.2->autogluon) (3.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.5.2->autogluon) (1.2.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.5.2->autogluon) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.5.2->autogluon) (2021.11.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-learn<1.1,>=1.0.0->autogluon.core[all]==0.5.2->autogluon) (3.0.0)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sktime~=0.11.4->autogluon.timeseries[all]==0.5.2->autogluon) (1.2.13)\n",
      "Requirement already satisfied: numba>=0.53 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sktime~=0.11.4->autogluon.timeseries[all]==0.5.2->autogluon) (0.53.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers<4.21.0,>=4.18.0->autogluon.multimodal==0.5.2->autogluon) (0.10.1)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.90 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from boto3->autogluon.core[all]==0.5.2->autogluon) (1.27.95)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from boto3->autogluon.core[all]==0.5.2->autogluon) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from boto3->autogluon.core[all]==0.5.2->autogluon) (0.10.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from deprecated>=1.2.13->sktime~=0.11.4->autogluon.timeseries[all]==0.5.2->autogluon) (1.13.3)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (3.8.1)\n",
      "Requirement already satisfied: convertdate>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from holidays>=0.9->gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (2.4.0)\n",
      "Requirement already satisfied: korean-lunar-calendar in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from holidays>=0.9->gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (0.3.1)\n",
      "Requirement already satisfied: hijri-converter in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from holidays>=0.9->gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (2.2.4)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from numba>=0.53->sktime~=0.11.4->autogluon.timeseries[all]==0.5.2->autogluon) (0.36.0)\n",
      "Requirement already satisfied: locket in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from partd>=0.3.10->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (0.2.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (1.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.7.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (3.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.4.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (8.0.15)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.9.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (2.4.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.6.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (1.0.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (2.0.6)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from statsmodels!=0.12.0,>=0.11->pmdarima~=1.8.2->autogluon.timeseries[all]==0.5.2->autogluon) (0.5.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (2.0.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (1.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (2.13.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.4.6)\n",
      "Requirement already satisfied: heapdict in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from zict>=0.1.3->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.0.1)\n",
      "Requirement already satisfied: immutables>=0.9 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from contextvars->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (0.19)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (2.6.0)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (2.2.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (0.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jinja2->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.0.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jsonschema->ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (0.18.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from plotly->catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.2->autogluon) (8.0.1)\n",
      "Requirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (0.4.3)\n",
      "Requirement already satisfied: lxml in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (4.8.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from virtualenv->ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (0.3.6)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from virtualenv->ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (2.5.2)\n",
      "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from convertdate>=2.3.0->holidays>=0.9->gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (0.5.11)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (4.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.7.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (5.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# Installation\n",
    "!pip3 install -U pip\n",
    "!pip3 install -U setuptools wheel\n",
    "\n",
    "# Install the proper version of PyTorch following https://pytorch.org/get-started/locally/\n",
    "!pip3 install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchtext==0.13.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "\n",
    "!pip3 install \"mxnet_cu101<2.0.0, >=1.7.0\"    \n",
    "    \n",
    "!pip3 install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb13cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7a1084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt      education  education-num  \\\n",
       "6118    51   Private   39264   Some-college             10   \n",
       "23204   58   Private   51662           10th              6   \n",
       "29590   40   Private  326310   Some-college             10   \n",
       "18116   37   Private  222450        HS-grad              9   \n",
       "33964   62   Private  109190      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54fe23c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count        500\n",
      "unique         2\n",
      "top        <=50K\n",
      "freq         365\n",
      "Name: class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "label = 'class'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38543fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221122_095451/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221122_095451/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    691.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.73\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.65\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.81\t = Validation score   (accuracy)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t3.25s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t2.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.0s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221122_095451/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f9d8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>169085</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>226203</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>54260</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>176262</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>241185</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt      education  education-num  \\\n",
       "0   31            Private  169085           11th              7   \n",
       "1   17   Self-emp-not-inc  226203           12th              8   \n",
       "2   47            Private   54260      Assoc-voc             11   \n",
       "3   21            Private  176262   Some-college             10   \n",
       "4   17            Private  241185           12th              8   \n",
       "\n",
       "        marital-status        occupation relationship    race      sex  \\\n",
       "0   Married-civ-spouse             Sales         Wife   White   Female   \n",
       "1        Never-married             Sales    Own-child   White     Male   \n",
       "2   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n",
       "3        Never-married   Exec-managerial    Own-child   White   Female   \n",
       "4        Never-married    Prof-specialty    Own-child   White     Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0             0             0              20   United-States  \n",
       "1             0             0              45   United-States  \n",
       "2             0          1887              60   United-States  \n",
       "3             0             0              30   United-States  \n",
       "4             0             0              20   United-States  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "y_test = test_data[label]  # values to predict\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7140979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8374449790152523\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8374449790152523\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbcdd3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8374449790152523\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8374449790152523\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8374449790152523}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c5dd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.842973</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.157144</td>\n",
       "      <td>0.061006</td>\n",
       "      <td>0.583327</td>\n",
       "      <td>0.157144</td>\n",
       "      <td>0.061006</td>\n",
       "      <td>0.583327</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.037355</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>1.220509</td>\n",
       "      <td>0.037355</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>1.220509</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.841130</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.156240</td>\n",
       "      <td>0.059861</td>\n",
       "      <td>0.470254</td>\n",
       "      <td>0.156240</td>\n",
       "      <td>0.059861</td>\n",
       "      <td>0.470254</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.029294</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.252078</td>\n",
       "      <td>0.029294</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.252078</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.837445</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.224522</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.224522</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.837445</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.051539</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.620225</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.395703</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.836421</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>1.071510</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>1.071510</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.833453</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.166816</td>\n",
       "      <td>0.057844</td>\n",
       "      <td>0.468804</td>\n",
       "      <td>0.166816</td>\n",
       "      <td>0.057844</td>\n",
       "      <td>0.468804</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.832839</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.188453</td>\n",
       "      <td>0.058337</td>\n",
       "      <td>0.463114</td>\n",
       "      <td>0.188453</td>\n",
       "      <td>0.058337</td>\n",
       "      <td>0.463114</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.828949</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.033231</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>0.355061</td>\n",
       "      <td>0.033231</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>0.355061</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.818610</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.192446</td>\n",
       "      <td>0.019497</td>\n",
       "      <td>3.250093</td>\n",
       "      <td>0.192446</td>\n",
       "      <td>0.019497</td>\n",
       "      <td>3.250093</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.810523</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.155397</td>\n",
       "      <td>0.011746</td>\n",
       "      <td>2.658509</td>\n",
       "      <td>0.155397</td>\n",
       "      <td>0.011746</td>\n",
       "      <td>2.658509</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.725970</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.021930</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.021930</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.695158</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.028163</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.028163</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0      RandomForestGini    0.842973       0.84        0.157144       0.061006   \n",
       "1              CatBoost    0.842461       0.85        0.037355       0.009213   \n",
       "2      RandomForestEntr    0.841130       0.83        0.156240       0.059861   \n",
       "3              LightGBM    0.839799       0.85        0.029294       0.005735   \n",
       "4               XGBoost    0.837445       0.87        0.048340       0.007246   \n",
       "5   WeightedEnsemble_L2    0.837445       0.87        0.051539       0.007804   \n",
       "6            LightGBMXT    0.836421       0.83        0.017661       0.005626   \n",
       "7        ExtraTreesGini    0.833453       0.82        0.166816       0.057844   \n",
       "8        ExtraTreesEntr    0.832839       0.81        0.188453       0.058337   \n",
       "9         LightGBMLarge    0.828949       0.83        0.033231       0.006524   \n",
       "10      NeuralNetFastAI    0.818610       0.82        0.192446       0.019497   \n",
       "11       NeuralNetTorch    0.810523       0.85        0.155397       0.011746   \n",
       "12       KNeighborsUnif    0.725970       0.73        0.021930       0.006462   \n",
       "13       KNeighborsDist    0.695158       0.65        0.028163       0.004652   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.583327                 0.157144                0.061006   \n",
       "1   1.220509                 0.037355                0.009213   \n",
       "2   0.470254                 0.156240                0.059861   \n",
       "3   0.252078                 0.029294                0.005735   \n",
       "4   0.224522                 0.048340                0.007246   \n",
       "5   0.620225                 0.003199                0.000558   \n",
       "6   1.071510                 0.017661                0.005626   \n",
       "7   0.468804                 0.166816                0.057844   \n",
       "8   0.463114                 0.188453                0.058337   \n",
       "9   0.355061                 0.033231                0.006524   \n",
       "10  3.250093                 0.192446                0.019497   \n",
       "11  2.658509                 0.155397                0.011746   \n",
       "12  0.005832                 0.021930                0.006462   \n",
       "13  0.004138                 0.028163                0.004652   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.583327            1       True          5  \n",
       "1            1.220509            1       True          7  \n",
       "2            0.470254            1       True          6  \n",
       "3            0.252078            1       True          4  \n",
       "4            0.224522            1       True         11  \n",
       "5            0.395703            2       True         14  \n",
       "6            1.071510            1       True          3  \n",
       "7            0.468804            1       True          8  \n",
       "8            0.463114            1       True          9  \n",
       "9            0.355061            1       True         13  \n",
       "10           3.250093            1       True         10  \n",
       "11           2.658509            1       True         12  \n",
       "12           0.005832            1       True          1  \n",
       "13           0.004138            1       True          2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86294ce5",
   "metadata": {},
   "source": [
    "### Using hyperparameter settings\n",
    "#### You can find [here](https://auto.gluon.ai/dev/api/autogluon.tabular.models.html) some models and which hyperparameters you can set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d503770f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n"
     ]
    }
   ],
   "source": [
    "import autogluon.core as ag\n",
    "\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b638974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221122_095507/\"\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221122_095507/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    39073\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' <=50K', ' >50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    583.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.92 MB (3.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.19 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.127965602845955, Train Rows: 34073, Val Rows: 5000\n",
      "Fitting 4 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM ... Tuning model for up to 134.94s of the 599.72s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8532ea8737974f1c97b41570fd9987fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM/T1 ...\n",
      "\t0.8756\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM/T2 ...\n",
      "\t0.8764\t = Validation score   (accuracy)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM/T3 ...\n",
      "\t0.8756\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM/T4 ...\n",
      "\t0.8186\t = Validation score   (accuracy)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM/T5 ...\n",
      "\t0.8742\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest ... Tuning model for up to 134.94s of the 596.64s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2148ead5150b4759b9dc5c2e623af2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Reducing model 'n_estimators' from 400 -> 294 due to low memory. Expected memory usage reduced from 20.35% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 400 -> 193 due to low memory. Expected memory usage reduced from 30.96% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 400 -> 136 due to low memory. Expected memory usage reduced from 44.0% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 400 -> 134 due to low memory. Expected memory usage reduced from 44.63% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 400 -> 176 due to low memory. Expected memory usage reduced from 34.09% -> 15.0% of available memory...\n",
      "Fitted model: RandomForest/T1 ...\n",
      "\t0.8637\t = Validation score   (accuracy)\n",
      "\t2.94s\t = Training   runtime\n",
      "\t1.11s\t = Validation runtime\n",
      "Fitted model: RandomForest/T2 ...\n",
      "\t0.8608\t = Validation score   (accuracy)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitted model: RandomForest/T3 ...\n",
      "\t0.8546\t = Validation score   (accuracy)\n",
      "\t1.7s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitted model: RandomForest/T4 ...\n",
      "\t0.8547\t = Validation score   (accuracy)\n",
      "\t1.67s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitted model: RandomForest/T5 ...\n",
      "\t0.8587\t = Validation score   (accuracy)\n",
      "\t1.98s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Hyperparameter tuning model: CatBoost ... Tuning model for up to 134.94s of the 577.95s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c80b8b08534434eb7a434fff26b0ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: CatBoost/T1 ...\n",
      "\t0.8766\t = Validation score   (accuracy)\n",
      "\t12.52s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: CatBoost/T2 ...\n",
      "\t0.877\t = Validation score   (accuracy)\n",
      "\t5.99s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: CatBoost/T3 ...\n",
      "\t0.8776\t = Validation score   (accuracy)\n",
      "\t11.22s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: CatBoost/T4 ...\n",
      "\t0.8778\t = Validation score   (accuracy)\n",
      "\t10.49s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: CatBoost/T5 ...\n",
      "\t0.877\t = Validation score   (accuracy)\n",
      "\t13.56s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch ... Tuning model for up to 134.94s of the 523.95s of remaining time.\n",
      "Fitted model: NeuralNetTorch/ecf5e_00000 ...\n",
      "\t0.853\t = Validation score   (accuracy)\n",
      "\t32.86s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch/ecf5e_00001 ...\n",
      "\t0.8568\t = Validation score   (accuracy)\n",
      "\t31.29s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch/ecf5e_00002 ...\n",
      "\t0.846\t = Validation score   (accuracy)\n",
      "\t33.88s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch/ecf5e_00003 ...\n",
      "\t0.8486\t = Validation score   (accuracy)\n",
      "\t27.29s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch/ecf5e_00004 ...\n",
      "\t0.8456\t = Validation score   (accuracy)\n",
      "\t20.58s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 457.71s of remaining time.\n",
      "\t0.878\t = Validation score   (accuracy)\n",
      "\t3.34s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 145.67s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221122_095507/\")\n"
     ]
    }
   ],
   "source": [
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "rf_options = {\n",
    "    'n_estimators': 400,\n",
    "    'max_leaf_nodes' : ag.space.Int(lower=500, upper=15000, default=2000),\n",
    "}\n",
    "\n",
    "cat_options = {\n",
    "    'learning_rate' : ag.space.Real(0.0,0.2,default=0.05),\n",
    "}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                   'RF': rf_options,\n",
    "                   'CAT': cat_options,\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 10*60  # train various models for ~10 min\n",
    "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric='acc').fit(\n",
    "    train_data, time_limit=time_limit,\n",
    "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eaa225d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8748080663322756\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8748080663322756\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "807f7717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost/T5</td>\n",
       "      <td>0.875934</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.021490</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>13.562973</td>\n",
       "      <td>0.021490</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>13.562973</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM/T2</td>\n",
       "      <td>0.875934</td>\n",
       "      <td>0.876400</td>\n",
       "      <td>0.032944</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.514403</td>\n",
       "      <td>0.032944</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.514403</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost/T4</td>\n",
       "      <td>0.875115</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.013454</td>\n",
       "      <td>10.492069</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.013454</td>\n",
       "      <td>10.492069</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost/T3</td>\n",
       "      <td>0.875115</td>\n",
       "      <td>0.877600</td>\n",
       "      <td>0.020960</td>\n",
       "      <td>0.013583</td>\n",
       "      <td>11.221760</td>\n",
       "      <td>0.020960</td>\n",
       "      <td>0.013583</td>\n",
       "      <td>11.221760</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.874808</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.653411</td>\n",
       "      <td>0.297256</td>\n",
       "      <td>46.693883</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>3.341228</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost/T1</td>\n",
       "      <td>0.874706</td>\n",
       "      <td>0.876600</td>\n",
       "      <td>0.021744</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>12.521850</td>\n",
       "      <td>0.021744</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>12.521850</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM/T1</td>\n",
       "      <td>0.874296</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.017051</td>\n",
       "      <td>0.482210</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.017051</td>\n",
       "      <td>0.482210</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost/T2</td>\n",
       "      <td>0.873989</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.017154</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>5.992388</td>\n",
       "      <td>0.017154</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>5.992388</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM/T3</td>\n",
       "      <td>0.873887</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.046078</td>\n",
       "      <td>0.021614</td>\n",
       "      <td>0.622917</td>\n",
       "      <td>0.046078</td>\n",
       "      <td>0.021614</td>\n",
       "      <td>0.622917</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM/T5</td>\n",
       "      <td>0.872249</td>\n",
       "      <td>0.874200</td>\n",
       "      <td>0.038709</td>\n",
       "      <td>0.018659</td>\n",
       "      <td>0.576578</td>\n",
       "      <td>0.038709</td>\n",
       "      <td>0.018659</td>\n",
       "      <td>0.576578</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest/T1</td>\n",
       "      <td>0.864981</td>\n",
       "      <td>0.863704</td>\n",
       "      <td>0.271115</td>\n",
       "      <td>1.113817</td>\n",
       "      <td>2.939383</td>\n",
       "      <td>0.271115</td>\n",
       "      <td>1.113817</td>\n",
       "      <td>2.939383</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest/T2</td>\n",
       "      <td>0.859351</td>\n",
       "      <td>0.860799</td>\n",
       "      <td>0.241968</td>\n",
       "      <td>0.784207</td>\n",
       "      <td>2.087491</td>\n",
       "      <td>0.241968</td>\n",
       "      <td>0.784207</td>\n",
       "      <td>2.087491</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForest/T5</td>\n",
       "      <td>0.858430</td>\n",
       "      <td>0.858656</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>0.745349</td>\n",
       "      <td>1.984817</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>0.745349</td>\n",
       "      <td>1.984817</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForest/T4</td>\n",
       "      <td>0.857099</td>\n",
       "      <td>0.854724</td>\n",
       "      <td>0.173126</td>\n",
       "      <td>0.611449</td>\n",
       "      <td>1.673027</td>\n",
       "      <td>0.173126</td>\n",
       "      <td>0.611449</td>\n",
       "      <td>1.673027</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForest/T3</td>\n",
       "      <td>0.856485</td>\n",
       "      <td>0.854636</td>\n",
       "      <td>0.215488</td>\n",
       "      <td>0.622603</td>\n",
       "      <td>1.696091</td>\n",
       "      <td>0.215488</td>\n",
       "      <td>0.622603</td>\n",
       "      <td>1.696091</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NeuralNetTorch/ecf5e_00001</td>\n",
       "      <td>0.853311</td>\n",
       "      <td>0.856800</td>\n",
       "      <td>0.142316</td>\n",
       "      <td>0.147981</td>\n",
       "      <td>31.294452</td>\n",
       "      <td>0.142316</td>\n",
       "      <td>0.147981</td>\n",
       "      <td>31.294452</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NeuralNetTorch/ecf5e_00000</td>\n",
       "      <td>0.850548</td>\n",
       "      <td>0.853000</td>\n",
       "      <td>0.626675</td>\n",
       "      <td>0.276602</td>\n",
       "      <td>32.860587</td>\n",
       "      <td>0.626675</td>\n",
       "      <td>0.276602</td>\n",
       "      <td>32.860587</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NeuralNetTorch/ecf5e_00003</td>\n",
       "      <td>0.849217</td>\n",
       "      <td>0.848600</td>\n",
       "      <td>0.134257</td>\n",
       "      <td>0.153200</td>\n",
       "      <td>27.288305</td>\n",
       "      <td>0.134257</td>\n",
       "      <td>0.153200</td>\n",
       "      <td>27.288305</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NeuralNetTorch/ecf5e_00004</td>\n",
       "      <td>0.847784</td>\n",
       "      <td>0.845600</td>\n",
       "      <td>0.181765</td>\n",
       "      <td>0.087234</td>\n",
       "      <td>20.583878</td>\n",
       "      <td>0.181765</td>\n",
       "      <td>0.087234</td>\n",
       "      <td>20.583878</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NeuralNetTorch/ecf5e_00002</td>\n",
       "      <td>0.845737</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>0.147076</td>\n",
       "      <td>0.079870</td>\n",
       "      <td>33.882057</td>\n",
       "      <td>0.147076</td>\n",
       "      <td>0.079870</td>\n",
       "      <td>33.882057</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LightGBM/T4</td>\n",
       "      <td>0.820248</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.032290</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.512863</td>\n",
       "      <td>0.032290</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.512863</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  score_test  score_val  pred_time_test  \\\n",
       "0                  CatBoost/T5    0.875934   0.877000        0.021490   \n",
       "1                  LightGBM/T2    0.875934   0.876400        0.032944   \n",
       "2                  CatBoost/T4    0.875115   0.877800        0.019815   \n",
       "3                  CatBoost/T3    0.875115   0.877600        0.020960   \n",
       "4          WeightedEnsemble_L2    0.874808   0.878000        0.653411   \n",
       "5                  CatBoost/T1    0.874706   0.876600        0.021744   \n",
       "6                  LightGBM/T1    0.874296   0.875600        0.036829   \n",
       "7                  CatBoost/T2    0.873989   0.877000        0.017154   \n",
       "8                  LightGBM/T3    0.873887   0.875600        0.046078   \n",
       "9                  LightGBM/T5    0.872249   0.874200        0.038709   \n",
       "10             RandomForest/T1    0.864981   0.863704        0.271115   \n",
       "11             RandomForest/T2    0.859351   0.860799        0.241968   \n",
       "12             RandomForest/T5    0.858430   0.858656        0.227600   \n",
       "13             RandomForest/T4    0.857099   0.854724        0.173126   \n",
       "14             RandomForest/T3    0.856485   0.854636        0.215488   \n",
       "15  NeuralNetTorch/ecf5e_00001    0.853311   0.856800        0.142316   \n",
       "16  NeuralNetTorch/ecf5e_00000    0.850548   0.853000        0.626675   \n",
       "17  NeuralNetTorch/ecf5e_00003    0.849217   0.848600        0.134257   \n",
       "18  NeuralNetTorch/ecf5e_00004    0.847784   0.845600        0.181765   \n",
       "19  NeuralNetTorch/ecf5e_00002    0.845737   0.846000        0.147076   \n",
       "20                 LightGBM/T4    0.820248   0.818600        0.032290   \n",
       "\n",
       "    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.015692  13.562973                 0.021490                0.015692   \n",
       "1        0.016001   0.514403                 0.032944                0.016001   \n",
       "2        0.013454  10.492069                 0.019815                0.013454   \n",
       "3        0.013583  11.221760                 0.020960                0.013583   \n",
       "4        0.297256  46.693883                 0.006920                0.007200   \n",
       "5        0.016599  12.521850                 0.021744                0.016599   \n",
       "6        0.017051   0.482210                 0.036829                0.017051   \n",
       "7        0.011777   5.992388                 0.017154                0.011777   \n",
       "8        0.021614   0.622917                 0.046078                0.021614   \n",
       "9        0.018659   0.576578                 0.038709                0.018659   \n",
       "10       1.113817   2.939383                 0.271115                1.113817   \n",
       "11       0.784207   2.087491                 0.241968                0.784207   \n",
       "12       0.745349   1.984817                 0.227600                0.745349   \n",
       "13       0.611449   1.673027                 0.173126                0.611449   \n",
       "14       0.622603   1.696091                 0.215488                0.622603   \n",
       "15       0.147981  31.294452                 0.142316                0.147981   \n",
       "16       0.276602  32.860587                 0.626675                0.276602   \n",
       "17       0.153200  27.288305                 0.134257                0.153200   \n",
       "18       0.087234  20.583878                 0.181765                0.087234   \n",
       "19       0.079870  33.882057                 0.147076                0.079870   \n",
       "20       0.014599   0.512863                 0.032290                0.014599   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           13.562973            1       True         15  \n",
       "1            0.514403            1       True          2  \n",
       "2           10.492069            1       True         14  \n",
       "3           11.221760            1       True         13  \n",
       "4            3.341228            2       True         21  \n",
       "5           12.521850            1       True         11  \n",
       "6            0.482210            1       True          1  \n",
       "7            5.992388            1       True         12  \n",
       "8            0.622917            1       True          3  \n",
       "9            0.576578            1       True          5  \n",
       "10           2.939383            1       True          6  \n",
       "11           2.087491            1       True          7  \n",
       "12           1.984817            1       True         10  \n",
       "13           1.673027            1       True          9  \n",
       "14           1.696091            1       True          8  \n",
       "15          31.294452            1       True         17  \n",
       "16          32.860587            1       True         16  \n",
       "17          27.288305            1       True         19  \n",
       "18          20.583878            1       True         20  \n",
       "19          33.882057            1       True         18  \n",
       "20           0.512863            1       True          4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d4749",
   "metadata": {},
   "source": [
    "### Using ensembling techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a3f9c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221122_095737/\"\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221122_095737/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    39073\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' <=50K', ' >50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6206.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.92 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.19 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 4 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 11.99s of the 599.73s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5aa18fbd2424dfd9e0c4a969deeb03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM_BAG_L1/T1 ...\n",
      "\t0.8713\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T2 ...\n",
      "\t0.8715\t = Validation score   (accuracy)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T3 ...\n",
      "\t0.8694\t = Validation score   (accuracy)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T4 ...\n",
      "\t0.8193\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T5 ...\n",
      "\t0.8681\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest_BAG_L1 ... Tuning model for up to 11.99s of the 596.14s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038fc81958b84d2baec60dc989f74d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: RandomForest_BAG_L1/T1 ...\n",
      "\t0.8638\t = Validation score   (accuracy)\n",
      "\t4.49s\t = Training   runtime\n",
      "\t1.65s\t = Validation runtime\n",
      "Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 11.99s of the 587.77s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd08089e69db401e944577036207ec3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 282.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L1/T1 ...\n",
      "\t0.8706\t = Validation score   (accuracy)\n",
      "\t9.58s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 11.99s of the 578.07s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "2022-11-22 09:58:09,944\tINFO stopper.py:363 -- Reached timeout of 9.5933639758358 seconds. Stopping all trials.\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T1 ...\n",
      "\t0.8374\t = Validation score   (accuracy)\n",
      "\t5.19s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T2 ...\n",
      "\t0.8375\t = Validation score   (accuracy)\n",
      "\t4.85s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T3 ...\n",
      "\t0.8379\t = Validation score   (accuracy)\n",
      "\t4.99s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 233.4s of the 566.66s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8733\t = Validation score   (accuracy)\n",
      "\t2.87s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 228.55s of the 561.8s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8743\t = Validation score   (accuracy)\n",
      "\t2.62s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T3 ... Training model for up to 223.55s of the 556.8s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t2.96s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T4 ... Training model for up to 218.29s of the 551.54s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8214\t = Validation score   (accuracy)\n",
      "\t2.69s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T5 ... Training model for up to 213.32s of the 546.57s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8715\t = Validation score   (accuracy)\n",
      "\t3.25s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L1/T1 ... Training model for up to 207.58s of the 540.84s of remaining time.\n",
      "\t0.8638\t = Validation score   (accuracy)\n",
      "\t4.49s\t = Training   runtime\n",
      "\t1.65s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1/T1 ... Training model for up to 207.52s of the 540.78s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t89.89s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T1 ... Training model for up to 124.3s of the 457.55s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8479\t = Validation score   (accuracy)\n",
      "\t30.56s\t = Training   runtime\n",
      "\t1.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T2 ... Training model for up to 96.22s of the 429.47s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8439\t = Validation score   (accuracy)\n",
      "\t32.88s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T3 ... Training model for up to 65.68s of the 398.93s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8477\t = Validation score   (accuracy)\n",
      "\t26.89s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Completed 1/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 374.36s of remaining time.\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t11.04s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting 4 L2 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 10.89s of the 363.24s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ef6d02511942399c1ad514f26753fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM_BAG_L2/T1 ...\n",
      "\t0.8751\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L2/T2 ...\n",
      "\t0.8736\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L2/T3 ...\n",
      "\t0.8734\t = Validation score   (accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L2/T4 ...\n",
      "\t0.8393\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L2/T5 ...\n",
      "\t0.8741\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest_BAG_L2 ... Tuning model for up to 10.89s of the 359.29s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f889d332b46a4f1e90ca89ae349c96a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: RandomForest_BAG_L2/T1 ...\n",
      "\t0.8735\t = Validation score   (accuracy)\n",
      "\t10.16s\t = Training   runtime\n",
      "\t1.6s\t = Validation runtime\n",
      "Hyperparameter tuning model: CatBoost_BAG_L2 ... Tuning model for up to 10.89s of the 345.28s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62398063169458da90a954ff451bed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 241.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L2/T1 ...\n",
      "\t0.8743\t = Validation score   (accuracy)\n",
      "\t8.7s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L2 ... Tuning model for up to 10.89s of the 336.41s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "2022-11-22 10:02:10,816\tINFO stopper.py:363 -- Reached timeout of 8.71587961683941 seconds. Stopping all trials.\n",
      "Fitted model: NeuralNetTorch_BAG_L2/T1 ...\n",
      "\t0.8694\t = Validation score   (accuracy)\n",
      "\t4.46s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L2/T2 ...\n",
      "\t0.8727\t = Validation score   (accuracy)\n",
      "\t5.26s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L2/T3 ...\n",
      "\t0.8619\t = Validation score   (accuracy)\n",
      "\t4.69s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L2/T4 ...\n",
      "\t0.8701\t = Validation score   (accuracy)\n",
      "\t4.68s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T1 ... Training model for up to 204.43s of the 325.57s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8742\t = Validation score   (accuracy)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T2 ... Training model for up to 199.11s of the 320.24s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8737\t = Validation score   (accuracy)\n",
      "\t3.39s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T3 ... Training model for up to 193.61s of the 314.74s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8734\t = Validation score   (accuracy)\n",
      "\t3.83s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T4 ... Training model for up to 187.74s of the 308.87s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8397\t = Validation score   (accuracy)\n",
      "\t3.3s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T5 ... Training model for up to 182.22s of the 303.35s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8737\t = Validation score   (accuracy)\n",
      "\t3.94s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L2/T1 ... Training model for up to 176.34s of the 297.47s of remaining time.\n",
      "\t0.8735\t = Validation score   (accuracy)\n",
      "\t10.16s\t = Training   runtime\n",
      "\t1.6s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2/T1 ... Training model for up to 176.2s of the 297.33s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8752\t = Validation score   (accuracy)\n",
      "\t29.86s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2/T1 ... Training model for up to 152.34s of the 273.47s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.873\t = Validation score   (accuracy)\n",
      "\t35.33s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2/T2 ... Training model for up to 118.62s of the 239.75s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8743\t = Validation score   (accuracy)\n",
      "\t37.09s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2/T3 ... Training model for up to 83.27s of the 204.41s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8711\t = Validation score   (accuracy)\n",
      "\t54.54s\t = Training   runtime\n",
      "\t1.24s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2/T4 ... Training model for up to 29.18s of the 150.31s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8711\t = Validation score   (accuracy)\n",
      "\t29.76s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Completed 1/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 121.69s of remaining time.\n",
      "\t0.8752\t = Validation score   (accuracy)\n",
      "\t16.52s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting 4 L3 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L3 ... Tuning model for up to 4.73s of the 105.08s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c0bbcf71734996a005f45c43e0266b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: LightGBM_BAG_L3/T1 ...\n",
      "\t0.8811\t = Validation score   (accuracy)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L3/T2 ...\n",
      "\t0.8825\t = Validation score   (accuracy)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L3/T3 ...\n",
      "\t0.8827\t = Validation score   (accuracy)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest_BAG_L3 ... Tuning model for up to 4.73s of the 101.47s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e9c1ff463845f885a3ea2405a5259f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: RandomForest_BAG_L3/T1 ...\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t18.85s\t = Training   runtime\n",
      "\t2.15s\t = Validation runtime\n",
      "Hyperparameter tuning model: CatBoost_BAG_L3 ... Tuning model for up to 4.73s of the 77.35s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aece3d9c79834a51bc92d19f3ae3ca67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 61.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L3/T1 ...\n",
      "\t0.8821\t = Validation score   (accuracy)\n",
      "\t3.69s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L3 ... Tuning model for up to 4.73s of the 73.42s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "2022-11-22 10:06:30,317\tINFO stopper.py:363 -- Reached timeout of 3.7835224056243906 seconds. Stopping all trials.\n",
      "Fitting model: LightGBM_BAG_L3/T1 ... Training model for up to 66.66s of the 66.64s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8744\t = Validation score   (accuracy)\n",
      "\t5.22s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3/T2 ... Training model for up to 58.69s of the 58.67s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8752\t = Validation score   (accuracy)\n",
      "\t4.71s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3/T3 ... Training model for up to 51.01s of the 50.99s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8747\t = Validation score   (accuracy)\n",
      "\t6.36s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L3/T1 ... Training model for up to 42.01s of the 41.99s of remaining time.\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t18.85s\t = Training   runtime\n",
      "\t2.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3/T1 ... Training model for up to 41.88s of the 41.86s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8756\t = Validation score   (accuracy)\n",
      "\t37.95s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Completed 1/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.0s of the 3.12s of remaining time.\n",
      "\t0.8756\t = Validation score   (accuracy)\n",
      "\t9.81s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 606.85s ... Best model: \"WeightedEnsemble_L4\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221122_095737/\")\n"
     ]
    }
   ],
   "source": [
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "rf_options = {\n",
    "    'n_estimators': 400,\n",
    "    'max_leaf_nodes' : ag.space.Int(lower=500, upper=15000, default=2000),\n",
    "}\n",
    "\n",
    "cat_options = {\n",
    "    'learning_rate' : ag.space.Real(0.0,0.2,default=0.05),\n",
    "}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                   'RF': rf_options,\n",
    "                   'CAT': cat_options,\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 10*60  # train various models for ~10 min\n",
    "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric='acc').fit(\n",
    "    train_data, time_limit=time_limit, #auto_stack=True,\n",
    "    num_bag_folds=5, num_bag_sets=2, num_stack_levels=2,\n",
    "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5578242c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8745009724639164\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8745009724639164\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29a74339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L2/T5</td>\n",
       "      <td>0.876446</td>\n",
       "      <td>0.873672</td>\n",
       "      <td>6.548983</td>\n",
       "      <td>6.827475</td>\n",
       "      <td>203.032670</td>\n",
       "      <td>0.245272</td>\n",
       "      <td>0.208085</td>\n",
       "      <td>3.938540</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost_BAG_L2/T1</td>\n",
       "      <td>0.875729</td>\n",
       "      <td>0.875234</td>\n",
       "      <td>6.394531</td>\n",
       "      <td>6.728380</td>\n",
       "      <td>228.955591</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.108991</td>\n",
       "      <td>29.861461</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.875729</td>\n",
       "      <td>0.875234</td>\n",
       "      <td>6.396495</td>\n",
       "      <td>6.791907</td>\n",
       "      <td>245.474826</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.063527</td>\n",
       "      <td>16.519235</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L2/T2</td>\n",
       "      <td>0.875729</td>\n",
       "      <td>0.873698</td>\n",
       "      <td>6.482572</td>\n",
       "      <td>6.728957</td>\n",
       "      <td>202.482234</td>\n",
       "      <td>0.178861</td>\n",
       "      <td>0.109567</td>\n",
       "      <td>3.388104</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L2/T3</td>\n",
       "      <td>0.875729</td>\n",
       "      <td>0.873391</td>\n",
       "      <td>6.553095</td>\n",
       "      <td>6.800457</td>\n",
       "      <td>202.925216</td>\n",
       "      <td>0.249384</td>\n",
       "      <td>0.181068</td>\n",
       "      <td>3.831086</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_BAG_L2/T1</td>\n",
       "      <td>0.875422</td>\n",
       "      <td>0.874235</td>\n",
       "      <td>6.515791</td>\n",
       "      <td>6.830537</td>\n",
       "      <td>202.602746</td>\n",
       "      <td>0.212080</td>\n",
       "      <td>0.211147</td>\n",
       "      <td>3.508616</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetTorch_BAG_L2/T1</td>\n",
       "      <td>0.875422</td>\n",
       "      <td>0.872981</td>\n",
       "      <td>7.911817</td>\n",
       "      <td>8.051803</td>\n",
       "      <td>234.419336</td>\n",
       "      <td>1.608106</td>\n",
       "      <td>1.432413</td>\n",
       "      <td>35.325206</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM_BAG_L1/T1</td>\n",
       "      <td>0.874910</td>\n",
       "      <td>0.873288</td>\n",
       "      <td>0.347302</td>\n",
       "      <td>0.438626</td>\n",
       "      <td>2.869899</td>\n",
       "      <td>0.347302</td>\n",
       "      <td>0.438626</td>\n",
       "      <td>2.869899</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM_BAG_L3/T1</td>\n",
       "      <td>0.874910</td>\n",
       "      <td>0.874389</td>\n",
       "      <td>13.352954</td>\n",
       "      <td>14.564839</td>\n",
       "      <td>419.013834</td>\n",
       "      <td>0.185335</td>\n",
       "      <td>0.276117</td>\n",
       "      <td>5.217258</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost_BAG_L1/T1</td>\n",
       "      <td>0.874808</td>\n",
       "      <td>0.874517</td>\n",
       "      <td>0.178349</td>\n",
       "      <td>0.187852</td>\n",
       "      <td>89.889010</td>\n",
       "      <td>0.178349</td>\n",
       "      <td>0.187852</td>\n",
       "      <td>89.889010</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.874808</td>\n",
       "      <td>0.874517</td>\n",
       "      <td>0.180074</td>\n",
       "      <td>0.241833</td>\n",
       "      <td>100.931148</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>11.042138</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM_BAG_L1/T2</td>\n",
       "      <td>0.874706</td>\n",
       "      <td>0.874338</td>\n",
       "      <td>0.377745</td>\n",
       "      <td>0.354313</td>\n",
       "      <td>2.620293</td>\n",
       "      <td>0.377745</td>\n",
       "      <td>0.354313</td>\n",
       "      <td>2.620293</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NeuralNetTorch_BAG_L2/T2</td>\n",
       "      <td>0.874706</td>\n",
       "      <td>0.874312</td>\n",
       "      <td>7.464974</td>\n",
       "      <td>7.823893</td>\n",
       "      <td>236.183428</td>\n",
       "      <td>1.161263</td>\n",
       "      <td>1.204503</td>\n",
       "      <td>37.089297</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CatBoost_BAG_L3/T1</td>\n",
       "      <td>0.874501</td>\n",
       "      <td>0.875566</td>\n",
       "      <td>13.271150</td>\n",
       "      <td>14.598851</td>\n",
       "      <td>451.749946</td>\n",
       "      <td>0.103531</td>\n",
       "      <td>0.310129</td>\n",
       "      <td>37.953370</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WeightedEnsemble_L4</td>\n",
       "      <td>0.874501</td>\n",
       "      <td>0.875566</td>\n",
       "      <td>13.273069</td>\n",
       "      <td>14.737295</td>\n",
       "      <td>461.560830</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.138444</td>\n",
       "      <td>9.810884</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBM_BAG_L1/T3</td>\n",
       "      <td>0.874296</td>\n",
       "      <td>0.872495</td>\n",
       "      <td>0.432455</td>\n",
       "      <td>0.411289</td>\n",
       "      <td>2.958015</td>\n",
       "      <td>0.432455</td>\n",
       "      <td>0.411289</td>\n",
       "      <td>2.958015</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LightGBM_BAG_L3/T2</td>\n",
       "      <td>0.873989</td>\n",
       "      <td>0.875208</td>\n",
       "      <td>13.310717</td>\n",
       "      <td>14.473056</td>\n",
       "      <td>418.504262</td>\n",
       "      <td>0.143098</td>\n",
       "      <td>0.184334</td>\n",
       "      <td>4.707686</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBM_BAG_L1/T5</td>\n",
       "      <td>0.873682</td>\n",
       "      <td>0.871523</td>\n",
       "      <td>0.361296</td>\n",
       "      <td>0.365884</td>\n",
       "      <td>3.247837</td>\n",
       "      <td>0.361296</td>\n",
       "      <td>0.365884</td>\n",
       "      <td>3.247837</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBM_BAG_L3/T3</td>\n",
       "      <td>0.873170</td>\n",
       "      <td>0.874696</td>\n",
       "      <td>13.357040</td>\n",
       "      <td>14.454283</td>\n",
       "      <td>420.157269</td>\n",
       "      <td>0.189421</td>\n",
       "      <td>0.165560</td>\n",
       "      <td>6.360693</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForest_BAG_L3/T1</td>\n",
       "      <td>0.872658</td>\n",
       "      <td>0.872521</td>\n",
       "      <td>13.715319</td>\n",
       "      <td>16.440729</td>\n",
       "      <td>432.648779</td>\n",
       "      <td>0.547700</td>\n",
       "      <td>2.152007</td>\n",
       "      <td>18.852204</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NeuralNetTorch_BAG_L2/T3</td>\n",
       "      <td>0.872556</td>\n",
       "      <td>0.871113</td>\n",
       "      <td>7.754911</td>\n",
       "      <td>7.857933</td>\n",
       "      <td>253.634474</td>\n",
       "      <td>1.451200</td>\n",
       "      <td>1.238543</td>\n",
       "      <td>54.540344</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForest_BAG_L2/T1</td>\n",
       "      <td>0.871532</td>\n",
       "      <td>0.873468</td>\n",
       "      <td>6.775750</td>\n",
       "      <td>8.220260</td>\n",
       "      <td>209.253558</td>\n",
       "      <td>0.472039</td>\n",
       "      <td>1.600871</td>\n",
       "      <td>10.159428</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NeuralNetTorch_BAG_L2/T4</td>\n",
       "      <td>0.869690</td>\n",
       "      <td>0.871062</td>\n",
       "      <td>7.271530</td>\n",
       "      <td>7.802551</td>\n",
       "      <td>228.856494</td>\n",
       "      <td>0.967819</td>\n",
       "      <td>1.183161</td>\n",
       "      <td>29.762363</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForest_BAG_L1/T1</td>\n",
       "      <td>0.867233</td>\n",
       "      <td>0.863793</td>\n",
       "      <td>0.517500</td>\n",
       "      <td>1.648071</td>\n",
       "      <td>4.486376</td>\n",
       "      <td>0.517500</td>\n",
       "      <td>1.648071</td>\n",
       "      <td>4.486376</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T1</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.847926</td>\n",
       "      <td>1.910214</td>\n",
       "      <td>1.383870</td>\n",
       "      <td>30.557496</td>\n",
       "      <td>1.910214</td>\n",
       "      <td>1.383870</td>\n",
       "      <td>30.557496</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T3</td>\n",
       "      <td>0.850752</td>\n",
       "      <td>0.847695</td>\n",
       "      <td>0.866586</td>\n",
       "      <td>0.770314</td>\n",
       "      <td>26.893839</td>\n",
       "      <td>0.866586</td>\n",
       "      <td>0.770314</td>\n",
       "      <td>26.893839</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T2</td>\n",
       "      <td>0.846555</td>\n",
       "      <td>0.843856</td>\n",
       "      <td>0.961206</td>\n",
       "      <td>0.805339</td>\n",
       "      <td>32.883213</td>\n",
       "      <td>0.961206</td>\n",
       "      <td>0.805339</td>\n",
       "      <td>32.883213</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LightGBM_BAG_L2/T4</td>\n",
       "      <td>0.838673</td>\n",
       "      <td>0.839659</td>\n",
       "      <td>6.530775</td>\n",
       "      <td>6.810373</td>\n",
       "      <td>202.392131</td>\n",
       "      <td>0.227064</td>\n",
       "      <td>0.190983</td>\n",
       "      <td>3.298001</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LightGBM_BAG_L1/T4</td>\n",
       "      <td>0.820760</td>\n",
       "      <td>0.821411</td>\n",
       "      <td>0.351057</td>\n",
       "      <td>0.253832</td>\n",
       "      <td>2.688152</td>\n",
       "      <td>0.351057</td>\n",
       "      <td>0.253832</td>\n",
       "      <td>2.688152</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  score_test  score_val  pred_time_test  \\\n",
       "0         LightGBM_BAG_L2/T5    0.876446   0.873672        6.548983   \n",
       "1         CatBoost_BAG_L2/T1    0.875729   0.875234        6.394531   \n",
       "2        WeightedEnsemble_L3    0.875729   0.875234        6.396495   \n",
       "3         LightGBM_BAG_L2/T2    0.875729   0.873698        6.482572   \n",
       "4         LightGBM_BAG_L2/T3    0.875729   0.873391        6.553095   \n",
       "5         LightGBM_BAG_L2/T1    0.875422   0.874235        6.515791   \n",
       "6   NeuralNetTorch_BAG_L2/T1    0.875422   0.872981        7.911817   \n",
       "7         LightGBM_BAG_L1/T1    0.874910   0.873288        0.347302   \n",
       "8         LightGBM_BAG_L3/T1    0.874910   0.874389       13.352954   \n",
       "9         CatBoost_BAG_L1/T1    0.874808   0.874517        0.178349   \n",
       "10       WeightedEnsemble_L2    0.874808   0.874517        0.180074   \n",
       "11        LightGBM_BAG_L1/T2    0.874706   0.874338        0.377745   \n",
       "12  NeuralNetTorch_BAG_L2/T2    0.874706   0.874312        7.464974   \n",
       "13        CatBoost_BAG_L3/T1    0.874501   0.875566       13.271150   \n",
       "14       WeightedEnsemble_L4    0.874501   0.875566       13.273069   \n",
       "15        LightGBM_BAG_L1/T3    0.874296   0.872495        0.432455   \n",
       "16        LightGBM_BAG_L3/T2    0.873989   0.875208       13.310717   \n",
       "17        LightGBM_BAG_L1/T5    0.873682   0.871523        0.361296   \n",
       "18        LightGBM_BAG_L3/T3    0.873170   0.874696       13.357040   \n",
       "19    RandomForest_BAG_L3/T1    0.872658   0.872521       13.715319   \n",
       "20  NeuralNetTorch_BAG_L2/T3    0.872556   0.871113        7.754911   \n",
       "21    RandomForest_BAG_L2/T1    0.871532   0.873468        6.775750   \n",
       "22  NeuralNetTorch_BAG_L2/T4    0.869690   0.871062        7.271530   \n",
       "23    RandomForest_BAG_L1/T1    0.867233   0.863793        0.517500   \n",
       "24  NeuralNetTorch_BAG_L1/T1    0.853414   0.847926        1.910214   \n",
       "25  NeuralNetTorch_BAG_L1/T3    0.850752   0.847695        0.866586   \n",
       "26  NeuralNetTorch_BAG_L1/T2    0.846555   0.843856        0.961206   \n",
       "27        LightGBM_BAG_L2/T4    0.838673   0.839659        6.530775   \n",
       "28        LightGBM_BAG_L1/T4    0.820760   0.821411        0.351057   \n",
       "\n",
       "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        6.827475  203.032670                 0.245272   \n",
       "1        6.728380  228.955591                 0.090820   \n",
       "2        6.791907  245.474826                 0.001964   \n",
       "3        6.728957  202.482234                 0.178861   \n",
       "4        6.800457  202.925216                 0.249384   \n",
       "5        6.830537  202.602746                 0.212080   \n",
       "6        8.051803  234.419336                 1.608106   \n",
       "7        0.438626    2.869899                 0.347302   \n",
       "8       14.564839  419.013834                 0.185335   \n",
       "9        0.187852   89.889010                 0.178349   \n",
       "10       0.241833  100.931148                 0.001725   \n",
       "11       0.354313    2.620293                 0.377745   \n",
       "12       7.823893  236.183428                 1.161263   \n",
       "13      14.598851  451.749946                 0.103531   \n",
       "14      14.737295  461.560830                 0.001919   \n",
       "15       0.411289    2.958015                 0.432455   \n",
       "16      14.473056  418.504262                 0.143098   \n",
       "17       0.365884    3.247837                 0.361296   \n",
       "18      14.454283  420.157269                 0.189421   \n",
       "19      16.440729  432.648779                 0.547700   \n",
       "20       7.857933  253.634474                 1.451200   \n",
       "21       8.220260  209.253558                 0.472039   \n",
       "22       7.802551  228.856494                 0.967819   \n",
       "23       1.648071    4.486376                 0.517500   \n",
       "24       1.383870   30.557496                 1.910214   \n",
       "25       0.770314   26.893839                 0.866586   \n",
       "26       0.805339   32.883213                 0.961206   \n",
       "27       6.810373  202.392131                 0.227064   \n",
       "28       0.253832    2.688152                 0.351057   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.208085           3.938540            2       True   \n",
       "1                 0.108991          29.861461            2       True   \n",
       "2                 0.063527          16.519235            3       True   \n",
       "3                 0.109567           3.388104            2       True   \n",
       "4                 0.181068           3.831086            2       True   \n",
       "5                 0.211147           3.508616            2       True   \n",
       "6                 1.432413          35.325206            2       True   \n",
       "7                 0.438626           2.869899            1       True   \n",
       "8                 0.276117           5.217258            3       True   \n",
       "9                 0.187852          89.889010            1       True   \n",
       "10                0.053981          11.042138            2       True   \n",
       "11                0.354313           2.620293            1       True   \n",
       "12                1.204503          37.089297            2       True   \n",
       "13                0.310129          37.953370            3       True   \n",
       "14                0.138444           9.810884            4       True   \n",
       "15                0.411289           2.958015            1       True   \n",
       "16                0.184334           4.707686            3       True   \n",
       "17                0.365884           3.247837            1       True   \n",
       "18                0.165560           6.360693            3       True   \n",
       "19                2.152007          18.852204            3       True   \n",
       "20                1.238543          54.540344            2       True   \n",
       "21                1.600871          10.159428            2       True   \n",
       "22                1.183161          29.762363            2       True   \n",
       "23                1.648071           4.486376            1       True   \n",
       "24                1.383870          30.557496            1       True   \n",
       "25                0.770314          26.893839            1       True   \n",
       "26                0.805339          32.883213            1       True   \n",
       "27                0.190983           3.298001            2       True   \n",
       "28                0.253832           2.688152            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          16  \n",
       "1          18  \n",
       "2          23  \n",
       "3          13  \n",
       "4          14  \n",
       "5          12  \n",
       "6          19  \n",
       "7           1  \n",
       "8          24  \n",
       "9           7  \n",
       "10         11  \n",
       "11          2  \n",
       "12         20  \n",
       "13         28  \n",
       "14         29  \n",
       "15          3  \n",
       "16         25  \n",
       "17          5  \n",
       "18         26  \n",
       "19         27  \n",
       "20         21  \n",
       "21         17  \n",
       "22         22  \n",
       "23          6  \n",
       "24          8  \n",
       "25         10  \n",
       "26          9  \n",
       "27         15  \n",
       "28          4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc35fa8",
   "metadata": {},
   "source": [
    "#### Extra automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac3952de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221122_100812/\"\n",
      "Presets specified: ['best_quality']\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221122_100812/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    39073\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' <=50K', ' >50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5472.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.92 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.3s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.19 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 4 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 16.87s of the 599.7s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdf50ec926c402baf071be0978d8f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.125281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: LightGBM_BAG_L1/T1 ...\n",
      "\t0.8747\t = Validation score   (accuracy)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T2 ...\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t1.39s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T3 ...\n",
      "\t0.8755\t = Validation score   (accuracy)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T4 ...\n",
      "\t0.8747\t = Validation score   (accuracy)\n",
      "\t6.36s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest_BAG_L1 ... Tuning model for up to 16.87s of the 587.03s of remaining time.\n",
      "\tNo hyperparameter search space specified for RandomForest. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "Warning: Exception caused RandomForest_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1380, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1001, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 182, in _hyperparameter_tune\n",
      "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1080, in _hyperparameter_tune\n",
      "    model_path = model_info['path']\n",
      "TypeError: string indices must be integers\n",
      "string indices must be integers\n",
      "Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 16.87s of the 578.94s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802c899f650e4c41a778623054a6cc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 284.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L1/T1 ...\n",
      "\t0.8723\t = Validation score   (accuracy)\n",
      "\t13.42s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 16.87s of the 565.4s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "2022-11-22 10:09:02,479\tINFO stopper.py:363 -- Reached timeout of 13.493324695229532 seconds. Stopping all trials.\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T1 ...\n",
      "\t0.8475\t = Validation score   (accuracy)\n",
      "\t7.86s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T2 ...\n",
      "\t0.8426\t = Validation score   (accuracy)\n",
      "\t8.4s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T3 ...\n",
      "\t0.8356\t = Validation score   (accuracy)\n",
      "\t8.35s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 549.74s of the 549.74s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t11.97s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 536.08s of the 536.08s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t12.44s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T3 ... Training model for up to 521.46s of the 521.46s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.874\t = Validation score   (accuracy)\n",
      "\t11.87s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T4 ... Training model for up to 507.34s of the 507.34s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8738\t = Validation score   (accuracy)\n",
      "\t35.62s\t = Training   runtime\n",
      "\t5.2s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1/T1 ... Training model for up to 474.07s of the 474.07s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8734\t = Validation score   (accuracy)\n",
      "\t178.36s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T1 ... Training model for up to 305.88s of the 305.88s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8579\t = Validation score   (accuracy)\n",
      "\t217.72s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T2 ... Training model for up to 92.52s of the 92.52s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.854\t = Validation score   (accuracy)\n",
      "\t87.56s\t = Training   runtime\n",
      "\t1.27s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T3 ... Training model for up to 10.26s of the 10.25s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1/T3.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1.34s of remaining time.\n",
      "\t0.8749\t = Validation score   (accuracy)\n",
      "\t8.98s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 607.72s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221122_100812/\")\n"
     ]
    }
   ],
   "source": [
    "nn_options = {}\n",
    "gbm_options = {}\n",
    "rf_options = {}\n",
    "cat_options = {}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                   'RF': rf_options,\n",
    "                   'CAT': cat_options,\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 10*60  # train various models for ~10 min\n",
    "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric='acc').fit(\n",
    "    train_data, time_limit=time_limit, auto_stack=True, presets='best_quality',\n",
    "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "    sample_weight='balanced_weight',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0470ea1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8753198894462074\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8753198894462074\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "981e9160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L1/T1</td>\n",
       "      <td>0.876139</td>\n",
       "      <td>0.873391</td>\n",
       "      <td>0.250188</td>\n",
       "      <td>0.354206</td>\n",
       "      <td>178.363245</td>\n",
       "      <td>0.250188</td>\n",
       "      <td>0.354206</td>\n",
       "      <td>178.363245</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L1/T1</td>\n",
       "      <td>0.876036</td>\n",
       "      <td>0.874543</td>\n",
       "      <td>0.810949</td>\n",
       "      <td>0.935043</td>\n",
       "      <td>11.969077</td>\n",
       "      <td>0.810949</td>\n",
       "      <td>0.935043</td>\n",
       "      <td>11.969077</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L1/T4</td>\n",
       "      <td>0.875525</td>\n",
       "      <td>0.873800</td>\n",
       "      <td>4.690636</td>\n",
       "      <td>5.198068</td>\n",
       "      <td>35.623856</td>\n",
       "      <td>4.690636</td>\n",
       "      <td>5.198068</td>\n",
       "      <td>35.623856</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L1/T3</td>\n",
       "      <td>0.875422</td>\n",
       "      <td>0.873979</td>\n",
       "      <td>0.887022</td>\n",
       "      <td>0.781623</td>\n",
       "      <td>11.866903</td>\n",
       "      <td>0.887022</td>\n",
       "      <td>0.781623</td>\n",
       "      <td>11.866903</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1/T2</td>\n",
       "      <td>0.875320</td>\n",
       "      <td>0.874850</td>\n",
       "      <td>0.796434</td>\n",
       "      <td>0.744634</td>\n",
       "      <td>12.435519</td>\n",
       "      <td>0.796434</td>\n",
       "      <td>0.744634</td>\n",
       "      <td>12.435519</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.875320</td>\n",
       "      <td>0.874875</td>\n",
       "      <td>2.782690</td>\n",
       "      <td>2.298138</td>\n",
       "      <td>239.135580</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.074118</td>\n",
       "      <td>8.975713</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T1</td>\n",
       "      <td>0.863138</td>\n",
       "      <td>0.857933</td>\n",
       "      <td>1.983714</td>\n",
       "      <td>1.479386</td>\n",
       "      <td>217.724348</td>\n",
       "      <td>1.983714</td>\n",
       "      <td>1.479386</td>\n",
       "      <td>217.724348</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T2</td>\n",
       "      <td>0.858327</td>\n",
       "      <td>0.854017</td>\n",
       "      <td>1.684031</td>\n",
       "      <td>1.268226</td>\n",
       "      <td>87.562599</td>\n",
       "      <td>1.684031</td>\n",
       "      <td>1.268226</td>\n",
       "      <td>87.562599</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T3</td>\n",
       "      <td>0.843689</td>\n",
       "      <td>0.835619</td>\n",
       "      <td>0.211390</td>\n",
       "      <td>0.093792</td>\n",
       "      <td>8.351446</td>\n",
       "      <td>0.211390</td>\n",
       "      <td>0.093792</td>\n",
       "      <td>8.351446</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_test  score_val  pred_time_test  \\\n",
       "0        CatBoost_BAG_L1/T1    0.876139   0.873391        0.250188   \n",
       "1        LightGBM_BAG_L1/T1    0.876036   0.874543        0.810949   \n",
       "2        LightGBM_BAG_L1/T4    0.875525   0.873800        4.690636   \n",
       "3        LightGBM_BAG_L1/T3    0.875422   0.873979        0.887022   \n",
       "4        LightGBM_BAG_L1/T2    0.875320   0.874850        0.796434   \n",
       "5       WeightedEnsemble_L2    0.875320   0.874875        2.782690   \n",
       "6  NeuralNetTorch_BAG_L1/T1    0.863138   0.857933        1.983714   \n",
       "7  NeuralNetTorch_BAG_L1/T2    0.858327   0.854017        1.684031   \n",
       "8  NeuralNetTorch_BAG_L1/T3    0.843689   0.835619        0.211390   \n",
       "\n",
       "   pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.354206  178.363245                 0.250188                0.354206   \n",
       "1       0.935043   11.969077                 0.810949                0.935043   \n",
       "2       5.198068   35.623856                 4.690636                5.198068   \n",
       "3       0.781623   11.866903                 0.887022                0.781623   \n",
       "4       0.744634   12.435519                 0.796434                0.744634   \n",
       "5       2.298138  239.135580                 0.002541                0.074118   \n",
       "6       1.479386  217.724348                 1.983714                1.479386   \n",
       "7       1.268226   87.562599                 1.684031                1.268226   \n",
       "8       0.093792    8.351446                 0.211390                0.093792   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0         178.363245            1       True          5  \n",
       "1          11.969077            1       True          1  \n",
       "2          35.623856            1       True          4  \n",
       "3          11.866903            1       True          3  \n",
       "4          12.435519            1       True          2  \n",
       "5           8.975713            2       True          9  \n",
       "6         217.724348            1       True          6  \n",
       "7          87.562599            1       True          7  \n",
       "8           8.351446            1       True          8  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12520a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
