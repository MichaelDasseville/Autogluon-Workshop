{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a3b6a9",
   "metadata": {},
   "source": [
    "# AWS Re:Invent  Autogluon Workshop\n",
    "### This workshop will demonstrate a machine learning problem solved by autogluon.\n",
    "* Use the documentation of autogluon and the different tutorials [here](https://auto.gluon.ai/stable/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73379461",
   "metadata": {},
   "source": [
    "### Context\n",
    "In this notebook we are going to use Autogluon in different ways. We will start with default setting and let it fit our Dataset. In a second time we will use hyperparameters to specify a given set of model to try with a defined range of hyperparameters to try. We will compare the accuracy between Default setting and hyperparameters. Lastly, we will pass ensembling arguments to Autogluon predictor with the same hyperparameter setting of the previous section. We will compare the different accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf266751",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: autogluon in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (0.5.2)\n",
      "Requirement already satisfied: autogluon.features==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: autogluon.timeseries[all]==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: autogluon.tabular[all]==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: autogluon.text==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: autogluon.vision==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: autogluon.core[all]==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: autogluon.multimodal==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (4.62.3)\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.5,>=1.2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (1.3.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (2.26.0)\n",
      "Requirement already satisfied: distributed<=2021.11.2,>=2021.09.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (2021.11.2)\n",
      "Requirement already satisfied: dask<=2021.11.2,>=2021.09.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (2021.11.2)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (1.24.90)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (3.5.0)\n",
      "Requirement already satisfied: numpy<1.23,>=1.21 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (1.21.2)\n",
      "Requirement already satisfied: autogluon.common==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (0.5.2)\n",
      "Requirement already satisfied: scikit-learn<1.1,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (1.0.1)\n",
      "Requirement already satisfied: scipy<1.8.0,>=1.5.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (1.7.2)\n",
      "Requirement already satisfied: ray<1.14,>=1.13 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (1.13.0)\n",
      "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.core[all]==0.5.2->autogluon) (0.2.7)\n",
      "Requirement already satisfied: psutil<6,>=5.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.features==0.5.2->autogluon) (5.8.0)\n",
      "Requirement already satisfied: protobuf<=3.18.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (3.18.1)\n",
      "Requirement already satisfied: smart-open<5.3.0,>=5.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (5.2.1)\n",
      "Requirement already satisfied: timm<0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.5.4)\n",
      "Requirement already satisfied: torchtext<0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.13.0)\n",
      "Requirement already satisfied: torchmetrics<0.8.0,>=0.7.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.7.3)\n",
      "Requirement already satisfied: transformers<4.21.0,>=4.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (4.20.1)\n",
      "Requirement already satisfied: scikit-image<0.20.0,>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.19.3)\n",
      "Requirement already satisfied: Pillow<9.1.0,>=9.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (9.0.1)\n",
      "Requirement already satisfied: sentencepiece<0.2.0,>=0.1.95 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.1.95)\n",
      "Requirement already satisfied: pytorch-lightning<1.7.0,>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (1.6.5)\n",
      "Requirement already satisfied: torch<1.13,>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (1.12.0+cu113)\n",
      "Requirement already satisfied: fairscale<=0.4.6,>=0.4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.4.6)\n",
      "Requirement already satisfied: torchvision<0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (0.13.0+cu113)\n",
      "Requirement already satisfied: omegaconf<2.2.0,>=2.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (2.1.2)\n",
      "Requirement already satisfied: nlpaug<=1.1.10,>=1.1.10 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (1.1.10)\n",
      "Requirement already satisfied: pytorch-metric-learning<1.4.0,>=1.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (1.3.2)\n",
      "Requirement already satisfied: nptyping<1.5.0,>=1.4.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (1.4.4)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.multimodal==0.5.2->autogluon) (3.6.5)\n",
      "Requirement already satisfied: networkx<3.0,>=2.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.tabular[all]==0.5.2->autogluon) (2.6.3)\n",
      "Requirement already satisfied: xgboost<1.5,>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.tabular[all]==0.5.2->autogluon) (1.4.2)\n",
      "Requirement already satisfied: fastai<2.8,>=2.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.tabular[all]==0.5.2->autogluon) (2.7.9)\n",
      "Requirement already satisfied: catboost<1.1,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.tabular[all]==0.5.2->autogluon) (1.0.6)\n",
      "Requirement already satisfied: lightgbm<3.4,>=3.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.tabular[all]==0.5.2->autogluon) (3.3.3)\n",
      "Requirement already satisfied: autogluon-contrib-nlp==0.0.1b20220208 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.text==0.5.2->autogluon) (0.0.1b20220208)\n",
      "Requirement already satisfied: gluonts<0.10.0,>=0.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.timeseries[all]==0.5.2->autogluon) (0.9.9)\n",
      "Requirement already satisfied: pmdarima~=1.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.timeseries[all]==0.5.2->autogluon) (1.8.5)\n",
      "Requirement already satisfied: sktime~=0.11.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.timeseries[all]==0.5.2->autogluon) (0.11.4)\n",
      "Requirement already satisfied: tbats~=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.timeseries[all]==0.5.2->autogluon) (1.1.1)\n",
      "Requirement already satisfied: gluoncv<0.10.6,>=0.10.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon.vision==0.5.2->autogluon) (0.10.5.post0)\n",
      "Requirement already satisfied: flake8 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (3.8.4)\n",
      "Requirement already satisfied: pyarrow in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (7.0.0)\n",
      "Requirement already satisfied: yacs>=0.1.6 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (0.1.8)\n",
      "Requirement already satisfied: sacremoses>=0.0.38 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (0.0.53)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers>=0.9.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (0.12.1)\n",
      "Requirement already satisfied: sacrebleu in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (2.3.1)\n",
      "Requirement already satisfied: contextvars in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (2.4)\n",
      "Requirement already satisfied: graphviz in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.2->autogluon) (0.8.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.2->autogluon) (1.16.0)\n",
      "Requirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.2->autogluon) (5.6.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2021.11.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (21.3)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (0.11.2)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.0.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.2.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (5.4.1)\n",
      "Requirement already satisfied: click>=6.6 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (8.0.3)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.4.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (6.1)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.7.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (65.6.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.0.3)\n",
      "Requirement already satisfied: zict>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.0.0)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (3.0.3)\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (22.3.1)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (1.0.2)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.0.7)\n",
      "Requirement already satisfied: spacy<4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (3.2.3)\n",
      "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (1.5.27)\n",
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.5.2->autogluon) (4.5.1.48)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.5.2->autogluon) (2.6.0)\n",
      "Requirement already satisfied: autocfg in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.5.2->autogluon) (0.0.8)\n",
      "Requirement already satisfied: pydantic~=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (4.0.0)\n",
      "Requirement already satisfied: holidays>=0.9 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (0.16)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.5.2->autogluon) (0.18.2)\n",
      "Requirement already satisfied: py4j in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.5.2->autogluon) (0.10.9.5)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.5.2->autogluon) (0.38.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (4.28.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (0.11.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.5.2->autogluon) (1.1.0)\n",
      "Requirement already satisfied: typish>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nptyping<1.5.0,>=1.4.4->autogluon.multimodal==0.5.2->autogluon) (1.9.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from omegaconf<2.2.0,>=2.1.1->autogluon.multimodal==0.5.2->autogluon) (4.8)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pandas!=1.4.0,<1.5,>=1.2.5->autogluon.core[all]==0.5.2->autogluon) (2021.3)\n",
      "Requirement already satisfied: statsmodels!=0.12.0,>=0.11 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.5.2->autogluon) (0.13.1)\n",
      "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.5.2->autogluon) (0.29.24)\n",
      "Requirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.5.2->autogluon) (1.26.8)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (2.10.1)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.3.2)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (3.2.0)\n",
      "Requirement already satisfied: frozenlist in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (1.2.0)\n",
      "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (1.43.0)\n",
      "Requirement already satisfied: aiosignal in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (1.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (3.8.0)\n",
      "Requirement already satisfied: virtualenv in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (20.16.5)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (21.2.0)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (0.8.9)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (2.5.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->autogluon.core[all]==0.5.2->autogluon) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->autogluon.core[all]==0.5.2->autogluon) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->autogluon.core[all]==0.5.2->autogluon) (2.0.7)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.5.2->autogluon) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.5.2->autogluon) (1.2.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.5.2->autogluon) (2021.11.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-learn<1.1,>=1.0.0->autogluon.core[all]==0.5.2->autogluon) (3.0.0)\n",
      "Requirement already satisfied: numba>=0.53 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sktime~=0.11.4->autogluon.timeseries[all]==0.5.2->autogluon) (0.53.1)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sktime~=0.11.4->autogluon.timeseries[all]==0.5.2->autogluon) (1.2.13)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers<4.21.0,>=4.18.0->autogluon.multimodal==0.5.2->autogluon) (0.10.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from boto3->autogluon.core[all]==0.5.2->autogluon) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from boto3->autogluon.core[all]==0.5.2->autogluon) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.90 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from boto3->autogluon.core[all]==0.5.2->autogluon) (1.27.95)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from deprecated>=1.2.13->sktime~=0.11.4->autogluon.timeseries[all]==0.5.2->autogluon) (1.13.3)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (3.8.1)\n",
      "Requirement already satisfied: convertdate>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from holidays>=0.9->gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (2.4.0)\n",
      "Requirement already satisfied: hijri-converter in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from holidays>=0.9->gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (2.2.4)\n",
      "Requirement already satisfied: korean-lunar-calendar in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from holidays>=0.9->gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (0.3.1)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from numba>=0.53->sktime~=0.11.4->autogluon.timeseries[all]==0.5.2->autogluon) (0.36.0)\n",
      "Requirement already satisfied: locket in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from partd>=0.3.10->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (0.2.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (1.0.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.4.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.6.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.9.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (2.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.7.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (8.0.15)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (1.0.6)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from statsmodels!=0.12.0,>=0.11->pmdarima~=1.8.2->autogluon.timeseries[all]==0.5.2->autogluon) (0.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (2.13.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (1.3.0)\n",
      "Requirement already satisfied: heapdict in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from zict>=0.1.3->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.0.1)\n",
      "Requirement already satisfied: immutables>=0.9 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from contextvars->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (0.19)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (0.6.1)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (2.2.0)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (2.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jinja2->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.0.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jsonschema->ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (0.18.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from plotly->catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.2->autogluon) (8.0.1)\n",
      "Requirement already satisfied: lxml in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (4.8.0)\n",
      "Requirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (0.4.3)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from virtualenv->ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (2.5.2)\n",
      "Requirement already satisfied: distlib<1,>=0.3.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from virtualenv->ray<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (0.3.6)\n",
      "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from convertdate>=2.3.0->holidays>=0.9->gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (0.5.11)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (4.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.7.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (3.2.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: ipywidgets in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (7.6.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipywidgets) (6.5.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipywidgets) (7.32.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: pickleshare in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.22)\n",
      "Requirement already satisfied: pygments in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: backcall in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (65.6.0)\n",
      "Requirement already satisfied: jupyter-core in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.6)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: argon2-cffi in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: nbconvert in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.3.0)\n",
      "Requirement already satisfied: prometheus-client in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: bleach in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.9)\n",
      "Requirement already satisfied: defusedxml in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: testpath in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: webencodings in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.6)\n"
     ]
    }
   ],
   "source": [
    "# If running on your own computer please refer to AutoGluon installation instructions:\n",
    "# https://auto.gluon.ai/stable/install.html\n",
    "# This notebook assumes running in SageMaker Studio with \"PyTorch 1.12 Python 3.8 CPU Optimized\" kernel.\n",
    "!pip3 install autogluon\n",
    "!pip3 install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad53a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7683df4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt      education  education-num  \\\n",
       "6118    51   Private   39264   Some-college             10   \n",
       "23204   58   Private   51662           10th              6   \n",
       "29590   40   Private  326310   Some-college             10   \n",
       "18116   37   Private  222450        HS-grad              9   \n",
       "33964   62   Private  109190      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data directly from Autogluon datasets.\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "# subsample subset of data for faster demo, try setting this to much larger values\n",
    "subsample_size = 500  \n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e4baaf",
   "metadata": {},
   "source": [
    "In this dataset we want to predict what is the class of the people given the set of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf90380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count        500\n",
      "unique         2\n",
      "top        <=50K\n",
      "freq         365\n",
      "Name: class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# We specify the column of our dataset that is the label.\n",
    "label = 'class'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8379c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221125_121604/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221125_121604/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5665.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.73\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.65\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t1.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t1.13s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.81\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t3.2s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t2.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.19s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221125_121604/\")\n"
     ]
    }
   ],
   "source": [
    "# Run tabular predictor with default settings.\n",
    "predictor = TabularPredictor(label=label).fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b4197",
   "metadata": {},
   "source": [
    "With the default settings Autogluon finds that the WeightedEnsemble_L2 is the best model. With a Validation accuracy of 87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad29a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>169085</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>226203</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>54260</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>176262</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>241185</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt      education  education-num  \\\n",
       "0   31            Private  169085           11th              7   \n",
       "1   17   Self-emp-not-inc  226203           12th              8   \n",
       "2   47            Private   54260      Assoc-voc             11   \n",
       "3   21            Private  176262   Some-college             10   \n",
       "4   17            Private  241185           12th              8   \n",
       "\n",
       "        marital-status        occupation relationship    race      sex  \\\n",
       "0   Married-civ-spouse             Sales         Wife   White   Female   \n",
       "1        Never-married             Sales    Own-child   White     Male   \n",
       "2   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n",
       "3        Never-married   Exec-managerial    Own-child   White   Female   \n",
       "4        Never-married    Prof-specialty    Own-child   White     Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0             0             0              20   United-States  \n",
       "1             0             0              45   United-States  \n",
       "2             0          1887              60   United-States  \n",
       "3             0             0              30   United-States  \n",
       "4             0             0              20   United-States  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "y_test = test_data[label]  # values to predict\n",
    "# delete label column to prove we're not cheating\n",
    "test_data_nolab = test_data.drop(columns=[label])  \n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc70a08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8374449790152523\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8374449790152523\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "463de155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8374449790152523\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8374449790152523\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8374449790152523}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48299c",
   "metadata": {},
   "source": [
    "There is two function of evalutions for tabular predictor, 'evaluate_predictions' where you pass the prediction and the true labels. 'evaluate' where you pass direclty the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23fae483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.842973</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.158744</td>\n",
       "      <td>0.062258</td>\n",
       "      <td>0.579492</td>\n",
       "      <td>0.158744</td>\n",
       "      <td>0.062258</td>\n",
       "      <td>0.579492</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.041671</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>1.129016</td>\n",
       "      <td>0.041671</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>1.129016</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.841130</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.163591</td>\n",
       "      <td>0.064237</td>\n",
       "      <td>0.474408</td>\n",
       "      <td>0.163591</td>\n",
       "      <td>0.064237</td>\n",
       "      <td>0.474408</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.028759</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>0.226991</td>\n",
       "      <td>0.028759</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>0.226991</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.837445</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.039582</td>\n",
       "      <td>0.007091</td>\n",
       "      <td>0.229637</td>\n",
       "      <td>0.039582</td>\n",
       "      <td>0.007091</td>\n",
       "      <td>0.229637</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.837445</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.042729</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.609865</td>\n",
       "      <td>0.003148</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.380228</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.836421</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>1.010078</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>1.010078</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.833453</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.169352</td>\n",
       "      <td>0.060101</td>\n",
       "      <td>0.470258</td>\n",
       "      <td>0.169352</td>\n",
       "      <td>0.060101</td>\n",
       "      <td>0.470258</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.832839</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.203741</td>\n",
       "      <td>0.059756</td>\n",
       "      <td>0.469765</td>\n",
       "      <td>0.203741</td>\n",
       "      <td>0.059756</td>\n",
       "      <td>0.469765</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.828949</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.032964</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>0.351349</td>\n",
       "      <td>0.032964</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>0.351349</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.818610</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.186569</td>\n",
       "      <td>0.020543</td>\n",
       "      <td>3.196307</td>\n",
       "      <td>0.186569</td>\n",
       "      <td>0.020543</td>\n",
       "      <td>3.196307</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.810523</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.156705</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>2.082316</td>\n",
       "      <td>0.156705</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>2.082316</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.725970</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.023242</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.023242</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.695158</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.004656</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.004656</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0      RandomForestGini    0.842973       0.84        0.158744       0.062258   \n",
       "1              CatBoost    0.842461       0.85        0.041671       0.010297   \n",
       "2      RandomForestEntr    0.841130       0.83        0.163591       0.064237   \n",
       "3              LightGBM    0.839799       0.85        0.028759       0.005999   \n",
       "4               XGBoost    0.837445       0.87        0.039582       0.007091   \n",
       "5   WeightedEnsemble_L2    0.837445       0.87        0.042729       0.007671   \n",
       "6            LightGBMXT    0.836421       0.83        0.016908       0.005784   \n",
       "7        ExtraTreesGini    0.833453       0.82        0.169352       0.060101   \n",
       "8        ExtraTreesEntr    0.832839       0.81        0.203741       0.059756   \n",
       "9         LightGBMLarge    0.828949       0.83        0.032964       0.006310   \n",
       "10      NeuralNetFastAI    0.818610       0.82        0.186569       0.020543   \n",
       "11       NeuralNetTorch    0.810523       0.85        0.156705       0.011351   \n",
       "12       KNeighborsUnif    0.725970       0.73        0.023242       0.006256   \n",
       "13       KNeighborsDist    0.695158       0.65        0.022026       0.004328   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.579492                 0.158744                0.062258   \n",
       "1   1.129016                 0.041671                0.010297   \n",
       "2   0.474408                 0.163591                0.064237   \n",
       "3   0.226991                 0.028759                0.005999   \n",
       "4   0.229637                 0.039582                0.007091   \n",
       "5   0.609865                 0.003148                0.000581   \n",
       "6   1.010078                 0.016908                0.005784   \n",
       "7   0.470258                 0.169352                0.060101   \n",
       "8   0.469765                 0.203741                0.059756   \n",
       "9   0.351349                 0.032964                0.006310   \n",
       "10  3.196307                 0.186569                0.020543   \n",
       "11  2.082316                 0.156705                0.011351   \n",
       "12  0.004771                 0.023242                0.006256   \n",
       "13  0.004656                 0.022026                0.004328   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.579492            1       True          5  \n",
       "1            1.129016            1       True          7  \n",
       "2            0.474408            1       True          6  \n",
       "3            0.226991            1       True          4  \n",
       "4            0.229637            1       True         11  \n",
       "5            0.380228            2       True         14  \n",
       "6            1.010078            1       True          3  \n",
       "7            0.470258            1       True          8  \n",
       "8            0.469765            1       True          9  \n",
       "9            0.351349            1       True         13  \n",
       "10           3.196307            1       True         10  \n",
       "11           2.082316            1       True         12  \n",
       "12           0.004771            1       True          1  \n",
       "13           0.004656            1       True          2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f81e4",
   "metadata": {},
   "source": [
    "We use the leaderboard function to compare the tested model of the predictor. We have RandomForestGini with the best score test (accuracy of the test dataset). If we don't have constraint we can choose RandomForestGini as the production model. If we need a model that gives a prediction in less than 0.1s we can select CatBoost. The final decision on the production model can be done using the leaderboard above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c4825",
   "metadata": {},
   "source": [
    "### Using hyperparameter settings\n",
    "#### You can find [here](https://auto.gluon.ai/dev/api/autogluon.tabular.models.html) some models and which hyperparameters you can set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5caed71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n"
     ]
    }
   ],
   "source": [
    "# We need the core lib of Autogluon for hyperparameter\n",
    "import autogluon.core as ag\n",
    "\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be91b2",
   "metadata": {},
   "source": [
    "We are going to use 4 different models Neural Network, Gradient Boost, Random Forest and Cat boost. If you want to use other models or to tune other hyperparameter you can use the [documentation](https://auto.gluon.ai/stable/api/autogluon.predictor.html#autogluon.tabular.TabularPredictor.fit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaba007a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221125_121620/\"\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221125_121620/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    39073\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' <=50K', ' >50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5478.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.92 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.19 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.127965602845955, Train Rows: 34073, Val Rows: 5000\n",
      "Fitting 4 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM ... Tuning model for up to 26.94s of the 119.72s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db405bf67b37468aba241cae6f2b07a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM/T1 ...\n",
      "\t0.8756\t = Validation score   (accuracy)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM/T2 ...\n",
      "\t0.8764\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM/T3 ...\n",
      "\t0.8756\t = Validation score   (accuracy)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM/T4 ...\n",
      "\t0.8186\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM/T5 ...\n",
      "\t0.8742\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest ... Tuning model for up to 26.94s of the 116.55s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe77ce57eb247209b444cab31844cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: RandomForest/T1 ...\n",
      "\t0.8637\t = Validation score   (accuracy)\n",
      "\t4.0s\t = Training   runtime\n",
      "\t1.51s\t = Validation runtime\n",
      "Fitted model: RandomForest/T2 ...\n",
      "\t0.8621\t = Validation score   (accuracy)\n",
      "\t4.96s\t = Training   runtime\n",
      "\t1.62s\t = Validation runtime\n",
      "Fitted model: RandomForest/T3 ...\n",
      "\t0.8575\t = Validation score   (accuracy)\n",
      "\t4.99s\t = Training   runtime\n",
      "\t1.84s\t = Validation runtime\n",
      "Fitted model: RandomForest/T4 ...\n",
      "\t0.8575\t = Validation score   (accuracy)\n",
      "\t4.96s\t = Training   runtime\n",
      "\t1.83s\t = Validation runtime\n",
      "Hyperparameter tuning model: CatBoost ... Tuning model for up to 26.94s of the 88.59s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd7731d550544e68fc21c64241b48a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost/T1 ...\n",
      "\t0.8766\t = Validation score   (accuracy)\n",
      "\t12.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: CatBoost/T2 ...\n",
      "\t0.877\t = Validation score   (accuracy)\n",
      "\t6.25s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch ... Tuning model for up to 26.94s of the 69.96s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "Fitted model: NeuralNetTorch/16846_00000 ...\n",
      "\t0.8514\t = Validation score   (accuracy)\n",
      "\t20.19s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch/16846_00001 ...\n",
      "\t0.8568\t = Validation score   (accuracy)\n",
      "\t19.73s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch/16846_00002 ...\n",
      "\t0.846\t = Validation score   (accuracy)\n",
      "\t19.7s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch/16846_00003 ...\n",
      "\t0.8486\t = Validation score   (accuracy)\n",
      "\t19.63s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.72s of the 39.24s of remaining time.\n",
      "\t0.879\t = Validation score   (accuracy)\n",
      "\t2.43s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 83.24s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221125_121620/\")\n"
     ]
    }
   ],
   "source": [
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "rf_options = {\n",
    "    'n_estimators': 400, # number of estimators\n",
    "    'max_leaf_nodes' : ag.space.Int(lower=500, upper=15000, default=2000), # range of max leaf number per node.\n",
    "}\n",
    "\n",
    "cat_options = {\n",
    "    'learning_rate' : ag.space.Real(0.0,0.2,default=0.05),\n",
    "}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                   'RF': rf_options,\n",
    "                   'CAT': cat_options,\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 2*60  # train various models for ~10 min\n",
    "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "                          # you can use different option like bayesian\n",
    "\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric='acc').fit(\n",
    "    train_data, time_limit=time_limit,\n",
    "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e348a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8751151602006346\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8751151602006346\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc22b135",
   "metadata": {},
   "source": [
    "With Hyperparameter settings we improved the test accuracy going from 0.83 to 0.87."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f9f9370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM/T2</td>\n",
       "      <td>0.875934</td>\n",
       "      <td>0.876400</td>\n",
       "      <td>0.035081</td>\n",
       "      <td>0.017068</td>\n",
       "      <td>0.529088</td>\n",
       "      <td>0.035081</td>\n",
       "      <td>0.017068</td>\n",
       "      <td>0.529088</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.875115</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>1.353800</td>\n",
       "      <td>3.787422</td>\n",
       "      <td>71.307823</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>2.433342</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost/T1</td>\n",
       "      <td>0.874706</td>\n",
       "      <td>0.876600</td>\n",
       "      <td>0.021959</td>\n",
       "      <td>0.013993</td>\n",
       "      <td>12.268428</td>\n",
       "      <td>0.021959</td>\n",
       "      <td>0.013993</td>\n",
       "      <td>12.268428</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM/T1</td>\n",
       "      <td>0.874296</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.037819</td>\n",
       "      <td>0.017509</td>\n",
       "      <td>0.503016</td>\n",
       "      <td>0.037819</td>\n",
       "      <td>0.017509</td>\n",
       "      <td>0.503016</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost/T2</td>\n",
       "      <td>0.873989</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.017755</td>\n",
       "      <td>0.013820</td>\n",
       "      <td>6.253347</td>\n",
       "      <td>0.017755</td>\n",
       "      <td>0.013820</td>\n",
       "      <td>6.253347</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM/T3</td>\n",
       "      <td>0.873887</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.052321</td>\n",
       "      <td>0.029020</td>\n",
       "      <td>0.637372</td>\n",
       "      <td>0.052321</td>\n",
       "      <td>0.029020</td>\n",
       "      <td>0.637372</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM/T5</td>\n",
       "      <td>0.872249</td>\n",
       "      <td>0.874200</td>\n",
       "      <td>0.045976</td>\n",
       "      <td>0.018671</td>\n",
       "      <td>0.582480</td>\n",
       "      <td>0.045976</td>\n",
       "      <td>0.018671</td>\n",
       "      <td>0.582480</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest/T1</td>\n",
       "      <td>0.864367</td>\n",
       "      <td>0.863704</td>\n",
       "      <td>0.343115</td>\n",
       "      <td>1.510821</td>\n",
       "      <td>4.004969</td>\n",
       "      <td>0.343115</td>\n",
       "      <td>1.510821</td>\n",
       "      <td>4.004969</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest/T2</td>\n",
       "      <td>0.860272</td>\n",
       "      <td>0.862061</td>\n",
       "      <td>0.401631</td>\n",
       "      <td>1.623583</td>\n",
       "      <td>4.955801</td>\n",
       "      <td>0.401631</td>\n",
       "      <td>1.623583</td>\n",
       "      <td>4.955801</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest/T4</td>\n",
       "      <td>0.856792</td>\n",
       "      <td>0.857453</td>\n",
       "      <td>0.505308</td>\n",
       "      <td>1.833908</td>\n",
       "      <td>4.957541</td>\n",
       "      <td>0.505308</td>\n",
       "      <td>1.833908</td>\n",
       "      <td>4.957541</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest/T3</td>\n",
       "      <td>0.856792</td>\n",
       "      <td>0.857453</td>\n",
       "      <td>0.537054</td>\n",
       "      <td>1.841641</td>\n",
       "      <td>4.989393</td>\n",
       "      <td>0.537054</td>\n",
       "      <td>1.841641</td>\n",
       "      <td>4.989393</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetTorch/16846_00001</td>\n",
       "      <td>0.853311</td>\n",
       "      <td>0.856800</td>\n",
       "      <td>0.305295</td>\n",
       "      <td>0.154184</td>\n",
       "      <td>19.730800</td>\n",
       "      <td>0.305295</td>\n",
       "      <td>0.154184</td>\n",
       "      <td>19.730800</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NeuralNetTorch/16846_00000</td>\n",
       "      <td>0.851367</td>\n",
       "      <td>0.851400</td>\n",
       "      <td>0.210534</td>\n",
       "      <td>0.069103</td>\n",
       "      <td>20.187272</td>\n",
       "      <td>0.210534</td>\n",
       "      <td>0.069103</td>\n",
       "      <td>20.187272</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NeuralNetTorch/16846_00003</td>\n",
       "      <td>0.849217</td>\n",
       "      <td>0.848600</td>\n",
       "      <td>0.153415</td>\n",
       "      <td>0.129622</td>\n",
       "      <td>19.628535</td>\n",
       "      <td>0.153415</td>\n",
       "      <td>0.129622</td>\n",
       "      <td>19.628535</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NeuralNetTorch/16846_00002</td>\n",
       "      <td>0.844918</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>0.166925</td>\n",
       "      <td>0.128812</td>\n",
       "      <td>19.699261</td>\n",
       "      <td>0.166925</td>\n",
       "      <td>0.128812</td>\n",
       "      <td>19.699261</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBM/T4</td>\n",
       "      <td>0.820248</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.032766</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>0.526468</td>\n",
       "      <td>0.032766</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>0.526468</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  score_test  score_val  pred_time_test  \\\n",
       "0                  LightGBM/T2    0.875934   0.876400        0.035081   \n",
       "1          WeightedEnsemble_L2    0.875115   0.879000        1.353800   \n",
       "2                  CatBoost/T1    0.874706   0.876600        0.021959   \n",
       "3                  LightGBM/T1    0.874296   0.875600        0.037819   \n",
       "4                  CatBoost/T2    0.873989   0.877000        0.017755   \n",
       "5                  LightGBM/T3    0.873887   0.875600        0.052321   \n",
       "6                  LightGBM/T5    0.872249   0.874200        0.045976   \n",
       "7              RandomForest/T1    0.864367   0.863704        0.343115   \n",
       "8              RandomForest/T2    0.860272   0.862061        0.401631   \n",
       "9              RandomForest/T4    0.856792   0.857453        0.505308   \n",
       "10             RandomForest/T3    0.856792   0.857453        0.537054   \n",
       "11  NeuralNetTorch/16846_00001    0.853311   0.856800        0.305295   \n",
       "12  NeuralNetTorch/16846_00000    0.851367   0.851400        0.210534   \n",
       "13  NeuralNetTorch/16846_00003    0.849217   0.848600        0.153415   \n",
       "14  NeuralNetTorch/16846_00002    0.844918   0.846000        0.166925   \n",
       "15                 LightGBM/T4    0.820248   0.818600        0.032766   \n",
       "\n",
       "    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.017068   0.529088                 0.035081                0.017068   \n",
       "1        3.787422  71.307823                 0.005750                0.007946   \n",
       "2        0.013993  12.268428                 0.021959                0.013993   \n",
       "3        0.017509   0.503016                 0.037819                0.017509   \n",
       "4        0.013820   6.253347                 0.017755                0.013820   \n",
       "5        0.029020   0.637372                 0.052321                0.029020   \n",
       "6        0.018671   0.582480                 0.045976                0.018671   \n",
       "7        1.510821   4.004969                 0.343115                1.510821   \n",
       "8        1.623583   4.955801                 0.401631                1.623583   \n",
       "9        1.833908   4.957541                 0.505308                1.833908   \n",
       "10       1.841641   4.989393                 0.537054                1.841641   \n",
       "11       0.154184  19.730800                 0.305295                0.154184   \n",
       "12       0.069103  20.187272                 0.210534                0.069103   \n",
       "13       0.129622  19.628535                 0.153415                0.129622   \n",
       "14       0.128812  19.699261                 0.166925                0.128812   \n",
       "15       0.015358   0.526468                 0.032766                0.015358   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.529088            1       True          2  \n",
       "1            2.433342            2       True         16  \n",
       "2           12.268428            1       True         10  \n",
       "3            0.503016            1       True          1  \n",
       "4            6.253347            1       True         11  \n",
       "5            0.637372            1       True          3  \n",
       "6            0.582480            1       True          5  \n",
       "7            4.004969            1       True          6  \n",
       "8            4.955801            1       True          7  \n",
       "9            4.957541            1       True          9  \n",
       "10           4.989393            1       True          8  \n",
       "11          19.730800            1       True         13  \n",
       "12          20.187272            1       True         12  \n",
       "13          19.628535            1       True         15  \n",
       "14          19.699261            1       True         14  \n",
       "15           0.526468            1       True          4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f225f6e7",
   "metadata": {},
   "source": [
    "CatBoost/T5 and LightGBM/T2 are the best models on the test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acfea80",
   "metadata": {},
   "source": [
    "### Using ensembling techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e9a6114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221125_121748/\"\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221125_121748/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    39073\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' <=50K', ' >50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4171.2 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.92 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.19 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 4 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 11.99s of the 599.73s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e361c3f3217a461390496d73b22a8322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM_BAG_L1/T1 ...\n",
      "\t0.8713\t = Validation score   (accuracy)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T2 ...\n",
      "\t0.8715\t = Validation score   (accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T3 ...\n",
      "\t0.8694\t = Validation score   (accuracy)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T4 ...\n",
      "\t0.8193\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T5 ...\n",
      "\t0.8681\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest_BAG_L1 ... Tuning model for up to 11.99s of the 596.18s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e04e87d789a49aaa2775822e284ebfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Reducing model 'n_estimators' from 400 -> 373 due to low time. Expected time usage reduced from 10.2s -> 9.6s...\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: RandomForest_BAG_L1/T1 ...\n",
      "\t0.8644\t = Validation score   (accuracy)\n",
      "\t4.24s\t = Training   runtime\n",
      "\t1.54s\t = Validation runtime\n",
      "Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 11.99s of the 588.39s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af94486279e845c7a1336de660dcceca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 279.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L1/T1 ...\n",
      "\t0.8704\t = Validation score   (accuracy)\n",
      "\t9.55s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 11.99s of the 578.72s of remaining time.\n",
      "2022-11-25 12:18:20,464\tINFO stopper.py:363 -- Reached timeout of 9.59327265955925 seconds. Stopping all trials.\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T1 ...\n",
      "\t0.8395\t = Validation score   (accuracy)\n",
      "\t5.84s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 234.38s of the 567.62s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8733\t = Validation score   (accuracy)\n",
      "\t3.15s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 229.22s of the 562.47s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8743\t = Validation score   (accuracy)\n",
      "\t3.14s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T3 ... Training model for up to 223.94s of the 557.19s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t3.55s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T4 ... Training model for up to 218.18s of the 551.43s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8214\t = Validation score   (accuracy)\n",
      "\t3.2s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T5 ... Training model for up to 212.54s of the 545.79s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8715\t = Validation score   (accuracy)\n",
      "\t3.34s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L1/T1 ... Training model for up to 207.12s of the 540.37s of remaining time.\n",
      "\t0.8644\t = Validation score   (accuracy)\n",
      "\t4.24s\t = Training   runtime\n",
      "\t1.54s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1/T1 ... Training model for up to 207.06s of the 540.31s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t91.49s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T1 ... Training model for up to 122.3s of the 455.55s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.848\t = Validation score   (accuracy)\n",
      "\t28.68s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Completed 1/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 430.11s of remaining time.\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t8.64s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting 4 L2 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 12.64s of the 421.4s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdd8db24e8242a4958e2896b69a7cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM_BAG_L2/T1 ...\n",
      "\t0.8741\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L2/T2 ...\n",
      "\t0.8737\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L2/T3 ...\n",
      "\t0.8742\t = Validation score   (accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L2/T4 ...\n",
      "\t0.8398\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L2/T5 ...\n",
      "\t0.8728\t = Validation score   (accuracy)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest_BAG_L2 ... Tuning model for up to 12.64s of the 417.59s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96fb508749044746a1bb0406732a228c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Reducing model 'n_estimators' from 400 -> 378 due to low time. Expected time usage reduced from 10.6s -> 10.1s...\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: RandomForest_BAG_L2/T1 ...\n",
      "\t0.8739\t = Validation score   (accuracy)\n",
      "\t9.06s\t = Training   runtime\n",
      "\t1.52s\t = Validation runtime\n",
      "Hyperparameter tuning model: CatBoost_BAG_L2 ... Tuning model for up to 12.64s of the 404.95s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc46411051b4c979f936ebafc7247d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 55.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L2/T1 ...\n",
      "\t0.8733\t = Validation score   (accuracy)\n",
      "\t3.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: CatBoost_BAG_L2/T2 ...\n",
      "\t0.8729\t = Validation score   (accuracy)\n",
      "\t2.92s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: CatBoost_BAG_L2/T3 ...\n",
      "\t0.8747\t = Validation score   (accuracy)\n",
      "\t3.32s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L2 ... Tuning model for up to 12.64s of the 394.76s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "2022-11-25 12:21:25,153\tINFO stopper.py:363 -- Reached timeout of 10.111261961485866 seconds. Stopping all trials.\n",
      "Fitted model: NeuralNetTorch_BAG_L2/T1 ...\n",
      "\t0.8717\t = Validation score   (accuracy)\n",
      "\t6.14s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L2/T2 ...\n",
      "\t0.8722\t = Validation score   (accuracy)\n",
      "\t6.63s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T1 ... Training model for up to 242.26s of the 382.79s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8739\t = Validation score   (accuracy)\n",
      "\t3.38s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T2 ... Training model for up to 236.96s of the 377.49s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T3 ... Training model for up to 231.27s of the 371.8s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8744\t = Validation score   (accuracy)\n",
      "\t3.69s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T4 ... Training model for up to 225.41s of the 365.94s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8398\t = Validation score   (accuracy)\n",
      "\t3.41s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2/T5 ... Training model for up to 219.73s of the 360.26s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8739\t = Validation score   (accuracy)\n",
      "\t3.68s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L2/T1 ... Training model for up to 213.85s of the 354.38s of remaining time.\n",
      "\t0.8739\t = Validation score   (accuracy)\n",
      "\t9.06s\t = Training   runtime\n",
      "\t1.52s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2/T1 ... Training model for up to 213.77s of the 354.3s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8746\t = Validation score   (accuracy)\n",
      "\t16.36s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2/T2 ... Training model for up to 198.3s of the 338.83s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8749\t = Validation score   (accuracy)\n",
      "\t15.01s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2/T3 ... Training model for up to 183.54s of the 324.07s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8751\t = Validation score   (accuracy)\n",
      "\t27.19s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2/T1 ... Training model for up to 157.15s of the 297.68s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.873\t = Validation score   (accuracy)\n",
      "\t31.89s\t = Training   runtime\n",
      "\t1.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2/T2 ... Training model for up to 128.66s of the 269.19s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8743\t = Validation score   (accuracy)\n",
      "\t31.3s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Completed 1/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 241.89s of remaining time.\n",
      "\t0.8751\t = Validation score   (accuracy)\n",
      "\t11.88s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting 4 L3 models ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L3 ... Tuning model for up to 10.35s of the 229.92s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdc45c03b3c44d596ecdfb34d9b1d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM_BAG_L3/T1 ...\n",
      "\t0.8815\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L3/T2 ...\n",
      "\t0.8833\t = Validation score   (accuracy)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L3/T3 ...\n",
      "\t0.8815\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L3/T4 ...\n",
      "\t0.8464\t = Validation score   (accuracy)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L3/T5 ...\n",
      "\t0.8815\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForest_BAG_L3 ... Tuning model for up to 10.35s of the 225.86s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915461704d1249d591ad15500e3c32d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Reducing model 'n_estimators' from 400 -> 257 due to low time. Expected time usage reduced from 12.8s -> 8.2s...\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: RandomForest_BAG_L3/T1 ...\n",
      "\t0.8715\t = Validation score   (accuracy)\n",
      "\t7.38s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Hyperparameter tuning model: CatBoost_BAG_L3 ... Tuning model for up to 10.35s of the 215.93s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8223f7401020412f8155b0331aecd68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 222.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L3/T1 ...\n",
      "\t0.8828\t = Validation score   (accuracy)\n",
      "\t8.22s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L3 ... Tuning model for up to 10.35s of the 207.57s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "Fitted model: NeuralNetTorch_BAG_L3/T1 ...\n",
      "\t0.88\t = Validation score   (accuracy)\n",
      "\t3.97s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L3/T2 ...\n",
      "\t0.8801\t = Validation score   (accuracy)\n",
      "\t4.13s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3/T1 ... Training model for up to 197.99s of the 197.98s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8751\t = Validation score   (accuracy)\n",
      "\t3.19s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3/T2 ... Training model for up to 192.98s of the 192.97s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8751\t = Validation score   (accuracy)\n",
      "\t3.46s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3/T3 ... Training model for up to 187.28s of the 187.27s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8747\t = Validation score   (accuracy)\n",
      "\t3.85s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3/T4 ... Training model for up to 181.37s of the 181.36s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8422\t = Validation score   (accuracy)\n",
      "\t3.14s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3/T5 ... Training model for up to 176.1s of the 176.09s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8751\t = Validation score   (accuracy)\n",
      "\t3.46s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L3/T1 ... Training model for up to 170.55s of the 170.54s of remaining time.\n",
      "\t0.8715\t = Validation score   (accuracy)\n",
      "\t7.38s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3/T1 ... Training model for up to 170.48s of the 170.47s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8753\t = Validation score   (accuracy)\n",
      "\t21.11s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3/T1 ... Training model for up to 154.67s of the 154.66s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8747\t = Validation score   (accuracy)\n",
      "\t30.21s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3/T2 ... Training model for up to 125.48s of the 125.47s of remaining time.\n",
      "\tFitting 4 child models (S1F2 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8743\t = Validation score   (accuracy)\n",
      "\t28.57s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Completed 1/2 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.0s of the 98.29s of remaining time.\n",
      "\t0.8753\t = Validation score   (accuracy)\n",
      "\t9.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 511.51s ... Best model: \"WeightedEnsemble_L4\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221125_121748/\")\n"
     ]
    }
   ],
   "source": [
    "# We define the same set of hyperparameter and we will use ensembling.\n",
    "\n",
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "rf_options = {\n",
    "    'n_estimators': 400,\n",
    "    'max_leaf_nodes' : ag.space.Int(lower=500, upper=15000, default=2000),\n",
    "}\n",
    "\n",
    "cat_options = {\n",
    "    'learning_rate' : ag.space.Real(0.0,0.2,default=0.05),\n",
    "}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                   'RF': rf_options,\n",
    "                   'CAT': cat_options,\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 10*60  # train various models for ~10 min\n",
    "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "# To run ensembling you have to pass the arguments num_bag_folds, num_bag_sets and num_stack_levels.\n",
    "# You can also pass auto_stack=True run ensembling if you don't know what set of\n",
    "# num_bag_folds, num_bag_sets and num_stack_levels to use.\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric='acc').fit(\n",
    "    train_data, time_limit=time_limit, #auto_stack=True,\n",
    "    num_bag_folds=5, num_bag_sets=2, num_stack_levels=2,\n",
    "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "435a071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8757293479373528\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8757293479373528\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolab)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f3c54",
   "metadata": {},
   "source": [
    "We improved the accuracy from 0.8751 to 0.8757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69bd18e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L2/T5</td>\n",
       "      <td>0.876548</td>\n",
       "      <td>0.873928</td>\n",
       "      <td>2.496034</td>\n",
       "      <td>4.421388</td>\n",
       "      <td>144.474092</td>\n",
       "      <td>0.134856</td>\n",
       "      <td>0.167992</td>\n",
       "      <td>3.682369</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L2/T2</td>\n",
       "      <td>0.876446</td>\n",
       "      <td>0.874773</td>\n",
       "      <td>2.455060</td>\n",
       "      <td>4.357116</td>\n",
       "      <td>144.298052</td>\n",
       "      <td>0.093883</td>\n",
       "      <td>0.103721</td>\n",
       "      <td>3.506329</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch_BAG_L2/T2</td>\n",
       "      <td>0.876241</td>\n",
       "      <td>0.874287</td>\n",
       "      <td>3.128216</td>\n",
       "      <td>5.040683</td>\n",
       "      <td>172.095147</td>\n",
       "      <td>0.767038</td>\n",
       "      <td>0.787287</td>\n",
       "      <td>31.303424</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_BAG_L2/T3</td>\n",
       "      <td>0.876139</td>\n",
       "      <td>0.875106</td>\n",
       "      <td>2.411528</td>\n",
       "      <td>4.360543</td>\n",
       "      <td>167.986573</td>\n",
       "      <td>0.050351</td>\n",
       "      <td>0.107147</td>\n",
       "      <td>27.194849</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L2/T1</td>\n",
       "      <td>0.876036</td>\n",
       "      <td>0.873928</td>\n",
       "      <td>2.481079</td>\n",
       "      <td>4.421201</td>\n",
       "      <td>144.171853</td>\n",
       "      <td>0.119901</td>\n",
       "      <td>0.167805</td>\n",
       "      <td>3.380130</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.875934</td>\n",
       "      <td>0.875131</td>\n",
       "      <td>2.461216</td>\n",
       "      <td>4.512600</td>\n",
       "      <td>194.881244</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.064934</td>\n",
       "      <td>11.882261</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost_BAG_L2/T1</td>\n",
       "      <td>0.875729</td>\n",
       "      <td>0.874645</td>\n",
       "      <td>2.407532</td>\n",
       "      <td>4.378627</td>\n",
       "      <td>157.155596</td>\n",
       "      <td>0.046355</td>\n",
       "      <td>0.125231</td>\n",
       "      <td>16.363873</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost_BAG_L3/T1</td>\n",
       "      <td>0.875729</td>\n",
       "      <td>0.875259</td>\n",
       "      <td>5.602559</td>\n",
       "      <td>8.980485</td>\n",
       "      <td>310.395371</td>\n",
       "      <td>0.053654</td>\n",
       "      <td>0.118517</td>\n",
       "      <td>21.109342</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WeightedEnsemble_L4</td>\n",
       "      <td>0.875729</td>\n",
       "      <td>0.875259</td>\n",
       "      <td>5.603869</td>\n",
       "      <td>9.042653</td>\n",
       "      <td>320.114155</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.062168</td>\n",
       "      <td>9.718784</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest_BAG_L3/T1</td>\n",
       "      <td>0.875422</td>\n",
       "      <td>0.871548</td>\n",
       "      <td>5.767019</td>\n",
       "      <td>9.913685</td>\n",
       "      <td>296.668267</td>\n",
       "      <td>0.218114</td>\n",
       "      <td>1.051717</td>\n",
       "      <td>7.382238</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetTorch_BAG_L3/T2</td>\n",
       "      <td>0.875422</td>\n",
       "      <td>0.874261</td>\n",
       "      <td>6.304443</td>\n",
       "      <td>9.632116</td>\n",
       "      <td>317.858592</td>\n",
       "      <td>0.755538</td>\n",
       "      <td>0.770148</td>\n",
       "      <td>28.572562</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetTorch_BAG_L3/T1</td>\n",
       "      <td>0.875320</td>\n",
       "      <td>0.874696</td>\n",
       "      <td>6.881378</td>\n",
       "      <td>9.996569</td>\n",
       "      <td>319.498260</td>\n",
       "      <td>1.332473</td>\n",
       "      <td>1.134601</td>\n",
       "      <td>30.212231</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CatBoost_BAG_L2/T2</td>\n",
       "      <td>0.875218</td>\n",
       "      <td>0.874926</td>\n",
       "      <td>2.409073</td>\n",
       "      <td>4.340520</td>\n",
       "      <td>155.804134</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>0.087124</td>\n",
       "      <td>15.012411</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CatBoost_BAG_L1/T1</td>\n",
       "      <td>0.875115</td>\n",
       "      <td>0.874466</td>\n",
       "      <td>0.106084</td>\n",
       "      <td>0.183347</td>\n",
       "      <td>91.489487</td>\n",
       "      <td>0.106084</td>\n",
       "      <td>0.183347</td>\n",
       "      <td>91.489487</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.875115</td>\n",
       "      <td>0.874466</td>\n",
       "      <td>0.107770</td>\n",
       "      <td>0.243849</td>\n",
       "      <td>100.125840</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.060502</td>\n",
       "      <td>8.636353</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBM_BAG_L1/T1</td>\n",
       "      <td>0.874910</td>\n",
       "      <td>0.873288</td>\n",
       "      <td>0.237961</td>\n",
       "      <td>0.376976</td>\n",
       "      <td>3.148822</td>\n",
       "      <td>0.237961</td>\n",
       "      <td>0.376976</td>\n",
       "      <td>3.148822</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LightGBM_BAG_L2/T3</td>\n",
       "      <td>0.874808</td>\n",
       "      <td>0.874363</td>\n",
       "      <td>2.518229</td>\n",
       "      <td>4.467771</td>\n",
       "      <td>144.484174</td>\n",
       "      <td>0.157051</td>\n",
       "      <td>0.214375</td>\n",
       "      <td>3.692451</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBM_BAG_L1/T2</td>\n",
       "      <td>0.874706</td>\n",
       "      <td>0.874338</td>\n",
       "      <td>0.217613</td>\n",
       "      <td>0.327338</td>\n",
       "      <td>3.142780</td>\n",
       "      <td>0.217613</td>\n",
       "      <td>0.327338</td>\n",
       "      <td>3.142780</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBM_BAG_L3/T2</td>\n",
       "      <td>0.874706</td>\n",
       "      <td>0.875106</td>\n",
       "      <td>5.643369</td>\n",
       "      <td>8.960145</td>\n",
       "      <td>292.743650</td>\n",
       "      <td>0.094464</td>\n",
       "      <td>0.098177</td>\n",
       "      <td>3.457620</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LightGBM_BAG_L1/T3</td>\n",
       "      <td>0.874296</td>\n",
       "      <td>0.872495</td>\n",
       "      <td>0.250929</td>\n",
       "      <td>0.428586</td>\n",
       "      <td>3.554370</td>\n",
       "      <td>0.250929</td>\n",
       "      <td>0.428586</td>\n",
       "      <td>3.554370</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LightGBM_BAG_L3/T5</td>\n",
       "      <td>0.874092</td>\n",
       "      <td>0.875131</td>\n",
       "      <td>5.705968</td>\n",
       "      <td>9.052336</td>\n",
       "      <td>292.746080</td>\n",
       "      <td>0.157063</td>\n",
       "      <td>0.190368</td>\n",
       "      <td>3.460050</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LightGBM_BAG_L1/T5</td>\n",
       "      <td>0.873682</td>\n",
       "      <td>0.871523</td>\n",
       "      <td>0.230989</td>\n",
       "      <td>0.373916</td>\n",
       "      <td>3.340849</td>\n",
       "      <td>0.230989</td>\n",
       "      <td>0.373916</td>\n",
       "      <td>3.340849</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NeuralNetTorch_BAG_L2/T1</td>\n",
       "      <td>0.873682</td>\n",
       "      <td>0.872956</td>\n",
       "      <td>3.666874</td>\n",
       "      <td>5.395929</td>\n",
       "      <td>172.678498</td>\n",
       "      <td>1.305696</td>\n",
       "      <td>1.142533</td>\n",
       "      <td>31.886775</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LightGBM_BAG_L3/T1</td>\n",
       "      <td>0.873682</td>\n",
       "      <td>0.875131</td>\n",
       "      <td>5.676495</td>\n",
       "      <td>9.018267</td>\n",
       "      <td>292.476849</td>\n",
       "      <td>0.127590</td>\n",
       "      <td>0.156299</td>\n",
       "      <td>3.190819</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LightGBM_BAG_L3/T3</td>\n",
       "      <td>0.873170</td>\n",
       "      <td>0.874722</td>\n",
       "      <td>5.668790</td>\n",
       "      <td>9.007225</td>\n",
       "      <td>293.136432</td>\n",
       "      <td>0.119885</td>\n",
       "      <td>0.145257</td>\n",
       "      <td>3.850402</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomForest_BAG_L2/T1</td>\n",
       "      <td>0.872966</td>\n",
       "      <td>0.873903</td>\n",
       "      <td>2.673306</td>\n",
       "      <td>5.769068</td>\n",
       "      <td>149.856645</td>\n",
       "      <td>0.312128</td>\n",
       "      <td>1.515672</td>\n",
       "      <td>9.064922</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForest_BAG_L1/T1</td>\n",
       "      <td>0.867540</td>\n",
       "      <td>0.864382</td>\n",
       "      <td>0.335617</td>\n",
       "      <td>1.536195</td>\n",
       "      <td>4.238518</td>\n",
       "      <td>0.335617</td>\n",
       "      <td>1.536195</td>\n",
       "      <td>4.238518</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T1</td>\n",
       "      <td>0.850957</td>\n",
       "      <td>0.848028</td>\n",
       "      <td>0.804966</td>\n",
       "      <td>0.745541</td>\n",
       "      <td>28.678173</td>\n",
       "      <td>0.804966</td>\n",
       "      <td>0.745541</td>\n",
       "      <td>28.678173</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LightGBM_BAG_L3/T4</td>\n",
       "      <td>0.840823</td>\n",
       "      <td>0.842244</td>\n",
       "      <td>5.704303</td>\n",
       "      <td>9.059768</td>\n",
       "      <td>292.430381</td>\n",
       "      <td>0.155398</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>3.144351</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LightGBM_BAG_L2/T4</td>\n",
       "      <td>0.837854</td>\n",
       "      <td>0.839813</td>\n",
       "      <td>2.513749</td>\n",
       "      <td>4.443081</td>\n",
       "      <td>144.198497</td>\n",
       "      <td>0.152571</td>\n",
       "      <td>0.189685</td>\n",
       "      <td>3.406774</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LightGBM_BAG_L1/T4</td>\n",
       "      <td>0.820760</td>\n",
       "      <td>0.821411</td>\n",
       "      <td>0.177018</td>\n",
       "      <td>0.281497</td>\n",
       "      <td>3.198724</td>\n",
       "      <td>0.177018</td>\n",
       "      <td>0.281497</td>\n",
       "      <td>3.198724</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  score_test  score_val  pred_time_test  \\\n",
       "0         LightGBM_BAG_L2/T5    0.876548   0.873928        2.496034   \n",
       "1         LightGBM_BAG_L2/T2    0.876446   0.874773        2.455060   \n",
       "2   NeuralNetTorch_BAG_L2/T2    0.876241   0.874287        3.128216   \n",
       "3         CatBoost_BAG_L2/T3    0.876139   0.875106        2.411528   \n",
       "4         LightGBM_BAG_L2/T1    0.876036   0.873928        2.481079   \n",
       "5        WeightedEnsemble_L3    0.875934   0.875131        2.461216   \n",
       "6         CatBoost_BAG_L2/T1    0.875729   0.874645        2.407532   \n",
       "7         CatBoost_BAG_L3/T1    0.875729   0.875259        5.602559   \n",
       "8        WeightedEnsemble_L4    0.875729   0.875259        5.603869   \n",
       "9     RandomForest_BAG_L3/T1    0.875422   0.871548        5.767019   \n",
       "10  NeuralNetTorch_BAG_L3/T2    0.875422   0.874261        6.304443   \n",
       "11  NeuralNetTorch_BAG_L3/T1    0.875320   0.874696        6.881378   \n",
       "12        CatBoost_BAG_L2/T2    0.875218   0.874926        2.409073   \n",
       "13        CatBoost_BAG_L1/T1    0.875115   0.874466        0.106084   \n",
       "14       WeightedEnsemble_L2    0.875115   0.874466        0.107770   \n",
       "15        LightGBM_BAG_L1/T1    0.874910   0.873288        0.237961   \n",
       "16        LightGBM_BAG_L2/T3    0.874808   0.874363        2.518229   \n",
       "17        LightGBM_BAG_L1/T2    0.874706   0.874338        0.217613   \n",
       "18        LightGBM_BAG_L3/T2    0.874706   0.875106        5.643369   \n",
       "19        LightGBM_BAG_L1/T3    0.874296   0.872495        0.250929   \n",
       "20        LightGBM_BAG_L3/T5    0.874092   0.875131        5.705968   \n",
       "21        LightGBM_BAG_L1/T5    0.873682   0.871523        0.230989   \n",
       "22  NeuralNetTorch_BAG_L2/T1    0.873682   0.872956        3.666874   \n",
       "23        LightGBM_BAG_L3/T1    0.873682   0.875131        5.676495   \n",
       "24        LightGBM_BAG_L3/T3    0.873170   0.874722        5.668790   \n",
       "25    RandomForest_BAG_L2/T1    0.872966   0.873903        2.673306   \n",
       "26    RandomForest_BAG_L1/T1    0.867540   0.864382        0.335617   \n",
       "27  NeuralNetTorch_BAG_L1/T1    0.850957   0.848028        0.804966   \n",
       "28        LightGBM_BAG_L3/T4    0.840823   0.842244        5.704303   \n",
       "29        LightGBM_BAG_L2/T4    0.837854   0.839813        2.513749   \n",
       "30        LightGBM_BAG_L1/T4    0.820760   0.821411        0.177018   \n",
       "\n",
       "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        4.421388  144.474092                 0.134856   \n",
       "1        4.357116  144.298052                 0.093883   \n",
       "2        5.040683  172.095147                 0.767038   \n",
       "3        4.360543  167.986573                 0.050351   \n",
       "4        4.421201  144.171853                 0.119901   \n",
       "5        4.512600  194.881244                 0.001792   \n",
       "6        4.378627  157.155596                 0.046355   \n",
       "7        8.980485  310.395371                 0.053654   \n",
       "8        9.042653  320.114155                 0.001310   \n",
       "9        9.913685  296.668267                 0.218114   \n",
       "10       9.632116  317.858592                 0.755538   \n",
       "11       9.996569  319.498260                 1.332473   \n",
       "12       4.340520  155.804134                 0.047896   \n",
       "13       0.183347   91.489487                 0.106084   \n",
       "14       0.243849  100.125840                 0.001687   \n",
       "15       0.376976    3.148822                 0.237961   \n",
       "16       4.467771  144.484174                 0.157051   \n",
       "17       0.327338    3.142780                 0.217613   \n",
       "18       8.960145  292.743650                 0.094464   \n",
       "19       0.428586    3.554370                 0.250929   \n",
       "20       9.052336  292.746080                 0.157063   \n",
       "21       0.373916    3.340849                 0.230989   \n",
       "22       5.395929  172.678498                 1.305696   \n",
       "23       9.018267  292.476849                 0.127590   \n",
       "24       9.007225  293.136432                 0.119885   \n",
       "25       5.769068  149.856645                 0.312128   \n",
       "26       1.536195    4.238518                 0.335617   \n",
       "27       0.745541   28.678173                 0.804966   \n",
       "28       9.059768  292.430381                 0.155398   \n",
       "29       4.443081  144.198497                 0.152571   \n",
       "30       0.281497    3.198724                 0.177018   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.167992           3.682369            2       True   \n",
       "1                 0.103721           3.506329            2       True   \n",
       "2                 0.787287          31.303424            2       True   \n",
       "3                 0.107147          27.194849            2       True   \n",
       "4                 0.167805           3.380130            2       True   \n",
       "5                 0.064934          11.882261            3       True   \n",
       "6                 0.125231          16.363873            2       True   \n",
       "7                 0.118517          21.109342            3       True   \n",
       "8                 0.062168           9.718784            4       True   \n",
       "9                 1.051717           7.382238            3       True   \n",
       "10                0.770148          28.572562            3       True   \n",
       "11                1.134601          30.212231            3       True   \n",
       "12                0.087124          15.012411            2       True   \n",
       "13                0.183347          91.489487            1       True   \n",
       "14                0.060502           8.636353            2       True   \n",
       "15                0.376976           3.148822            1       True   \n",
       "16                0.214375           3.692451            2       True   \n",
       "17                0.327338           3.142780            1       True   \n",
       "18                0.098177           3.457620            3       True   \n",
       "19                0.428586           3.554370            1       True   \n",
       "20                0.190368           3.460050            3       True   \n",
       "21                0.373916           3.340849            1       True   \n",
       "22                1.142533          31.886775            2       True   \n",
       "23                0.156299           3.190819            3       True   \n",
       "24                0.145257           3.850402            3       True   \n",
       "25                1.515672           9.064922            2       True   \n",
       "26                1.536195           4.238518            1       True   \n",
       "27                0.745541          28.678173            1       True   \n",
       "28                0.197800           3.144351            3       True   \n",
       "29                0.189685           3.406774            2       True   \n",
       "30                0.281497           3.198724            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          14  \n",
       "1          11  \n",
       "2          20  \n",
       "3          18  \n",
       "4          10  \n",
       "5          21  \n",
       "6          16  \n",
       "7          28  \n",
       "8          31  \n",
       "9          27  \n",
       "10         30  \n",
       "11         29  \n",
       "12         17  \n",
       "13          7  \n",
       "14          9  \n",
       "15          1  \n",
       "16         12  \n",
       "17          2  \n",
       "18         23  \n",
       "19          3  \n",
       "20         26  \n",
       "21          5  \n",
       "22         19  \n",
       "23         22  \n",
       "24         24  \n",
       "25         15  \n",
       "26          6  \n",
       "27          8  \n",
       "28         25  \n",
       "29         13  \n",
       "30          4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e9864",
   "metadata": {},
   "source": [
    "## Extra automation with Longer training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7a44698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221128_020212/\"\n",
      "Presets specified: ['best_quality']\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Values in column 'class' used as sample weights instead of predictive features. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221128_020212/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    39073\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3946.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.92 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.4s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.19 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.45s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 13 L1 models ...\n",
      "Hyperparameter tuning model: KNeighborsUnif_BAG_L1 ... Tuning model for up to 31.15s of the 3599.54s of remaining time.\n",
      "\tNo hyperparameter search space specified for KNeighborsUnif. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "Warning: Exception caused KNeighborsUnif_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1380, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1001, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 182, in _hyperparameter_tune\n",
      "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1080, in _hyperparameter_tune\n",
      "    model_path = model_info['path']\n",
      "TypeError: string indices must be integers\n",
      "string indices must be integers\n",
      "Hyperparameter tuning model: KNeighborsDist_BAG_L1 ... Tuning model for up to 31.15s of the 3598.67s of remaining time.\n",
      "\tNo hyperparameter search space specified for KNeighborsDist. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "Warning: Exception caused KNeighborsDist_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1380, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1001, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 182, in _hyperparameter_tune\n",
      "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1080, in _hyperparameter_tune\n",
      "    model_path = model_info['path']\n",
      "TypeError: string indices must be integers\n",
      "string indices must be integers\n",
      "Hyperparameter tuning model: LightGBMXT_BAG_L1 ... Tuning model for up to 31.15s of the 3597.9s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c43c5f063542a2a4b60aaafca120bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.132242\n",
      "[2000]\tvalid_set's binary_error: 0.130604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: LightGBMXT_BAG_L1/T1 ...\n",
      "\t0.8727\t = Validation score   (accuracy)\n",
      "\t3.19s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitted model: LightGBMXT_BAG_L1/T2 ...\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitted model: LightGBMXT_BAG_L1/T3 ...\n",
      "\t0.8698\t = Validation score   (accuracy)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitted model: LightGBMXT_BAG_L1/T4 ...\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t16.42s\t = Training   runtime\n",
      "\t1.11s\t = Validation runtime\n",
      "Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 31.15s of the 3569.53s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bdd01c535b4a2ca83e5bbccb53ccb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.125281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 497. Best iteration is:\n",
      "\t[495]\tvalid_set's binary_error: 0.125896\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: LightGBM_BAG_L1/T1 ...\n",
      "\t0.8747\t = Validation score   (accuracy)\n",
      "\t1.63s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T2 ...\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T3 ...\n",
      "\t0.8755\t = Validation score   (accuracy)\n",
      "\t2.48s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T4 ...\n",
      "\t0.8747\t = Validation score   (accuracy)\n",
      "\t7.0s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T5 ...\n",
      "\t0.8759\t = Validation score   (accuracy)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T6 ...\n",
      "\t0.8743\t = Validation score   (accuracy)\n",
      "\t2.81s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T7 ...\n",
      "\t0.8757\t = Validation score   (accuracy)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T8 ...\n",
      "\t0.8759\t = Validation score   (accuracy)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitted model: LightGBM_BAG_L1/T9 ...\n",
      "\t0.8741\t = Validation score   (accuracy)\n",
      "\t3.77s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Hyperparameter tuning model: RandomForestGini_BAG_L1 ... Tuning model for up to 31.15s of the 3541.47s of remaining time.\n",
      "\tNo hyperparameter search space specified for RandomForestGini. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "Warning: Exception caused RandomForestGini_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1380, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1001, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 182, in _hyperparameter_tune\n",
      "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1080, in _hyperparameter_tune\n",
      "    model_path = model_info['path']\n",
      "TypeError: string indices must be integers\n",
      "string indices must be integers\n",
      "Hyperparameter tuning model: RandomForestEntr_BAG_L1 ... Tuning model for up to 31.15s of the 3531.82s of remaining time.\n",
      "\tNo hyperparameter search space specified for RandomForestEntr. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "Warning: Exception caused RandomForestEntr_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1380, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1001, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 182, in _hyperparameter_tune\n",
      "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1080, in _hyperparameter_tune\n",
      "    model_path = model_info['path']\n",
      "TypeError: string indices must be integers\n",
      "string indices must be integers\n",
      "Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 31.15s of the 3520.58s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfda92fb95644ba4a580abc5961030df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 428.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CatBoost_BAG_L1/T1 ...\n",
      "\t0.8755\t = Validation score   (accuracy)\n",
      "\t24.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: ExtraTreesGini_BAG_L1 ... Tuning model for up to 31.15s of the 3495.53s of remaining time.\n",
      "\tNo hyperparameter search space specified for ExtraTreesGini. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "Warning: Exception caused ExtraTreesGini_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1380, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1001, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 182, in _hyperparameter_tune\n",
      "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1080, in _hyperparameter_tune\n",
      "    model_path = model_info['path']\n",
      "TypeError: string indices must be integers\n",
      "string indices must be integers\n",
      "Hyperparameter tuning model: ExtraTreesEntr_BAG_L1 ... Tuning model for up to 31.15s of the 3487.32s of remaining time.\n",
      "\tNo hyperparameter search space specified for ExtraTreesEntr. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "Warning: Exception caused ExtraTreesEntr_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1380, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1001, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 182, in _hyperparameter_tune\n",
      "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1080, in _hyperparameter_tune\n",
      "    model_path = model_info['path']\n",
      "TypeError: string indices must be integers\n",
      "string indices must be integers\n",
      "Hyperparameter tuning model: NeuralNetFastAI_BAG_L1 ... Tuning model for up to 31.15s of the 3477.67s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "2022-11-28 02:04:42,325\tINFO stopper.py:363 -- Reached timeout of 24.9199501490593 seconds. Stopping all trials.\n",
      "Fitted model: NeuralNetFastAI_BAG_L1/T1 ...\n",
      "\t0.8414\t = Validation score   (accuracy)\n",
      "\t17.8s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitted model: NeuralNetFastAI_BAG_L1/T2 ...\n",
      "\t0.8583\t = Validation score   (accuracy)\n",
      "\t19.62s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitted model: NeuralNetFastAI_BAG_L1/T3 ...\n",
      "\t0.8393\t = Validation score   (accuracy)\n",
      "\t18.01s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitted model: NeuralNetFastAI_BAG_L1/T4 ...\n",
      "\t0.8557\t = Validation score   (accuracy)\n",
      "\t20.12s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Hyperparameter tuning model: XGBoost_BAG_L1 ... Tuning model for up to 31.15s of the 3449.58s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c93bb76e6a400fb75f4cbe0ebd0b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: XGBoost_BAG_L1/T1 ...\n",
      "\t0.8776\t = Validation score   (accuracy)\n",
      "\t2.96s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitted model: XGBoost_BAG_L1/T2 ...\n",
      "\t0.8716\t = Validation score   (accuracy)\n",
      "\t2.96s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitted model: XGBoost_BAG_L1/T3 ...\n",
      "\t0.8712\t = Validation score   (accuracy)\n",
      "\t3.58s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitted model: XGBoost_BAG_L1/T4 ...\n",
      "\t0.8712\t = Validation score   (accuracy)\n",
      "\t2.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: XGBoost_BAG_L1/T5 ...\n",
      "\t0.8716\t = Validation score   (accuracy)\n",
      "\t3.99s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitted model: XGBoost_BAG_L1/T6 ...\n",
      "\t0.8684\t = Validation score   (accuracy)\n",
      "\t2.14s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitted model: XGBoost_BAG_L1/T7 ...\n",
      "\t0.8678\t = Validation score   (accuracy)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitted model: XGBoost_BAG_L1/T8 ...\n",
      "\t0.8659\t = Validation score   (accuracy)\n",
      "\t3.96s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 31.15s of the 3424.81s of remaining time.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "2022-11-28 02:05:34,300\tINFO stopper.py:363 -- Reached timeout of 24.9199501490593 seconds. Stopping all trials.\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T1 ...\n",
      "\t0.8448\t = Validation score   (accuracy)\n",
      "\t19.91s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T2 ...\n",
      "\t0.8459\t = Validation score   (accuracy)\n",
      "\t19.49s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T3 ...\n",
      "\t0.8536\t = Validation score   (accuracy)\n",
      "\t19.75s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 31.15s of the 3397.81s of remaining time.\n",
      "\tFitting 1 child models (S1F1 - S1F1) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t7.68s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1/T1 ... Training model for up to 3388.01s of the 3388.0s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8683\t = Validation score   (accuracy)\n",
      "\t14.99s\t = Training   runtime\n",
      "\t1.17s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1/T2 ... Training model for up to 3373.47s of the 3373.46s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8683\t = Validation score   (accuracy)\n",
      "\t27.31s\t = Training   runtime\n",
      "\t3.51s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1/T3 ... Training model for up to 3343.54s of the 3343.54s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8671\t = Validation score   (accuracy)\n",
      "\t19.0s\t = Training   runtime\n",
      "\t2.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1/T4 ... Training model for up to 3320.52s of the 3320.52s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8665\t = Validation score   (accuracy)\n",
      "\t60.49s\t = Training   runtime\n",
      "\t11.65s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 3269.2s of the 3269.2s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t11.77s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 3255.73s of the 3255.72s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t12.48s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T3 ... Training model for up to 3241.82s of the 3241.82s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.874\t = Validation score   (accuracy)\n",
      "\t13.29s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T4 ... Training model for up to 3227.51s of the 3227.51s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8738\t = Validation score   (accuracy)\n",
      "\t35.56s\t = Training   runtime\n",
      "\t5.84s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T5 ... Training model for up to 3194.84s of the 3194.83s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8746\t = Validation score   (accuracy)\n",
      "\t11.78s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T6 ... Training model for up to 3180.69s of the 3180.69s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8734\t = Validation score   (accuracy)\n",
      "\t17.64s\t = Training   runtime\n",
      "\t1.27s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T7 ... Training model for up to 3162.31s of the 3162.31s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8739\t = Validation score   (accuracy)\n",
      "\t11.95s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T8 ... Training model for up to 3148.13s of the 3148.12s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8742\t = Validation score   (accuracy)\n",
      "\t11.26s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1/T9 ... Training model for up to 3134.2s of the 3134.2s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.873\t = Validation score   (accuracy)\n",
      "\t29.29s\t = Training   runtime\n",
      "\t4.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1/T1 ... Training model for up to 3103.85s of the 3103.85s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8738\t = Validation score   (accuracy)\n",
      "\t172.61s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1/T1 ... Training model for up to 2952.51s of the 2952.51s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8543\t = Validation score   (accuracy)\n",
      "\t473.98s\t = Training   runtime\n",
      "\t3.36s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1/T2 ... Training model for up to 2492.82s of the 2492.81s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8589\t = Validation score   (accuracy)\n",
      "\t68.21s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1/T3 ... Training model for up to 2441.04s of the 2441.04s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8581\t = Validation score   (accuracy)\n",
      "\t118.53s\t = Training   runtime\n",
      "\t1.46s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1/T4 ... Training model for up to 2337.05s of the 2337.04s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8616\t = Validation score   (accuracy)\n",
      "\t98.87s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1/T1 ... Training model for up to 2254.84s of the 2254.83s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8758\t = Validation score   (accuracy)\n",
      "\t19.43s\t = Training   runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1/T2 ... Training model for up to 2232.71s of the 2232.71s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.873\t = Validation score   (accuracy)\n",
      "\t17.61s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1/T3 ... Training model for up to 2213.92s of the 2213.92s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8732\t = Validation score   (accuracy)\n",
      "\t38.29s\t = Training   runtime\n",
      "\t2.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1/T4 ... Training model for up to 2174.29s of the 2174.28s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.873\t = Validation score   (accuracy)\n",
      "\t22.59s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1/T5 ... Training model for up to 2148.51s of the 2148.51s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8721\t = Validation score   (accuracy)\n",
      "\t30.36s\t = Training   runtime\n",
      "\t1.29s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1/T6 ... Training model for up to 2116.67s of the 2116.67s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8737\t = Validation score   (accuracy)\n",
      "\t39.38s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1/T7 ... Training model for up to 2074.53s of the 2074.52s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8713\t = Validation score   (accuracy)\n",
      "\t17.22s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1/T8 ... Training model for up to 2053.77s of the 2053.77s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8723\t = Validation score   (accuracy)\n",
      "\t64.41s\t = Training   runtime\n",
      "\t2.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T1 ... Training model for up to 1988.15s of the 1988.14s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.857\t = Validation score   (accuracy)\n",
      "\t394.37s\t = Training   runtime\n",
      "\t2.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T2 ... Training model for up to 1608.25s of the 1608.25s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8524\t = Validation score   (accuracy)\n",
      "\t283.88s\t = Training   runtime\n",
      "\t1.85s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T3 ... Training model for up to 1339.24s of the 1339.23s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.859\t = Validation score   (accuracy)\n",
      "\t260.33s\t = Training   runtime\n",
      "\t2.41s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1093.66s of the 1093.65s of remaining time.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8737\t = Validation score   (accuracy)\n",
      "\t28.4s\t = Training   runtime\n",
      "\t1.84s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1067.39s of remaining time.\n",
      "\t0.8758\t = Validation score   (accuracy)\n",
      "\t44.04s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2576.84s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221128_020212/\")\n"
     ]
    }
   ],
   "source": [
    "time_limit = 60*60  # train various models for ~1 h\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': 20,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "# We have to cast the label from str to int to use the sample weight method\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "train_data[label] = train_data[label].apply(lambda x: 0 if '<=50K' in x else 1)\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric='acc',\n",
    "                             sample_weight=label, problem_type='binary'\n",
    "                            ).fit(train_data, time_limit=time_limit,\n",
    "                                  auto_stack=True, presets='best_quality',\n",
    "                                  hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6f64123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.877162452656362\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.877162452656362\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "test_data2 = test_data.copy()\n",
    "test_data2[label] = test_data2[label].apply(lambda x: 0 if '<=50K' in x else 1)\n",
    "perf = predictor.evaluate(test_data2, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309cb92e",
   "metadata": {},
   "source": [
    "We improved the accuracy from 0.8757 to 0.8760"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35199aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L1/T1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873800</td>\n",
       "      <td>0.563200</td>\n",
       "      <td>0.366137</td>\n",
       "      <td>172.614355</td>\n",
       "      <td>0.563200</td>\n",
       "      <td>0.366137</td>\n",
       "      <td>172.614355</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L1/T7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873852</td>\n",
       "      <td>0.719223</td>\n",
       "      <td>0.568975</td>\n",
       "      <td>11.952137</td>\n",
       "      <td>0.719223</td>\n",
       "      <td>0.568975</td>\n",
       "      <td>11.952137</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L1/T8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874159</td>\n",
       "      <td>0.809996</td>\n",
       "      <td>0.755380</td>\n",
       "      <td>11.260965</td>\n",
       "      <td>0.809996</td>\n",
       "      <td>0.755380</td>\n",
       "      <td>11.260965</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L1/T2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874850</td>\n",
       "      <td>0.848019</td>\n",
       "      <td>0.749080</td>\n",
       "      <td>12.478494</td>\n",
       "      <td>0.848019</td>\n",
       "      <td>0.749080</td>\n",
       "      <td>12.478494</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1/T5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874568</td>\n",
       "      <td>0.921795</td>\n",
       "      <td>0.597973</td>\n",
       "      <td>11.775184</td>\n",
       "      <td>0.921795</td>\n",
       "      <td>0.597973</td>\n",
       "      <td>11.775184</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_BAG_L1/T3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873979</td>\n",
       "      <td>0.995435</td>\n",
       "      <td>0.899142</td>\n",
       "      <td>13.289551</td>\n",
       "      <td>0.995435</td>\n",
       "      <td>0.899142</td>\n",
       "      <td>13.289551</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_BAG_L1/T1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874543</td>\n",
       "      <td>1.037089</td>\n",
       "      <td>0.667051</td>\n",
       "      <td>11.771457</td>\n",
       "      <td>1.037089</td>\n",
       "      <td>0.667051</td>\n",
       "      <td>11.771457</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost_BAG_L1/T1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875797</td>\n",
       "      <td>1.112917</td>\n",
       "      <td>0.891370</td>\n",
       "      <td>19.428157</td>\n",
       "      <td>1.112917</td>\n",
       "      <td>0.891370</td>\n",
       "      <td>19.428157</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost_BAG_L1/T5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872111</td>\n",
       "      <td>1.372930</td>\n",
       "      <td>1.289406</td>\n",
       "      <td>30.363995</td>\n",
       "      <td>1.372930</td>\n",
       "      <td>1.289406</td>\n",
       "      <td>30.363995</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1/T4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861644</td>\n",
       "      <td>1.386764</td>\n",
       "      <td>0.745765</td>\n",
       "      <td>98.869826</td>\n",
       "      <td>1.386764</td>\n",
       "      <td>0.745765</td>\n",
       "      <td>98.869826</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost_BAG_L1/T7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871318</td>\n",
       "      <td>1.412387</td>\n",
       "      <td>0.832350</td>\n",
       "      <td>17.216294</td>\n",
       "      <td>1.412387</td>\n",
       "      <td>0.832350</td>\n",
       "      <td>17.216294</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost_BAG_L1/T4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873007</td>\n",
       "      <td>1.439530</td>\n",
       "      <td>0.749419</td>\n",
       "      <td>22.592386</td>\n",
       "      <td>1.439530</td>\n",
       "      <td>0.749419</td>\n",
       "      <td>22.592386</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873672</td>\n",
       "      <td>1.440516</td>\n",
       "      <td>1.838157</td>\n",
       "      <td>28.404886</td>\n",
       "      <td>1.440516</td>\n",
       "      <td>1.838157</td>\n",
       "      <td>28.404886</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1/T2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.858905</td>\n",
       "      <td>1.507040</td>\n",
       "      <td>0.710427</td>\n",
       "      <td>68.208057</td>\n",
       "      <td>1.507040</td>\n",
       "      <td>0.710427</td>\n",
       "      <td>68.208057</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBM_BAG_L1/T6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873442</td>\n",
       "      <td>1.537341</td>\n",
       "      <td>1.268070</td>\n",
       "      <td>17.640405</td>\n",
       "      <td>1.537341</td>\n",
       "      <td>1.268070</td>\n",
       "      <td>17.640405</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBMXT_BAG_L1/T1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868298</td>\n",
       "      <td>1.589864</td>\n",
       "      <td>1.166820</td>\n",
       "      <td>14.994406</td>\n",
       "      <td>1.589864</td>\n",
       "      <td>1.166820</td>\n",
       "      <td>14.994406</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBoost_BAG_L1/T6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873698</td>\n",
       "      <td>1.657272</td>\n",
       "      <td>1.631019</td>\n",
       "      <td>39.377660</td>\n",
       "      <td>1.657272</td>\n",
       "      <td>1.631019</td>\n",
       "      <td>39.377660</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBoost_BAG_L1/T2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873007</td>\n",
       "      <td>1.701849</td>\n",
       "      <td>0.920677</td>\n",
       "      <td>17.608718</td>\n",
       "      <td>1.701849</td>\n",
       "      <td>0.920677</td>\n",
       "      <td>17.608718</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBoost_BAG_L1/T3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873212</td>\n",
       "      <td>1.926292</td>\n",
       "      <td>2.047804</td>\n",
       "      <td>38.290473</td>\n",
       "      <td>1.926292</td>\n",
       "      <td>2.047804</td>\n",
       "      <td>38.290473</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LightGBMXT_BAG_L1/T3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.867121</td>\n",
       "      <td>2.088871</td>\n",
       "      <td>2.054278</td>\n",
       "      <td>18.995026</td>\n",
       "      <td>2.088871</td>\n",
       "      <td>2.054278</td>\n",
       "      <td>18.995026</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.858956</td>\n",
       "      <td>2.167222</td>\n",
       "      <td>2.412387</td>\n",
       "      <td>260.325031</td>\n",
       "      <td>2.167222</td>\n",
       "      <td>2.412387</td>\n",
       "      <td>260.325031</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBoost_BAG_L1/T8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872316</td>\n",
       "      <td>2.196382</td>\n",
       "      <td>2.062016</td>\n",
       "      <td>64.413380</td>\n",
       "      <td>2.196382</td>\n",
       "      <td>2.062016</td>\n",
       "      <td>64.413380</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1/T3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.858061</td>\n",
       "      <td>2.418714</td>\n",
       "      <td>1.462619</td>\n",
       "      <td>118.530020</td>\n",
       "      <td>2.418714</td>\n",
       "      <td>1.462619</td>\n",
       "      <td>118.530020</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LightGBMXT_BAG_L1/T2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868272</td>\n",
       "      <td>2.484471</td>\n",
       "      <td>3.509935</td>\n",
       "      <td>27.310038</td>\n",
       "      <td>2.484471</td>\n",
       "      <td>3.509935</td>\n",
       "      <td>27.310038</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875848</td>\n",
       "      <td>2.503693</td>\n",
       "      <td>1.779207</td>\n",
       "      <td>162.337248</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.142071</td>\n",
       "      <td>44.039265</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852379</td>\n",
       "      <td>3.483311</td>\n",
       "      <td>1.847616</td>\n",
       "      <td>283.880275</td>\n",
       "      <td>3.483311</td>\n",
       "      <td>1.847616</td>\n",
       "      <td>283.880275</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857037</td>\n",
       "      <td>3.572351</td>\n",
       "      <td>2.153313</td>\n",
       "      <td>394.370386</td>\n",
       "      <td>3.572351</td>\n",
       "      <td>2.153313</td>\n",
       "      <td>394.370386</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LightGBM_BAG_L1/T9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873033</td>\n",
       "      <td>4.570424</td>\n",
       "      <td>4.190924</td>\n",
       "      <td>29.292349</td>\n",
       "      <td>4.570424</td>\n",
       "      <td>4.190924</td>\n",
       "      <td>29.292349</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LightGBM_BAG_L1/T4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873800</td>\n",
       "      <td>6.148067</td>\n",
       "      <td>5.842562</td>\n",
       "      <td>35.562928</td>\n",
       "      <td>6.148067</td>\n",
       "      <td>5.842562</td>\n",
       "      <td>35.562928</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1/T1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.854350</td>\n",
       "      <td>7.015230</td>\n",
       "      <td>3.357838</td>\n",
       "      <td>473.982804</td>\n",
       "      <td>7.015230</td>\n",
       "      <td>3.357838</td>\n",
       "      <td>473.982804</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LightGBMXT_BAG_L1/T4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866481</td>\n",
       "      <td>13.009131</td>\n",
       "      <td>11.651915</td>\n",
       "      <td>60.485499</td>\n",
       "      <td>13.009131</td>\n",
       "      <td>11.651915</td>\n",
       "      <td>60.485499</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  score_test  score_val  pred_time_test  \\\n",
       "0          CatBoost_BAG_L1/T1         0.0   0.873800        0.563200   \n",
       "1          LightGBM_BAG_L1/T7         0.0   0.873852        0.719223   \n",
       "2          LightGBM_BAG_L1/T8         0.0   0.874159        0.809996   \n",
       "3          LightGBM_BAG_L1/T2         0.0   0.874850        0.848019   \n",
       "4          LightGBM_BAG_L1/T5         0.0   0.874568        0.921795   \n",
       "5          LightGBM_BAG_L1/T3         0.0   0.873979        0.995435   \n",
       "6          LightGBM_BAG_L1/T1         0.0   0.874543        1.037089   \n",
       "7           XGBoost_BAG_L1/T1         0.0   0.875797        1.112917   \n",
       "8           XGBoost_BAG_L1/T5         0.0   0.872111        1.372930   \n",
       "9   NeuralNetFastAI_BAG_L1/T4         0.0   0.861644        1.386764   \n",
       "10          XGBoost_BAG_L1/T7         0.0   0.871318        1.412387   \n",
       "11          XGBoost_BAG_L1/T4         0.0   0.873007        1.439530   \n",
       "12       LightGBMLarge_BAG_L1         0.0   0.873672        1.440516   \n",
       "13  NeuralNetFastAI_BAG_L1/T2         0.0   0.858905        1.507040   \n",
       "14         LightGBM_BAG_L1/T6         0.0   0.873442        1.537341   \n",
       "15       LightGBMXT_BAG_L1/T1         0.0   0.868298        1.589864   \n",
       "16          XGBoost_BAG_L1/T6         0.0   0.873698        1.657272   \n",
       "17          XGBoost_BAG_L1/T2         0.0   0.873007        1.701849   \n",
       "18          XGBoost_BAG_L1/T3         0.0   0.873212        1.926292   \n",
       "19       LightGBMXT_BAG_L1/T3         0.0   0.867121        2.088871   \n",
       "20   NeuralNetTorch_BAG_L1/T3         0.0   0.858956        2.167222   \n",
       "21          XGBoost_BAG_L1/T8         0.0   0.872316        2.196382   \n",
       "22  NeuralNetFastAI_BAG_L1/T3         0.0   0.858061        2.418714   \n",
       "23       LightGBMXT_BAG_L1/T2         0.0   0.868272        2.484471   \n",
       "24        WeightedEnsemble_L2         0.0   0.875848        2.503693   \n",
       "25   NeuralNetTorch_BAG_L1/T2         0.0   0.852379        3.483311   \n",
       "26   NeuralNetTorch_BAG_L1/T1         0.0   0.857037        3.572351   \n",
       "27         LightGBM_BAG_L1/T9         0.0   0.873033        4.570424   \n",
       "28         LightGBM_BAG_L1/T4         0.0   0.873800        6.148067   \n",
       "29  NeuralNetFastAI_BAG_L1/T1         0.0   0.854350        7.015230   \n",
       "30       LightGBMXT_BAG_L1/T4         0.0   0.866481       13.009131   \n",
       "\n",
       "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        0.366137  172.614355                 0.563200   \n",
       "1        0.568975   11.952137                 0.719223   \n",
       "2        0.755380   11.260965                 0.809996   \n",
       "3        0.749080   12.478494                 0.848019   \n",
       "4        0.597973   11.775184                 0.921795   \n",
       "5        0.899142   13.289551                 0.995435   \n",
       "6        0.667051   11.771457                 1.037089   \n",
       "7        0.891370   19.428157                 1.112917   \n",
       "8        1.289406   30.363995                 1.372930   \n",
       "9        0.745765   98.869826                 1.386764   \n",
       "10       0.832350   17.216294                 1.412387   \n",
       "11       0.749419   22.592386                 1.439530   \n",
       "12       1.838157   28.404886                 1.440516   \n",
       "13       0.710427   68.208057                 1.507040   \n",
       "14       1.268070   17.640405                 1.537341   \n",
       "15       1.166820   14.994406                 1.589864   \n",
       "16       1.631019   39.377660                 1.657272   \n",
       "17       0.920677   17.608718                 1.701849   \n",
       "18       2.047804   38.290473                 1.926292   \n",
       "19       2.054278   18.995026                 2.088871   \n",
       "20       2.412387  260.325031                 2.167222   \n",
       "21       2.062016   64.413380                 2.196382   \n",
       "22       1.462619  118.530020                 2.418714   \n",
       "23       3.509935   27.310038                 2.484471   \n",
       "24       1.779207  162.337248                 0.004012   \n",
       "25       1.847616  283.880275                 3.483311   \n",
       "26       2.153313  394.370386                 3.572351   \n",
       "27       4.190924   29.292349                 4.570424   \n",
       "28       5.842562   35.562928                 6.148067   \n",
       "29       3.357838  473.982804                 7.015230   \n",
       "30      11.651915   60.485499                13.009131   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.366137         172.614355            1       True   \n",
       "1                 0.568975          11.952137            1       True   \n",
       "2                 0.755380          11.260965            1       True   \n",
       "3                 0.749080          12.478494            1       True   \n",
       "4                 0.597973          11.775184            1       True   \n",
       "5                 0.899142          13.289551            1       True   \n",
       "6                 0.667051          11.771457            1       True   \n",
       "7                 0.891370          19.428157            1       True   \n",
       "8                 1.289406          30.363995            1       True   \n",
       "9                 0.745765          98.869826            1       True   \n",
       "10                0.832350          17.216294            1       True   \n",
       "11                0.749419          22.592386            1       True   \n",
       "12                1.838157          28.404886            1       True   \n",
       "13                0.710427          68.208057            1       True   \n",
       "14                1.268070          17.640405            1       True   \n",
       "15                1.166820          14.994406            1       True   \n",
       "16                1.631019          39.377660            1       True   \n",
       "17                0.920677          17.608718            1       True   \n",
       "18                2.047804          38.290473            1       True   \n",
       "19                2.054278          18.995026            1       True   \n",
       "20                2.412387         260.325031            1       True   \n",
       "21                2.062016          64.413380            1       True   \n",
       "22                1.462619         118.530020            1       True   \n",
       "23                3.509935          27.310038            1       True   \n",
       "24                0.142071          44.039265            2       True   \n",
       "25                1.847616         283.880275            1       True   \n",
       "26                2.153313         394.370386            1       True   \n",
       "27                4.190924          29.292349            1       True   \n",
       "28                5.842562          35.562928            1       True   \n",
       "29                3.357838         473.982804            1       True   \n",
       "30               11.651915          60.485499            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          14  \n",
       "1          11  \n",
       "2          12  \n",
       "3           6  \n",
       "4           9  \n",
       "5           7  \n",
       "6           5  \n",
       "7          19  \n",
       "8          23  \n",
       "9          18  \n",
       "10         25  \n",
       "11         22  \n",
       "12         30  \n",
       "13         16  \n",
       "14         10  \n",
       "15          1  \n",
       "16         24  \n",
       "17         20  \n",
       "18         21  \n",
       "19          3  \n",
       "20         29  \n",
       "21         26  \n",
       "22         17  \n",
       "23          2  \n",
       "24         31  \n",
       "25         28  \n",
       "26         27  \n",
       "27         13  \n",
       "28          8  \n",
       "29         15  \n",
       "30          4  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}